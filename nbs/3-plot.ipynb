{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Plot\n",
    "\n",
    "## Load all results data and compute mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import plt_configs\n",
    "\n",
    "keys = ['correct_pairings_inv', 'correct_pairings_basX', 'tau_inv', 'tau_basX', 'spearman_inv', 'spearman_basX', 'aucs_inv', 'aucs_basX', 'spearman_exceptional_inv', 'spearman_exceptional_basX', 'tau_exceptional_inv', 'tau_exceptional_basX']\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "DATASET_NAME = 'avila'\n",
    "MODEL_NAME = '0'\n",
    "GENERATION_MODE = ''\n",
    "TARGET_MEASURE = '_qmeans' #'_AttributionLocalisation' | '_TopKIntersection' | '_RelevanceRankAccuracy' | '_AUC' | 'EfficientMPRT'\n",
    "SUFFIX = '' #'_EfficientMPRT'\n",
    "\n",
    "#FIG2A, FIG3A, FIG7A & FIG8A\n",
    "DATASET_NAME, MODEL_NAME, GENERATION_MODE, TARGET_MEASURE, SUFFIX = 'avila', 'mlp', '_full', '_qmeans', ''\n",
    "#FIG2B, FIG3B, FIG7B\n",
    "#DATASET_NAME, MODEL_NAME, GENERATION_MODE, TARGET_MEASURE, SUFFIX = 'glass', 'mlp', '_full', '_qmeans', ''\n",
    "#FIG8B\n",
    "#DATASET_NAME, MODEL_NAME, GENERATION_MODE, TARGET_MEASURE, SUFFIX = 'avila', 'ood-mean', '_full', '_qmeans', ''\n",
    "#FIG8C\n",
    "#DATASET_NAME, MODEL_NAME, GENERATION_MODE, TARGET_MEASURE, SUFFIX = 'avila', 'untrained', '_full', '_qmeans', ''\n",
    "\n",
    "num_files = 0 # Count how many files are involved for use below\n",
    "\n",
    "for f in os.listdir(os.path.join(PROJ_DIR, 'results')):\n",
    "    if f.startswith(DATASET_NAME) and f.endswith(f'{MODEL_NAME}{GENERATION_MODE}{SUFFIX}_results{TARGET_MEASURE}.npz'):#{MODEL_NAME}{GENERATION_MODE}_localization_s_area_results{TARGET_MEASURE}.npz\n",
    "        FILENAME = os.path.join(PROJ_DIR, 'results', f)\n",
    "        print(FILENAME)\n",
    "        num_files += 1\n",
    "        with np.load(FILENAME) as data:\n",
    "            for k in keys:\n",
    "                d = np.expand_dims(data[k], axis=0)\n",
    "                if k in result_dict:\n",
    "                    result_dict[k] = np.vstack((result_dict[k], d))\n",
    "                else:\n",
    "                    result_dict[k] = d\n",
    "\n",
    "for k in keys:\n",
    "    result_dict[f'{k}_mean'] = np.nanmean(result_dict[k], axis=0)\n",
    "    result_dict[f'{k}_std'] = np.nanstd(result_dict[k], axis=0)\n",
    "\n",
    "# DEBUG\n",
    "#print(result_dict['spearman_inv'])\n",
    "#print(result_dict['spearman_inv_mean'])\n",
    "#print(result_dict['spearman_basX'])\n",
    "#print(result_dict['spearman_basX_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [0.5, 1, 1.5, 2, 2.5]#, 3, 3.5]\n",
    "counts_by_sigma_level =  np.zeros((num_files, len(boundaries)))\n",
    "filenames = []\n",
    "qmean_means = []\n",
    "qmean_stds = []\n",
    "\n",
    "# Genetic datasets need the distribution parameters of the random datasets, so load all dataset counts\n",
    "import json\n",
    "DATA_PATH = os.path.join(PROJ_DIR,'assets','data')\n",
    "with open(os.path.join(DATA_PATH, 'dataset-counts.json')) as fIn:\n",
    "    datasets = json.load(fIn)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#plt.figure(figsize=(3,2))\n",
    "current_file_num = 0\n",
    "for f in os.listdir(os.path.join(PROJ_DIR, 'results')):\n",
    "    if f.startswith(DATASET_NAME) and f.endswith(f'{MODEL_NAME}{GENERATION_MODE}{SUFFIX}_measures.npz'):\n",
    "        FILENAME = os.path.join(PROJ_DIR, 'results', f)\n",
    "        filenames.append(f)\n",
    "        short_filename = f.replace(\"_measures.npz\", \"\").replace(DATASET_NAME, \"\").replace(MODEL_NAME, \"\").replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "        with np.load(FILENAME) as data:\n",
    "            ax.hist(data[TARGET_MEASURE[1:]],\\\n",
    "                    alpha = 0.5,\\\n",
    "                    label = f'{short_filename} qmean~N({np.mean(data[TARGET_MEASURE[1:]]):.2f},{np.std(data[TARGET_MEASURE[1:]]):.2f})',\\\n",
    "                    #edgecolor='black',\\\n",
    "                    bins = 50,\\\n",
    "                    range=(0,1)\\\n",
    "                    )\n",
    "            #plt.xlim(0,1)\n",
    "\n",
    "            if GENERATION_MODE == '_genetic':\n",
    "                with np.load(FILENAME.replace('_genetic', '')) as data_ref:\n",
    "                    activation_ref = data_ref['output_curves'][8][-1]\n",
    "                    ax.hist(data_ref['qmeans'],\\\n",
    "                            alpha = 0.5,\\\n",
    "                            label = f'{short_filename.replace(\"genetic\", \"\")} qmean~N({np.mean(data_ref[\"qmeans\"]):.2f},{np.std(data_ref[\"qmeans\"]):.2f}) [{activation_ref:.2f}]',\\\n",
    "                            bins = 50\\\n",
    "                            )\n",
    "\n",
    "            exceptional_counts = []\n",
    "            # Compute z-score\n",
    "            if GENERATION_MODE == '_genetic':\n",
    "                qmean_mean = float(datasets[DATASET_NAME][f.replace('_genetic','')]['mean'])\n",
    "                qmean_std = float(datasets[DATASET_NAME][f.replace('_genetic','')]['std'])\n",
    "            else:\n",
    "                qmean_mean = np.mean(data[TARGET_MEASURE[1:]])\n",
    "                qmean_std = np.std(data[TARGET_MEASURE[1:]])\n",
    "                print(f'{qmean_mean = }')\n",
    "                qmean_means.append(qmean_mean)\n",
    "                qmean_stds.append(qmean_std)\n",
    "            \n",
    "            z_scores = ((data[TARGET_MEASURE[1:]] - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "            # Count exceptional rankings\n",
    "            for i in range(1,len(boundaries)+1):\n",
    "                bottom_limit = boundaries[i-1]\n",
    "                top_limit = float('inf')\n",
    "                if i < len(boundaries):\n",
    "                    top_limit = boundaries[i]\n",
    "                fraction_count = np.sum(np.logical_and(bottom_limit<=z_scores, z_scores<top_limit).astype(float) / z_scores.shape[0])\n",
    "                exceptional_counts.append(fraction_count)\n",
    "                counts_by_sigma_level[current_file_num, i - 1] = fraction_count\n",
    "            print(f'{short_filename} {\"  |  \".join((map(lambda x: f\"{x:.4f}\", exceptional_counts)))}')\n",
    "        current_file_num += 1\n",
    "#plt.legend()\n",
    "ax.set_ylim(0,3.7e6)\n",
    "ax.set_title(f'{\"trained\" if MODEL_NAME==\"0\" else MODEL_NAME}')\n",
    "ax.set_xlabel('q')\n",
    "if MODEL_NAME == \"0\":\n",
    "    ax.set_ylabel('# elems')\n",
    "else:\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_qmean_dists.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(counts_by_sigma_level)\n",
    "print('AVG STD:', np.mean(qmean_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_counts = {} if DATASET_NAME not in datasets else datasets[DATASET_NAME]\n",
    "for i, f in enumerate(filenames):\n",
    "    dataset_counts[f] = {'counts':list(counts_by_sigma_level[i]), 'mean': str(qmean_means[i]), 'std': str(qmean_stds[i])}\n",
    "\n",
    "datasets[DATASET_NAME] = dataset_counts\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'dataset-counts.json'), 'w') as fOut:\n",
    "    json.dump(datasets, fOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correct pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(3,2))\n",
    "plt.fill_between(range(1,11), result_dict['correct_pairings_basX_mean']+result_dict['correct_pairings_basX_std'], result_dict['correct_pairings_basX_mean']-result_dict['correct_pairings_basX_std'], color='lightblue')\n",
    "plt.plot(range(1,11),result_dict['correct_pairings_basX_mean'], label='qrandK')\n",
    "#plt.title(f'Correct pairs vs. K - {DATASET_NAME.capitalize()}')\n",
    "plt.title(f'{DATASET_NAME.capitalize()}')\n",
    "plt.plot([1,10], [result_dict['correct_pairings_inv_mean']+result_dict['correct_pairings_inv_std'], result_dict['correct_pairings_inv_mean']+result_dict['correct_pairings_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10], [result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_inv_std'], result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10],[result_dict['correct_pairings_inv_mean'],result_dict['correct_pairings_inv_mean']], label='qinv')\n",
    "plt.ylim(0.7,1.05)\n",
    "plt.xlabel('K')\n",
    "#plt.ylabel('q')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_correct_pairs.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "delta_p = result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_basX_mean'][0]\n",
    "print('delta_p', delta_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Kendall's tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(3,2))\n",
    "plt.fill_between(range(1,11), result_dict['tau_basX_mean']+result_dict['tau_basX_std'], result_dict['tau_basX_mean']-result_dict['tau_basX_std'], color='lightblue')\n",
    "plt.plot(range(1,11),result_dict['tau_basX_mean'], label='qrandK')\n",
    "#plt.title(f'Correct pairs vs. K - {DATASET_NAME.capitalize()}')\n",
    "plt.title(f'{DATASET_NAME.capitalize()}')\n",
    "plt.plot([1,10], [result_dict['tau_inv_mean']+result_dict['tau_inv_std'], result_dict['tau_inv_mean']+result_dict['tau_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10], [result_dict['tau_inv_mean']-result_dict['tau_inv_std'], result_dict['tau_inv_mean']-result_dict['tau_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10],[result_dict['tau_inv_mean'],result_dict['tau_inv_mean']], label='qinv')\n",
    "plt.ylim(0.45,1.05)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('$\\\\tau$')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_tau.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "delta_tau = result_dict['tau_inv_mean']-result_dict['tau_basX_mean'][0]\n",
    "print('delta_tau', delta_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(3,2))\n",
    "plt.fill_between(range(1,11), result_dict['spearman_basX_mean']+result_dict['spearman_basX_std'], result_dict['spearman_basX_mean']-result_dict['spearman_basX_std'], color='lightblue')\n",
    "plt.plot(range(1,11),result_dict['spearman_basX_mean'], label='qrandK')\n",
    "#plt.title('Spearman correlation vs. K')\n",
    "plt.title(f'{DATASET_NAME.capitalize()}')\n",
    "plt.plot([1,10], [result_dict['spearman_inv_mean']+result_dict['spearman_inv_std'], result_dict['spearman_inv_mean']+result_dict['spearman_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10], [result_dict['spearman_inv_mean']-result_dict['spearman_inv_std'], result_dict['spearman_inv_mean']-result_dict['spearman_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10],[result_dict['spearman_inv_mean'],result_dict['spearman_inv_mean']], label='qinv')\n",
    "plt.ylim(0.6,1.05)\n",
    "plt.xlabel('K')\n",
    "#plt.ylabel('q')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_spearman.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "delta_rho = result_dict['spearman_inv_mean']-result_dict['spearman_basX_mean'][0]\n",
    "print('delta_rho', delta_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ability to detect exceptional rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [0.5, 1, 1.5, 2, 2.5]#, 3, 3.5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.fill_between(range(1,11), result_dict['aucs_basX_mean'][:,i+1]+result_dict['aucs_basX_std'][:,i+1], result_dict['aucs_basX_mean'][:,i+1]-result_dict['aucs_basX_std'][:,i+1], color='lightblue')\n",
    "    ax.plot(range(1,11),result_dict['aucs_basX_mean'][:,i+1], label='qrandX')\n",
    "    ax.set_xlabel('K')\n",
    "    counts_str = '|'.join(map(lambda x:f'{x:.2f}',counts_by_sigma_level[:, i]))\n",
    "    if i<len(boundaries)-2:\n",
    "        #ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ ({counts_str})', fontsize=10)\n",
    "        ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ', fontsize=16)\n",
    "    else:\n",
    "        #ax.set_title(f'[{boundaries[i+1]},inf)σ ({counts_str})', fontsize=10)\n",
    "        ax.set_title(f'[{boundaries[i+1]},inf)σ', fontsize=16)\n",
    "    if i>0:\n",
    "        #ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xticks([2,4,6,8,10])\n",
    "    ax.plot([1,10], [result_dict['aucs_inv_mean'][i+1]+result_dict['aucs_inv_std'][i+1], result_dict['aucs_inv_mean'][i+1]+result_dict['aucs_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10], [result_dict['aucs_inv_mean'][i+1]-result_dict['aucs_inv_std'][i+1], result_dict['aucs_inv_mean'][i+1]-result_dict['aucs_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10],[result_dict['aucs_inv_mean'][i+1],result_dict['aucs_inv_mean'][i+1]], label='qinv')\n",
    "\n",
    "    if i==3:\n",
    "        ax.legend(loc='lower right')\n",
    "    ax.set_ylim(0.8,1.05)\n",
    "plt.tight_layout()\n",
    "#plt.suptitle('AUC vs. K')\n",
    "plt.suptitle(f'{DATASET_NAME.capitalize()}')\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_auc_exceptional.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Spearman correlation for exceptional rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.fill_between(range(1,11), result_dict['spearman_exceptional_basX_mean'][:,i+1]+result_dict['spearman_exceptional_basX_std'][:,i+1], result_dict['spearman_exceptional_basX_mean'][:,i+1]-result_dict['spearman_exceptional_basX_std'][:,i+1], color='lightblue')\n",
    "    ax.plot(range(1,11),result_dict['spearman_exceptional_basX_mean'][:,i+1], label='qrandX')\n",
    "    ax.set_xlabel('K')\n",
    "    counts_str = '|'.join(map(lambda x:f'{x:.2f}',counts_by_sigma_level[:, i]))\n",
    "    if i<len(boundaries)-2:\n",
    "        ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ', fontsize=16)\n",
    "    else:\n",
    "        ax.set_title(f'[{boundaries[i+1]},inf)σ', fontsize=16)\n",
    "    if i>0:\n",
    "        #ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "    ax.plot([1,10], [result_dict['spearman_exceptional_inv_mean'][i+1]+result_dict['spearman_exceptional_inv_std'][i+1], result_dict['spearman_exceptional_inv_mean'][i+1]+result_dict['spearman_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10], [result_dict['spearman_exceptional_inv_mean'][i+1]-result_dict['spearman_exceptional_inv_std'][i+1], result_dict['spearman_exceptional_inv_mean'][i+1]-result_dict['spearman_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10],[result_dict['spearman_exceptional_inv_mean'][i+1],result_dict['spearman_exceptional_inv_mean'][i+1]], label='qinv')\n",
    "    ax.set_ylim(0,1.05)\n",
    "    ax.set_xticks([2,4,6,8,10])\n",
    "    if i==3:\n",
    "        ax.legend(loc='lower right')\n",
    "plt.suptitle('Spearman correlation vs. K')\n",
    "plt.suptitle(f'{DATASET_NAME.capitalize()}')\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_spearman_exceptional.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Kendall's tau correlation for exceptional rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.fill_between(range(1,11), result_dict['tau_exceptional_basX_mean'][:,i+1]+result_dict['tau_exceptional_basX_std'][:,i+1], result_dict['tau_exceptional_basX_mean'][:,i+1]-result_dict['tau_exceptional_basX_std'][:,i+1], color='lightblue')\n",
    "    ax.plot(range(1,11),result_dict['tau_exceptional_basX_mean'][:,i+1], label='qrandX')\n",
    "    ax.set_xlabel('K')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('$\\\\tau$')\n",
    "    counts_str = '|'.join(map(lambda x:f'{x:.2f}',counts_by_sigma_level[:, i]))\n",
    "    if i<len(boundaries)-2:\n",
    "        ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ', fontsize=16)\n",
    "    else:\n",
    "        ax.set_title(f'[{boundaries[i+1]},inf)σ', fontsize=16)\n",
    "    if i>0:\n",
    "        #ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "    ax.plot([1,10], [result_dict['tau_exceptional_inv_mean'][i+1]+result_dict['tau_exceptional_inv_std'][i+1], result_dict['tau_exceptional_inv_mean'][i+1]+result_dict['tau_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10], [result_dict['tau_exceptional_inv_mean'][i+1]-result_dict['tau_exceptional_inv_std'][i+1], result_dict['tau_exceptional_inv_mean'][i+1]-result_dict['tau_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10],[result_dict['tau_exceptional_inv_mean'][i+1],result_dict['tau_exceptional_inv_mean'][i+1]], label='qinv')\n",
    "    ax.set_ylim(0,1.05)\n",
    "    ax.set_xticks([2,4,6,8,10])\n",
    "    if i==3:\n",
    "        ax.legend(loc='lower right')\n",
    "plt.suptitle('Kendall\\'s tau correlation vs. K')\n",
    "plt.suptitle(f'{DATASET_NAME.capitalize()}')\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_tau_exceptional.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
