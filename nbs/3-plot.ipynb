{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Plot\n",
    "\n",
    "## Load all results data and compute mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "keys = ['correct_pairings_inv', 'correct_pairings_basX', 'spearman_inv', 'spearman_basX', 'aucs_inv', 'aucs_basX', 'spearman_exceptional_inv', 'spearman_exceptional_basX']\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "DATASET_NAME = 'imagenet'\n",
    "MODEL_NAME = 'maxvit_t'\n",
    "GENERATION_MODE = '_chunky'\n",
    "\n",
    "num_files = 0 # Count how many files are involved for use below\n",
    "\n",
    "for f in os.listdir(os.path.join(PROJ_DIR, 'results')):\n",
    "    if f.startswith(DATASET_NAME) and f.endswith(f'{MODEL_NAME}{GENERATION_MODE}_results.npz'):\n",
    "        FILENAME = os.path.join(PROJ_DIR, 'results', f)\n",
    "        num_files += 1\n",
    "        with np.load(FILENAME) as data:\n",
    "            for k in keys:\n",
    "                d = np.expand_dims(data[k], axis=0)\n",
    "                if k in result_dict:\n",
    "                    result_dict[k] = np.vstack((result_dict[k], d))\n",
    "                else:\n",
    "                    result_dict[k] = d\n",
    "\n",
    "for k in keys:\n",
    "    result_dict[f'{k}_mean'] = np.nanmean(result_dict[k], axis=0)\n",
    "    result_dict[f'{k}_std'] = np.nanstd(result_dict[k], axis=0)\n",
    "\n",
    "# DEBUG\n",
    "#print(result_dict['spearman_inv'])\n",
    "#print(result_dict['spearman_inv_mean'])\n",
    "#print(result_dict['spearman_basX'])\n",
    "#print(result_dict['spearman_basX_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "boundaries = [0.5, 1, 1.5, 2, 2.5]#, 3, 3.5]\n",
    "counts_by_sigma_level =  np.zeros((num_files, len(boundaries)))\n",
    "filenames = []\n",
    "qmean_means = []\n",
    "qmean_stds = []\n",
    "\n",
    "# Genetic datasets need the distribution parameters of the random datasets, so load all dataset counts\n",
    "import json\n",
    "DATA_PATH = os.path.join(PROJ_DIR,'assets','data')\n",
    "with open(os.path.join(DATA_PATH, 'dataset-counts.json')) as fIn:\n",
    "    datasets = json.load(fIn)\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "current_file_num = 0\n",
    "for f in os.listdir(os.path.join(PROJ_DIR, 'results')):\n",
    "    if f.startswith(DATASET_NAME) and f.endswith(f'{MODEL_NAME}{GENERATION_MODE}_measures.npz'):\n",
    "        FILENAME = os.path.join(PROJ_DIR, 'results', f)\n",
    "        filenames.append(f)\n",
    "        short_filename = f.replace(\"_measures.npz\", \"\").replace(DATASET_NAME, \"\").replace(MODEL_NAME, \"\").replace(\"_\", \"\").replace(\"-\", \"\")\n",
    "        with np.load(FILENAME) as data:\n",
    "            activation = data['output_curves'][8][-1]\n",
    "            plt.hist(data['qmeans'],\\\n",
    "                    alpha = 0.5,\\\n",
    "                    label = f'{short_filename} qmean~N({np.mean(data[\"qmeans\"]):.2f},{np.std(data[\"qmeans\"]):.2f}) [{activation:.2f}]',\\\n",
    "                    #edgecolor='black',\\\n",
    "                    bins = 50,\\\n",
    "                    range=(0,1)\\\n",
    "                    )\n",
    "            #plt.xlim(0,1)\n",
    "\n",
    "            if GENERATION_MODE == '_genetic':\n",
    "                with np.load(FILENAME.replace('_genetic', '')) as data_ref:\n",
    "                    activation_ref = data_ref['output_curves'][8][-1]\n",
    "                    plt.hist(data_ref['qmeans'],\\\n",
    "                            alpha = 0.5,\\\n",
    "                            label = f'{short_filename.replace(\"genetic\", \"\")} qmean~N({np.mean(data_ref[\"qmeans\"]):.2f},{np.std(data_ref[\"qmeans\"]):.2f}) [{activation_ref:.2f}]',\\\n",
    "                            bins = 50\\\n",
    "                            )\n",
    "\n",
    "            exceptional_counts = []\n",
    "            # Compute z-score\n",
    "            if GENERATION_MODE == '_genetic':\n",
    "                qmean_mean = float(datasets[DATASET_NAME][f.replace('_genetic','')]['mean'])\n",
    "                qmean_std = float(datasets[DATASET_NAME][f.replace('_genetic','')]['std'])\n",
    "            else:\n",
    "                qmean_mean = np.mean(data[\"qmeans\"])\n",
    "                qmean_std = np.std(data[\"qmeans\"])\n",
    "                print(qmean_mean)\n",
    "                qmean_means.append(qmean_mean)\n",
    "                qmean_stds.append(qmean_std)\n",
    "            \n",
    "            z_scores = ((data[\"qmeans\"] - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "            # Count exceptional rankings\n",
    "            for i in range(1,len(boundaries)+1):\n",
    "                bottom_limit = boundaries[i-1]\n",
    "                top_limit = float('inf')\n",
    "                if i < len(boundaries):\n",
    "                    top_limit = boundaries[i]\n",
    "                fraction_count = np.sum(np.logical_and(bottom_limit<=z_scores, z_scores<top_limit).astype(float) / z_scores.shape[0])\n",
    "                exceptional_counts.append(fraction_count)\n",
    "                counts_by_sigma_level[current_file_num, i - 1] = fraction_count\n",
    "            print(f'{short_filename} {\"  |  \".join((map(lambda x: f\"{x:.4f}\", exceptional_counts)))}')\n",
    "        current_file_num += 1\n",
    "#plt.legend()\n",
    "plt.ylim(0,3.7e6)\n",
    "plt.title(f'{MODEL_NAME}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_qmean_dists.png'))\n",
    "plt.show()\n",
    "\n",
    "print(counts_by_sigma_level)\n",
    "print('AVG STD:', np.mean(qmean_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_counts = {} if DATASET_NAME not in datasets else datasets[DATASET_NAME]\n",
    "for i, f in enumerate(filenames):\n",
    "    if GENERATION_MODE == '_genetic':\n",
    "        dataset_counts[f.replace('_genetic', '')]['counts_genetic'] = list(counts_by_sigma_level[i])\n",
    "    else:\n",
    "        dataset_counts[f] = {'counts':list(counts_by_sigma_level[i]), 'mean': str(qmean_means[i]), 'std': str(qmean_stds[i])}\n",
    "\n",
    "datasets[DATASET_NAME] = dataset_counts\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'dataset-counts.json'), 'w') as fOut:\n",
    "    json.dump(datasets, fOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correct pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "plt.fill_between(range(1,11), result_dict['correct_pairings_basX_mean']+result_dict['correct_pairings_basX_std'], result_dict['correct_pairings_basX_mean']-result_dict['correct_pairings_basX_std'], color='lightblue')\n",
    "plt.plot(range(1,11),result_dict['correct_pairings_basX_mean'], label='qbasK')\n",
    "#plt.title(f'Correct pairs vs. K - {DATASET_NAME.capitalize()}')\n",
    "plt.title(f'{DATASET_NAME.capitalize()}')\n",
    "plt.plot([1,10], [result_dict['correct_pairings_inv_mean']+result_dict['correct_pairings_inv_std'], result_dict['correct_pairings_inv_mean']+result_dict['correct_pairings_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10], [result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_inv_std'], result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10],[result_dict['correct_pairings_inv_mean'],result_dict['correct_pairings_inv_mean']], label='qinv')\n",
    "plt.ylim(0.7,1.)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_correct_pairs.png'))\n",
    "plt.show()\n",
    "\n",
    "delta_p = result_dict['correct_pairings_inv_mean']-result_dict['correct_pairings_basX_mean'][0]\n",
    "print('delta_p', delta_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dict['correct_pairings_inv_mean'])\n",
    "result_dict['correct_pairings_inv_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "plt.fill_between(range(1,11), result_dict['spearman_basX_mean']+result_dict['spearman_basX_std'], result_dict['spearman_basX_mean']-result_dict['spearman_basX_std'], color='lightblue')\n",
    "plt.plot(range(1,11),result_dict['spearman_basX_mean'], label='qbasK')\n",
    "#plt.title('Spearman correlation vs. K')\n",
    "plt.title(f'{DATASET_NAME.capitalize()}')\n",
    "plt.plot([1,10], [result_dict['spearman_inv_mean']+result_dict['spearman_inv_std'], result_dict['spearman_inv_mean']+result_dict['spearman_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10], [result_dict['spearman_inv_mean']-result_dict['spearman_inv_std'], result_dict['spearman_inv_mean']-result_dict['spearman_inv_std']], color='orange', linestyle = 'dashed')\n",
    "plt.plot([1,10],[result_dict['spearman_inv_mean'],result_dict['spearman_inv_mean']], label='qinv')\n",
    "plt.ylim(0.6,1.05)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_spearman.png'))\n",
    "plt.show()\n",
    "\n",
    "delta_rho = result_dict['spearman_inv_mean']-result_dict['spearman_basX_mean'][0]\n",
    "print('delta_rho', delta_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ability to detect exceptional rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [0.5, 1, 1.5, 2, 2.5]#, 3, 3.5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.fill_between(range(1,11), result_dict['aucs_basX_mean'][:,i+1]+result_dict['aucs_basX_std'][:,i+1], result_dict['aucs_basX_mean'][:,i+1]-result_dict['aucs_basX_std'][:,i+1], color='lightblue')\n",
    "    ax.plot(range(1,11),result_dict['aucs_basX_mean'][:,i+1], label='qbasX')\n",
    "    counts_str = '|'.join(map(lambda x:f'{x:.2f}',counts_by_sigma_level[:, i]))\n",
    "    if i<len(boundaries)-2:\n",
    "        #ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ ({counts_str})', fontsize=10)\n",
    "        ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ', fontsize=10)\n",
    "    else:\n",
    "        #ax.set_title(f'[{boundaries[i+1]},inf)σ ({counts_str})', fontsize=10)\n",
    "        ax.set_title(f'[{boundaries[i+1]},inf)σ', fontsize=10)\n",
    "    if i>0:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xticks([2,4,6,8,10])\n",
    "    ax.plot([1,10], [result_dict['aucs_inv_mean'][i+1]+result_dict['aucs_inv_std'][i+1], result_dict['aucs_inv_mean'][i+1]+result_dict['aucs_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10], [result_dict['aucs_inv_mean'][i+1]-result_dict['aucs_inv_std'][i+1], result_dict['aucs_inv_mean'][i+1]-result_dict['aucs_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10],[result_dict['aucs_inv_mean'][i+1],result_dict['aucs_inv_mean'][i+1]], label='qinv')\n",
    "\n",
    "    if i==5:\n",
    "        ax.legend()\n",
    "    ax.set_ylim(0.8,1.05)\n",
    "plt.tight_layout()\n",
    "#plt.suptitle('AUC vs. K')\n",
    "plt.suptitle(f'{DATASET_NAME.capitalize()}')\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_auc_exceptional.png'))\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Spearman correlation for exceptional rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.fill_between(range(1,11), result_dict['spearman_exceptional_basX_mean'][:,i+1]+result_dict['spearman_exceptional_basX_std'][:,i+1], result_dict['spearman_exceptional_basX_mean'][:,i+1]-result_dict['spearman_exceptional_basX_std'][:,i+1], color='lightblue')\n",
    "    ax.plot(range(1,11),result_dict['spearman_exceptional_basX_mean'][:,i+1], label='qbasX')\n",
    "    counts_str = '|'.join(map(lambda x:f'{x:.2f}',counts_by_sigma_level[:, i]))\n",
    "    if i<len(boundaries)-2:\n",
    "        ax.set_title(f'[{boundaries[i+1]},{boundaries[i+1+1]}]σ', fontsize=10)\n",
    "    else:\n",
    "        ax.set_title(f'[{boundaries[i+1]},inf)σ', fontsize=10)\n",
    "    if i>0:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "    ax.plot([1,10], [result_dict['spearman_exceptional_inv_mean'][i+1]+result_dict['spearman_exceptional_inv_std'][i+1], result_dict['spearman_exceptional_inv_mean'][i+1]+result_dict['spearman_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10], [result_dict['spearman_exceptional_inv_mean'][i+1]-result_dict['spearman_exceptional_inv_std'][i+1], result_dict['spearman_exceptional_inv_mean'][i+1]-result_dict['spearman_exceptional_inv_std'][i+1]], color='orange', linestyle = 'dashed')\n",
    "    ax.plot([1,10],[result_dict['spearman_exceptional_inv_mean'][i+1],result_dict['spearman_exceptional_inv_mean'][i+1]], label='qinv')\n",
    "    ax.set_ylim(0,1.05)\n",
    "    ax.set_xticks([2,4,6,8,10])\n",
    "    if i==5:\n",
    "        ax.legend()\n",
    "plt.suptitle('Spearman correlation vs. K')\n",
    "plt.suptitle(f'{DATASET_NAME.capitalize()}')\n",
    "plt.savefig(os.path.join(PROJ_DIR, 'results', 'plots', f'{DATASET_NAME}_{MODEL_NAME}{GENERATION_MODE}_spearman_exceptional.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correct pairings vs z-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as ff\n",
    "\n",
    "for FILENAME in os.listdir(os.path.join(PROJ_DIR,'results')):\n",
    "    if FILENAME.startswith(DATASET_NAME) and FILENAME.endswith(f'{MODEL_NAME}{GENERATION_MODE}_measures.npz'):\n",
    "        print(FILENAME)\n",
    "\n",
    "        # Load data\n",
    "        data = ff.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "        qmeans = data['qmeans']\n",
    "        #qmeans_basX = [data['qmean_bas']] # We don't look at qmean_bas, it will be recomputed later with the appropriate reference\n",
    "        qmeans_basX = []\n",
    "        qmeans_inv = data['qmean_invs']\n",
    "\n",
    "        # Compute qmeans_bas[2-10]\n",
    "        def compute_qbas(measure, num_samples, reference:np.ndarray):\n",
    "            random_indices = np.random.randint(0,  reference.shape[0], (reference.shape[0], num_samples))\n",
    "            random_qmeans = reference[random_indices]\n",
    "            mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "            # First way to deal with std==0; add some epsilon\n",
    "            #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "            # Second way to deal with std==0; ignore std (divide by 1)\n",
    "            std = np.std(random_qmeans, axis=1)\n",
    "            std[std==0] = 1\n",
    "\n",
    "            # Always ignore std\n",
    "            std=1\n",
    "            return (measure - mean) / std\n",
    "        for i in range(1,11):\n",
    "            # If data is genetic, compute qbas with random data from other file\n",
    "            qmeans_basX.append(compute_qbas(qmeans, i, qmeans))\n",
    "\n",
    "        # Compute z-score\n",
    "        qmean_mean = np.mean(qmeans)\n",
    "        qmean_std = np.std(qmeans)\n",
    "\n",
    "        z_scores = ((qmeans - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "        def correct_orderings_by_zscore(truths, estimators, zscore):\n",
    "            '''\n",
    "            Creates len(truth) x,y pairs and computes the fraction of them for which (truths[x]<truths[y] and estimators[x]<estimators[y]) or (truths[x]>truths[y] and estimators[x]>estimators[y])\n",
    "            Inputs:\n",
    "                - Truths & estimators contain num_elems floats\n",
    "            Output:\n",
    "                - Float representing the fraction of correctly ordered pairings\n",
    "            '''\n",
    "            xs = np.random.permutation(truths.size)\n",
    "            ys = np.random.permutation(truths.size)\n",
    "            truthX_lt_Y = truths[xs] < truths[ys]\n",
    "            estimatorX_lt_Y = estimators[xs] < estimators[ys]\n",
    "            hits = truthX_lt_Y==estimatorX_lt_Y\n",
    "            return np.hstack((hits, np.expand_dims(zscore[xs]+zscore[ys], axis=1)))\n",
    "\n",
    "        def plot_hits_vs_zindex(correct_orderings_by_zscore, name):\n",
    "            # Define y as the bin edges, here we're just using the unique y values as edges\n",
    "            y_values = correct_orderings_by_zscore[:, 1]\n",
    "\n",
    "            # The number of bins should be one less than the number of unique y values\n",
    "            # because in histogram bins are between the edges\n",
    "            bins = np.linspace(y_values.min(), y_values.max(), 50)\n",
    "\n",
    "            # Use the x values as weights and the y values to determine the bins\n",
    "            sum_hist, edges = np.histogram(y_values, bins=bins, weights=correct_orderings_by_zscore[:, 0])\n",
    "\n",
    "            # Now get the counts in each y bin to calculate the average\n",
    "            count_hist, _ = np.histogram(y_values, bins=bins)\n",
    "\n",
    "            # Avoid division by zero by replacing zero counts with NaN (or another value)\n",
    "            # This will give a NaN result for average where count is zero\n",
    "            averages = np.divide(sum_hist, count_hist, out=np.zeros_like(sum_hist), where=count_hist!=0)\n",
    "\n",
    "            # Plotting the average x values for each bin of y\n",
    "            plt.bar(edges[:-1], averages, width=np.diff(edges), edgecolor=\"black\", align=\"edge\")\n",
    "\n",
    "            plt.xlabel('z-index')\n",
    "            plt.ylabel('Hits')\n",
    "            plt.title(f'Correct pairings vs z-index ({name})')\n",
    "            plt.show()\n",
    "\n",
    "        correct_pairings_basX = []\n",
    "        for i in range(len(qmeans_basX)):\n",
    "            correct_pairings_basX = correct_orderings_by_zscore(qmeans, qmeans_basX[i], z_scores)\n",
    "            plot_hits_vs_zindex(correct_pairings_basX, f'bas{i}')\n",
    "            break\n",
    "        \n",
    "        correct_pairings_inv = correct_orderings_by_zscore(qmeans, qmeans_inv, z_scores)\n",
    "        plot_hits_vs_zindex(correct_pairings_inv, 'inv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
