{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast training\n",
    " This notebook loads the Yeast dataset (https://archive.ics.uci.edu/dataset/110/yeast), preprocesses it and trains a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(PROJ_DIR, 'assets', 'data', 'yeast.data'), delimiter=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADT1_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADT2_YEAST</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADT3_YEAST</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAR2_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AATM_YEAST</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>YUR1_YEAST</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>ME2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>ZIP1_YEAST</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>ZNRP_YEAST</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.22</td>\n",
       "      <td>ME2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>ZUO1_YEAST</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>G6PD_YEAST</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>CYT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1484 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4    5    6     7     8    9\n",
       "0     ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22  MIT\n",
       "1     ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22  MIT\n",
       "2     ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22  MIT\n",
       "3     AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22  NUC\n",
       "4     AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22  MIT\n",
       "...          ...   ...   ...   ...   ...  ...  ...   ...   ...  ...\n",
       "1479  YUR1_YEAST  0.81  0.62  0.43  0.17  0.5  0.0  0.53  0.22  ME2\n",
       "1480  ZIP1_YEAST  0.47  0.43  0.61  0.40  0.5  0.0  0.48  0.47  NUC\n",
       "1481  ZNRP_YEAST  0.67  0.57  0.36  0.19  0.5  0.0  0.56  0.22  ME2\n",
       "1482  ZUO1_YEAST  0.43  0.40  0.60  0.16  0.5  0.0  0.53  0.39  NUC\n",
       "1483  G6PD_YEAST  0.65  0.54  0.54  0.13  0.5  0.0  0.53  0.22  CYT\n",
       "\n",
       "[1484 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from CSV and save it to a suitable format. This can be skipped if concrete_data.npz is in assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MIT', 'NUC', 'CYT', 'ME1', 'EXC', 'ME2', 'ME3', 'VAC', 'POX', 'ERL']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_yeast(path):\n",
    "    df = pd.read_csv(path, delimiter=';', header=None)\n",
    "\n",
    "    labels = df[9]\n",
    "    x = df.drop(columns=0)\n",
    "    x = x.drop(columns=9)\n",
    "\n",
    "    possible_labels = labels.unique().tolist()\n",
    "    print(possible_labels)\n",
    "    print(len(possible_labels))\n",
    "    y = labels.map(lambda x: possible_labels.index(x))\n",
    "\n",
    "    return x.to_numpy(), y.to_numpy()\n",
    "    \n",
    "x, y = load_yeast(os.path.join(PROJ_DIR, 'assets', 'data', 'yeast.data'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to assets\n",
    "np.savez(os.path.join(PROJ_DIR, 'assets', 'data', 'yeast.npz'),\\\n",
    "        x_train=x_train,\\\n",
    "        x_test=x_test,\\\n",
    "        y_train=y_train,\\\n",
    "        y_test=y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = np.load(os.path.join(PROJ_DIR, 'assets', 'data', 'yeast.npz'))\n",
    "x_train = file_data['x_train']\n",
    "x_test = file_data['x_test']\n",
    "y_train = file_data['y_train']\n",
    "y_test = file_data['y_test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  6.0872,   3.4306,   3.2343,  35.9697,  40.9310,  25.8043,   9.2734,\n",
      "         59.3500,  65.9444, 237.4000])\n",
      "Epoch 0/2000 - Loss: 7.044772624969482 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 1/2000 - Loss: 6.841350078582764 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 2/2000 - Loss: 8.341196060180664 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.2861952781677246\n",
      "Epoch 3/2000 - Loss: 8.842792510986328 - Train accuracy: 0.29486098885536194 - Test accuracy: 0.2861952781677246\n",
      "Epoch 4/2000 - Loss: 8.127361297607422 - Train accuracy: 0.29233360290527344 - Test accuracy: 0.31986531615257263\n",
      "Epoch 5/2000 - Loss: 7.090317726135254 - Train accuracy: 0.31002527475357056 - Test accuracy: 0.3232323229312897\n",
      "Epoch 6/2000 - Loss: 5.84609842300415 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 7/2000 - Loss: 5.0866193771362305 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 8/2000 - Loss: 4.8344926834106445 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 9/2000 - Loss: 4.5396409034729 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 10/2000 - Loss: 4.372000217437744 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 11/2000 - Loss: 4.244926452636719 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 12/2000 - Loss: 4.146786689758301 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 13/2000 - Loss: 4.082071304321289 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3164983093738556\n",
      "Epoch 14/2000 - Loss: 4.03856897354126 - Train accuracy: 0.3142375648021698 - Test accuracy: 0.32996633648872375\n",
      "Epoch 15/2000 - Loss: 4.002471446990967 - Train accuracy: 0.31844988465309143 - Test accuracy: 0.27272728085517883\n",
      "Epoch 16/2000 - Loss: 3.9657039642333984 - Train accuracy: 0.28896376490592957 - Test accuracy: 0.2794612646102905\n",
      "Epoch 17/2000 - Loss: 3.926016330718994 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 18/2000 - Loss: 3.8851478099823 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 19/2000 - Loss: 3.8469691276550293 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 20/2000 - Loss: 3.8158881664276123 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 21/2000 - Loss: 3.795431613922119 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 22/2000 - Loss: 3.7869865894317627 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 23/2000 - Loss: 3.7889862060546875 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 24/2000 - Loss: 3.7970457077026367 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 25/2000 - Loss: 3.805412769317627 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 26/2000 - Loss: 3.809194564819336 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 27/2000 - Loss: 3.806108236312866 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 28/2000 - Loss: 3.7967894077301025 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2794612646102905\n",
      "Epoch 29/2000 - Loss: 3.783802032470703 - Train accuracy: 0.29149115085601807 - Test accuracy: 0.2760942876338959\n",
      "Epoch 30/2000 - Loss: 3.7701380252838135 - Train accuracy: 0.2906486988067627 - Test accuracy: 0.3097642958164215\n",
      "Epoch 31/2000 - Loss: 3.7580389976501465 - Train accuracy: 0.2982308268547058 - Test accuracy: 0.3333333432674408\n",
      "Epoch 32/2000 - Loss: 3.748500108718872 - Train accuracy: 0.33698397874832153 - Test accuracy: 0.31986531615257263\n",
      "Epoch 33/2000 - Loss: 3.7413833141326904 - Train accuracy: 0.32855939865112305 - Test accuracy: 0.31313130259513855\n",
      "Epoch 34/2000 - Loss: 3.735830783843994 - Train accuracy: 0.31339511275291443 - Test accuracy: 0.31986531615257263\n",
      "Epoch 35/2000 - Loss: 3.730712890625 - Train accuracy: 0.31002527475357056 - Test accuracy: 0.3232323229312897\n",
      "Epoch 36/2000 - Loss: 3.7249650955200195 - Train accuracy: 0.31002527475357056 - Test accuracy: 0.3232323229312897\n",
      "Epoch 37/2000 - Loss: 3.717804193496704 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 38/2000 - Loss: 3.708843231201172 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 39/2000 - Loss: 3.6981308460235596 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 40/2000 - Loss: 3.6861371994018555 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 41/2000 - Loss: 3.6736724376678467 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 42/2000 - Loss: 3.6616837978363037 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 43/2000 - Loss: 3.65087890625 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 44/2000 - Loss: 3.6412134170532227 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 45/2000 - Loss: 3.6317298412323 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.3232323229312897\n",
      "Epoch 46/2000 - Loss: 3.621199607849121 - Train accuracy: 0.3091828227043152 - Test accuracy: 0.31986531615257263\n",
      "Epoch 47/2000 - Loss: 3.6090972423553467 - Train accuracy: 0.3108677268028259 - Test accuracy: 0.31986531615257263\n",
      "Epoch 48/2000 - Loss: 3.5959014892578125 - Train accuracy: 0.31255266070365906 - Test accuracy: 0.31313130259513855\n",
      "Epoch 49/2000 - Loss: 3.5826077461242676 - Train accuracy: 0.31592249870300293 - Test accuracy: 0.31986531615257263\n",
      "Epoch 50/2000 - Loss: 3.57002854347229 - Train accuracy: 0.31844988465309143 - Test accuracy: 0.32996633648872375\n",
      "Epoch 51/2000 - Loss: 3.5583949089050293 - Train accuracy: 0.3319292366504669 - Test accuracy: 0.3569023609161377\n",
      "Epoch 52/2000 - Loss: 3.547396183013916 - Train accuracy: 0.34456613659858704 - Test accuracy: 0.35353535413742065\n",
      "Epoch 53/2000 - Loss: 3.5364887714385986 - Train accuracy: 0.34709352254867554 - Test accuracy: 0.3333333432674408\n",
      "Epoch 54/2000 - Loss: 3.5252277851104736 - Train accuracy: 0.3479359745979309 - Test accuracy: 0.35353535413742065\n",
      "Epoch 55/2000 - Loss: 3.5134687423706055 - Train accuracy: 0.3403538465499878 - Test accuracy: 0.3400673270225525\n",
      "Epoch 56/2000 - Loss: 3.501405954360962 - Train accuracy: 0.32350462675094604 - Test accuracy: 0.31986531615257263\n",
      "Epoch 57/2000 - Loss: 3.489431381225586 - Train accuracy: 0.32350462675094604 - Test accuracy: 0.2996633052825928\n",
      "Epoch 58/2000 - Loss: 3.4778807163238525 - Train accuracy: 0.31339511275291443 - Test accuracy: 0.28956228494644165\n",
      "Epoch 59/2000 - Loss: 3.466798782348633 - Train accuracy: 0.3142375648021698 - Test accuracy: 0.2861952781677246\n",
      "Epoch 60/2000 - Loss: 3.4558823108673096 - Train accuracy: 0.30497050285339355 - Test accuracy: 0.28282827138900757\n",
      "Epoch 61/2000 - Loss: 3.4447052478790283 - Train accuracy: 0.3007582128047943 - Test accuracy: 0.28282827138900757\n",
      "Epoch 62/2000 - Loss: 3.433060646057129 - Train accuracy: 0.29991576075553894 - Test accuracy: 0.28282827138900757\n",
      "Epoch 63/2000 - Loss: 3.421128749847412 - Train accuracy: 0.3016006648540497 - Test accuracy: 0.2861952781677246\n",
      "Epoch 64/2000 - Loss: 3.409306287765503 - Train accuracy: 0.30497050285339355 - Test accuracy: 0.2861952781677246\n",
      "Epoch 65/2000 - Loss: 3.3978724479675293 - Train accuracy: 0.31339511275291443 - Test accuracy: 0.28956228494644165\n",
      "Epoch 66/2000 - Loss: 3.386789083480835 - Train accuracy: 0.3167649507522583 - Test accuracy: 0.2929292917251587\n",
      "Epoch 67/2000 - Loss: 3.3757970333099365 - Train accuracy: 0.3167649507522583 - Test accuracy: 0.2929292917251587\n",
      "Epoch 68/2000 - Loss: 3.364698648452759 - Train accuracy: 0.31760740280151367 - Test accuracy: 0.29629629850387573\n",
      "Epoch 69/2000 - Loss: 3.3535571098327637 - Train accuracy: 0.3201347887516022 - Test accuracy: 0.29629629850387573\n",
      "Epoch 70/2000 - Loss: 3.3426353931427 - Train accuracy: 0.3218197226524353 - Test accuracy: 0.29629629850387573\n",
      "Epoch 71/2000 - Loss: 3.3321313858032227 - Train accuracy: 0.3226621747016907 - Test accuracy: 0.29629629850387573\n",
      "Epoch 72/2000 - Loss: 3.321976900100708 - Train accuracy: 0.32097724080085754 - Test accuracy: 0.2929292917251587\n",
      "Epoch 73/2000 - Loss: 3.3119308948516846 - Train accuracy: 0.32350462675094604 - Test accuracy: 0.30639731884002686\n",
      "Epoch 74/2000 - Loss: 3.301868200302124 - Train accuracy: 0.3201347887516022 - Test accuracy: 0.31986531615257263\n",
      "Epoch 75/2000 - Loss: 3.2919154167175293 - Train accuracy: 0.32603201270103455 - Test accuracy: 0.32996633648872375\n",
      "Epoch 76/2000 - Loss: 3.282277822494507 - Train accuracy: 0.3277169466018677 - Test accuracy: 0.3501683473587036\n",
      "Epoch 77/2000 - Loss: 3.2729926109313965 - Train accuracy: 0.32855939865112305 - Test accuracy: 0.3569023609161377\n",
      "Epoch 78/2000 - Loss: 3.263906240463257 - Train accuracy: 0.3251895606517792 - Test accuracy: 0.3569023609161377\n",
      "Epoch 79/2000 - Loss: 3.2548866271972656 - Train accuracy: 0.32603201270103455 - Test accuracy: 0.36026936769485474\n",
      "Epoch 80/2000 - Loss: 3.2459752559661865 - Train accuracy: 0.3268744647502899 - Test accuracy: 0.36026936769485474\n",
      "Epoch 81/2000 - Loss: 3.2373108863830566 - Train accuracy: 0.3268744647502899 - Test accuracy: 0.3569023609161377\n",
      "Epoch 82/2000 - Loss: 3.2289328575134277 - Train accuracy: 0.3268744647502899 - Test accuracy: 0.3501683473587036\n",
      "Epoch 83/2000 - Loss: 3.2207367420196533 - Train accuracy: 0.32855939865112305 - Test accuracy: 0.35353535413742065\n",
      "Epoch 84/2000 - Loss: 3.2126214504241943 - Train accuracy: 0.3302443027496338 - Test accuracy: 0.3569023609161377\n",
      "Epoch 85/2000 - Loss: 3.2046151161193848 - Train accuracy: 0.3294018507003784 - Test accuracy: 0.36026936769485474\n",
      "Epoch 86/2000 - Loss: 3.1968085765838623 - Train accuracy: 0.3294018507003784 - Test accuracy: 0.36026936769485474\n",
      "Epoch 87/2000 - Loss: 3.1892058849334717 - Train accuracy: 0.3319292366504669 - Test accuracy: 0.3569023609161377\n",
      "Epoch 88/2000 - Loss: 3.1817142963409424 - Train accuracy: 0.3327716886997223 - Test accuracy: 0.3569023609161377\n",
      "Epoch 89/2000 - Loss: 3.174257516860962 - Train accuracy: 0.3344566226005554 - Test accuracy: 0.3569023609161377\n",
      "Epoch 90/2000 - Loss: 3.166846513748169 - Train accuracy: 0.3344566226005554 - Test accuracy: 0.3569023609161377\n",
      "Epoch 91/2000 - Loss: 3.159515142440796 - Train accuracy: 0.33614152669906616 - Test accuracy: 0.3569023609161377\n",
      "Epoch 92/2000 - Loss: 3.152228593826294 - Train accuracy: 0.33614152669906616 - Test accuracy: 0.36026936769485474\n",
      "Epoch 93/2000 - Loss: 3.144909143447876 - Train accuracy: 0.33614152669906616 - Test accuracy: 0.36026936769485474\n",
      "Epoch 94/2000 - Loss: 3.1375133991241455 - Train accuracy: 0.3344566226005554 - Test accuracy: 0.3468013405799866\n",
      "Epoch 95/2000 - Loss: 3.1300530433654785 - Train accuracy: 0.3428812026977539 - Test accuracy: 0.35353535413742065\n",
      "Epoch 96/2000 - Loss: 3.1225223541259766 - Train accuracy: 0.3504633605480194 - Test accuracy: 0.34343433380126953\n",
      "Epoch 97/2000 - Loss: 3.114861249923706 - Train accuracy: 0.35467565059661865 - Test accuracy: 0.34343433380126953\n",
      "Epoch 98/2000 - Loss: 3.106994390487671 - Train accuracy: 0.3563605844974518 - Test accuracy: 0.3501683473587036\n",
      "Epoch 99/2000 - Loss: 3.09887957572937 - Train accuracy: 0.355518102645874 - Test accuracy: 0.3501683473587036\n",
      "Epoch 100/2000 - Loss: 3.090485095977783 - Train accuracy: 0.3529907464981079 - Test accuracy: 0.3501683473587036\n",
      "Epoch 101/2000 - Loss: 3.0817437171936035 - Train accuracy: 0.3513058125972748 - Test accuracy: 0.35353535413742065\n",
      "Epoch 102/2000 - Loss: 3.072547674179077 - Train accuracy: 0.3513058125972748 - Test accuracy: 0.3569023609161377\n",
      "Epoch 103/2000 - Loss: 3.062784433364868 - Train accuracy: 0.35214826464653015 - Test accuracy: 0.3569023609161377\n",
      "Epoch 104/2000 - Loss: 3.0523455142974854 - Train accuracy: 0.35214826464653015 - Test accuracy: 0.3569023609161377\n",
      "Epoch 105/2000 - Loss: 3.04109787940979 - Train accuracy: 0.3563605844974518 - Test accuracy: 0.36026936769485474\n",
      "Epoch 106/2000 - Loss: 3.0288796424865723 - Train accuracy: 0.35973042249679565 - Test accuracy: 0.36026936769485474\n",
      "Epoch 107/2000 - Loss: 3.0155417919158936 - Train accuracy: 0.3639427125453949 - Test accuracy: 0.3636363744735718\n",
      "Epoch 108/2000 - Loss: 3.0010273456573486 - Train accuracy: 0.3664700984954834 - Test accuracy: 0.3670033812522888\n",
      "Epoch 109/2000 - Loss: 2.985431671142578 - Train accuracy: 0.3689974844455719 - Test accuracy: 0.37037035822868347\n",
      "Epoch 110/2000 - Loss: 2.9690215587615967 - Train accuracy: 0.376579612493515 - Test accuracy: 0.37037035822868347\n",
      "Epoch 111/2000 - Loss: 2.9521985054016113 - Train accuracy: 0.3799494504928589 - Test accuracy: 0.3905723989009857\n",
      "Epoch 112/2000 - Loss: 2.9353654384613037 - Train accuracy: 0.38668912649154663 - Test accuracy: 0.3905723989009857\n",
      "Epoch 113/2000 - Loss: 2.9187474250793457 - Train accuracy: 0.3900589644908905 - Test accuracy: 0.3973063826560974\n",
      "Epoch 114/2000 - Loss: 2.9022762775421143 - Train accuracy: 0.392586350440979 - Test accuracy: 0.40067338943481445\n",
      "Epoch 115/2000 - Loss: 2.8856797218322754 - Train accuracy: 0.39932602643966675 - Test accuracy: 0.4107744097709656\n",
      "Epoch 116/2000 - Loss: 2.868773937225342 - Train accuracy: 0.41364786028862 - Test accuracy: 0.40740740299224854\n",
      "Epoch 117/2000 - Loss: 2.851714849472046 - Train accuracy: 0.42038753628730774 - Test accuracy: 0.4208754301071167\n",
      "Epoch 118/2000 - Loss: 2.8349225521087646 - Train accuracy: 0.4262847602367401 - Test accuracy: 0.4208754301071167\n",
      "Epoch 119/2000 - Loss: 2.818751335144043 - Train accuracy: 0.4313395023345947 - Test accuracy: 0.4343434274196625\n",
      "Epoch 120/2000 - Loss: 2.8032805919647217 - Train accuracy: 0.43639427423477173 - Test accuracy: 0.44781145453453064\n",
      "Epoch 121/2000 - Loss: 2.7884137630462646 - Train accuracy: 0.4574557840824127 - Test accuracy: 0.4579124450683594\n",
      "Epoch 122/2000 - Loss: 2.774078607559204 - Train accuracy: 0.4717775881290436 - Test accuracy: 0.4781144857406616\n",
      "Epoch 123/2000 - Loss: 2.7602970600128174 - Train accuracy: 0.48525694012641907 - Test accuracy: 0.4983164966106415\n",
      "Epoch 124/2000 - Loss: 2.7471015453338623 - Train accuracy: 0.4978938400745392 - Test accuracy: 0.5151515007019043\n",
      "Epoch 125/2000 - Loss: 2.734428882598877 - Train accuracy: 0.5071609020233154 - Test accuracy: 0.5218855142593384\n",
      "Epoch 126/2000 - Loss: 2.7221145629882812 - Train accuracy: 0.5105307698249817 - Test accuracy: 0.5252525210380554\n",
      "Epoch 127/2000 - Loss: 2.7099897861480713 - Train accuracy: 0.5088458061218262 - Test accuracy: 0.5319865345954895\n",
      "Epoch 128/2000 - Loss: 2.6979620456695557 - Train accuracy: 0.5071609020233154 - Test accuracy: 0.5319865345954895\n",
      "Epoch 129/2000 - Loss: 2.686007022857666 - Train accuracy: 0.5080033540725708 - Test accuracy: 0.5252525210380554\n",
      "Epoch 130/2000 - Loss: 2.6741104125976562 - Train accuracy: 0.5155854821205139 - Test accuracy: 0.5252525210380554\n",
      "Epoch 131/2000 - Loss: 2.6622467041015625 - Train accuracy: 0.5164279937744141 - Test accuracy: 0.5286195278167725\n",
      "Epoch 132/2000 - Loss: 2.6504218578338623 - Train accuracy: 0.5214827060699463 - Test accuracy: 0.5286195278167725\n",
      "Epoch 133/2000 - Loss: 2.6386897563934326 - Train accuracy: 0.528222382068634 - Test accuracy: 0.5353535413742065\n",
      "Epoch 134/2000 - Loss: 2.627103567123413 - Train accuracy: 0.5358045697212219 - Test accuracy: 0.5454545617103577\n",
      "Epoch 135/2000 - Loss: 2.6156575679779053 - Train accuracy: 0.543386697769165 - Test accuracy: 0.5454545617103577\n",
      "Epoch 136/2000 - Loss: 2.6043155193328857 - Train accuracy: 0.5450716018676758 - Test accuracy: 0.5488215684890747\n",
      "Epoch 137/2000 - Loss: 2.59307599067688 - Train accuracy: 0.5450716018676758 - Test accuracy: 0.5521885752677917\n",
      "Epoch 138/2000 - Loss: 2.5819878578186035 - Train accuracy: 0.5492839217185974 - Test accuracy: 0.5488215684890747\n",
      "Epoch 139/2000 - Loss: 2.5710883140563965 - Train accuracy: 0.5501263737678528 - Test accuracy: 0.5521885752677917\n",
      "Epoch 140/2000 - Loss: 2.5603396892547607 - Train accuracy: 0.5509688258171082 - Test accuracy: 0.5521885752677917\n",
      "Epoch 141/2000 - Loss: 2.5496633052825928 - Train accuracy: 0.5526537299156189 - Test accuracy: 0.5555555820465088\n",
      "Epoch 142/2000 - Loss: 2.538998603820801 - Train accuracy: 0.5526537299156189 - Test accuracy: 0.5521885752677917\n",
      "Epoch 143/2000 - Loss: 2.528332233428955 - Train accuracy: 0.5526537299156189 - Test accuracy: 0.558922529220581\n",
      "Epoch 144/2000 - Loss: 2.5176830291748047 - Train accuracy: 0.5543386936187744 - Test accuracy: 0.5622895359992981\n",
      "Epoch 145/2000 - Loss: 2.507066011428833 - Train accuracy: 0.5610783696174622 - Test accuracy: 0.5757575631141663\n",
      "Epoch 146/2000 - Loss: 2.4964888095855713 - Train accuracy: 0.5610783696174622 - Test accuracy: 0.5723905563354492\n",
      "Epoch 147/2000 - Loss: 2.485948085784912 - Train accuracy: 0.5669755935668945 - Test accuracy: 0.5757575631141663\n",
      "Epoch 148/2000 - Loss: 2.475435495376587 - Train accuracy: 0.5686604976654053 - Test accuracy: 0.5791245698928833\n",
      "Epoch 149/2000 - Loss: 2.4649431705474854 - Train accuracy: 0.570345401763916 - Test accuracy: 0.5892255902290344\n",
      "Epoch 150/2000 - Loss: 2.454479932785034 - Train accuracy: 0.5720303058624268 - Test accuracy: 0.5858585834503174\n",
      "Epoch 151/2000 - Loss: 2.4440739154815674 - Train accuracy: 0.5720303058624268 - Test accuracy: 0.5858585834503174\n",
      "Epoch 152/2000 - Loss: 2.4337399005889893 - Train accuracy: 0.5720303058624268 - Test accuracy: 0.5892255902290344\n",
      "Epoch 153/2000 - Loss: 2.4234719276428223 - Train accuracy: 0.5711878538131714 - Test accuracy: 0.5925925970077515\n",
      "Epoch 154/2000 - Loss: 2.413259744644165 - Train accuracy: 0.5779275298118591 - Test accuracy: 0.5959596037864685\n",
      "Epoch 155/2000 - Loss: 2.40311598777771 - Train accuracy: 0.5779275298118591 - Test accuracy: 0.5925925970077515\n",
      "Epoch 156/2000 - Loss: 2.393066883087158 - Train accuracy: 0.5779275298118591 - Test accuracy: 0.5892255902290344\n",
      "Epoch 157/2000 - Loss: 2.3831369876861572 - Train accuracy: 0.5745577216148376 - Test accuracy: 0.5892255902290344\n",
      "Epoch 158/2000 - Loss: 2.373340606689453 - Train accuracy: 0.575400173664093 - Test accuracy: 0.5925925970077515\n",
      "Epoch 159/2000 - Loss: 2.36368727684021 - Train accuracy: 0.5762426257133484 - Test accuracy: 0.5959596037864685\n",
      "Epoch 160/2000 - Loss: 2.3541910648345947 - Train accuracy: 0.5762426257133484 - Test accuracy: 0.5959596037864685\n",
      "Epoch 161/2000 - Loss: 2.344874858856201 - Train accuracy: 0.5762426257133484 - Test accuracy: 0.5959596037864685\n",
      "Epoch 162/2000 - Loss: 2.3357646465301514 - Train accuracy: 0.58045494556427 - Test accuracy: 0.5925925970077515\n",
      "Epoch 163/2000 - Loss: 2.3268768787384033 - Train accuracy: 0.5812973976135254 - Test accuracy: 0.5925925970077515\n",
      "Epoch 164/2000 - Loss: 2.318207263946533 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5925925970077515\n",
      "Epoch 165/2000 - Loss: 2.309744358062744 - Train accuracy: 0.5812973976135254 - Test accuracy: 0.5925925970077515\n",
      "Epoch 166/2000 - Loss: 2.301480531692505 - Train accuracy: 0.5821398496627808 - Test accuracy: 0.5858585834503174\n",
      "Epoch 167/2000 - Loss: 2.293416976928711 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5824915766716003\n",
      "Epoch 168/2000 - Loss: 2.2855536937713623 - Train accuracy: 0.5812973976135254 - Test accuracy: 0.5824915766716003\n",
      "Epoch 169/2000 - Loss: 2.2778854370117188 - Train accuracy: 0.5796124935150146 - Test accuracy: 0.5824915766716003\n",
      "Epoch 170/2000 - Loss: 2.2704098224639893 - Train accuracy: 0.5787699818611145 - Test accuracy: 0.5757575631141663\n",
      "Epoch 171/2000 - Loss: 2.2631337642669678 - Train accuracy: 0.5787699818611145 - Test accuracy: 0.5723905563354492\n",
      "Epoch 172/2000 - Loss: 2.2560617923736572 - Train accuracy: 0.5779275298118591 - Test accuracy: 0.5690235495567322\n",
      "Epoch 173/2000 - Loss: 2.2491908073425293 - Train accuracy: 0.5779275298118591 - Test accuracy: 0.5723905563354492\n",
      "Epoch 174/2000 - Loss: 2.2425143718719482 - Train accuracy: 0.58045494556427 - Test accuracy: 0.5723905563354492\n",
      "Epoch 175/2000 - Loss: 2.236027240753174 - Train accuracy: 0.5821398496627808 - Test accuracy: 0.5690235495567322\n",
      "Epoch 176/2000 - Loss: 2.2297251224517822 - Train accuracy: 0.5821398496627808 - Test accuracy: 0.5690235495567322\n",
      "Epoch 177/2000 - Loss: 2.2236032485961914 - Train accuracy: 0.5812973976135254 - Test accuracy: 0.5656565427780151\n",
      "Epoch 178/2000 - Loss: 2.217653751373291 - Train accuracy: 0.58045494556427 - Test accuracy: 0.5690235495567322\n",
      "Epoch 179/2000 - Loss: 2.211866617202759 - Train accuracy: 0.5838247537612915 - Test accuracy: 0.5690235495567322\n",
      "Epoch 180/2000 - Loss: 2.2062346935272217 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5690235495567322\n",
      "Epoch 181/2000 - Loss: 2.2007548809051514 - Train accuracy: 0.5812973976135254 - Test accuracy: 0.5723905563354492\n",
      "Epoch 182/2000 - Loss: 2.195422887802124 - Train accuracy: 0.5838247537612915 - Test accuracy: 0.5757575631141663\n",
      "Epoch 183/2000 - Loss: 2.1902339458465576 - Train accuracy: 0.5846672058105469 - Test accuracy: 0.5757575631141663\n",
      "Epoch 184/2000 - Loss: 2.185182571411133 - Train accuracy: 0.585509717464447 - Test accuracy: 0.5757575631141663\n",
      "Epoch 185/2000 - Loss: 2.1802639961242676 - Train accuracy: 0.5838247537612915 - Test accuracy: 0.5723905563354492\n",
      "Epoch 186/2000 - Loss: 2.1754720211029053 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5723905563354492\n",
      "Epoch 187/2000 - Loss: 2.170799493789673 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5690235495567322\n",
      "Epoch 188/2000 - Loss: 2.166238307952881 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5656565427780151\n",
      "Epoch 189/2000 - Loss: 2.1617846488952637 - Train accuracy: 0.5829823017120361 - Test accuracy: 0.5622895359992981\n",
      "Epoch 190/2000 - Loss: 2.157432794570923 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.5622895359992981\n",
      "Epoch 191/2000 - Loss: 2.1531779766082764 - Train accuracy: 0.585509717464447 - Test accuracy: 0.5622895359992981\n",
      "Epoch 192/2000 - Loss: 2.149014711380005 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.5622895359992981\n",
      "Epoch 193/2000 - Loss: 2.1449382305145264 - Train accuracy: 0.5871946215629578 - Test accuracy: 0.5656565427780151\n",
      "Epoch 194/2000 - Loss: 2.1409459114074707 - Train accuracy: 0.5888795256614685 - Test accuracy: 0.5656565427780151\n",
      "Epoch 195/2000 - Loss: 2.1370339393615723 - Train accuracy: 0.5897219777107239 - Test accuracy: 0.5622895359992981\n",
      "Epoch 196/2000 - Loss: 2.133197069168091 - Train accuracy: 0.5888795256614685 - Test accuracy: 0.5622895359992981\n",
      "Epoch 197/2000 - Loss: 2.1294305324554443 - Train accuracy: 0.5888795256614685 - Test accuracy: 0.558922529220581\n",
      "Epoch 198/2000 - Loss: 2.1257309913635254 - Train accuracy: 0.5880370736122131 - Test accuracy: 0.5555555820465088\n",
      "Epoch 199/2000 - Loss: 2.1220929622650146 - Train accuracy: 0.585509717464447 - Test accuracy: 0.558922529220581\n",
      "Epoch 200/2000 - Loss: 2.1185104846954346 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.558922529220581\n",
      "Epoch 201/2000 - Loss: 2.1149797439575195 - Train accuracy: 0.5846672058105469 - Test accuracy: 0.558922529220581\n",
      "Epoch 202/2000 - Loss: 2.111496686935425 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.558922529220581\n",
      "Epoch 203/2000 - Loss: 2.1080567836761475 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.558922529220581\n",
      "Epoch 204/2000 - Loss: 2.1046559810638428 - Train accuracy: 0.585509717464447 - Test accuracy: 0.558922529220581\n",
      "Epoch 205/2000 - Loss: 2.101289987564087 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.558922529220581\n",
      "Epoch 206/2000 - Loss: 2.0979559421539307 - Train accuracy: 0.585509717464447 - Test accuracy: 0.558922529220581\n",
      "Epoch 207/2000 - Loss: 2.094649314880371 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.5622895359992981\n",
      "Epoch 208/2000 - Loss: 2.091366767883301 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.5622895359992981\n",
      "Epoch 209/2000 - Loss: 2.088104724884033 - Train accuracy: 0.585509717464447 - Test accuracy: 0.5622895359992981\n",
      "Epoch 210/2000 - Loss: 2.084860324859619 - Train accuracy: 0.5863521695137024 - Test accuracy: 0.5555555820465088\n",
      "Epoch 211/2000 - Loss: 2.0816307067871094 - Train accuracy: 0.5888795256614685 - Test accuracy: 0.5555555820465088\n",
      "Epoch 212/2000 - Loss: 2.078413724899292 - Train accuracy: 0.5888795256614685 - Test accuracy: 0.558922529220581\n",
      "Epoch 213/2000 - Loss: 2.0752077102661133 - Train accuracy: 0.5897219777107239 - Test accuracy: 0.558922529220581\n",
      "Epoch 214/2000 - Loss: 2.0720102787017822 - Train accuracy: 0.5905644297599792 - Test accuracy: 0.558922529220581\n",
      "Epoch 215/2000 - Loss: 2.068821430206299 - Train accuracy: 0.5914068818092346 - Test accuracy: 0.5622895359992981\n",
      "Epoch 216/2000 - Loss: 2.0656399726867676 - Train accuracy: 0.5922493934631348 - Test accuracy: 0.5622895359992981\n",
      "Epoch 217/2000 - Loss: 2.0624656677246094 - Train accuracy: 0.5905644297599792 - Test accuracy: 0.5622895359992981\n",
      "Epoch 218/2000 - Loss: 2.0592989921569824 - Train accuracy: 0.5897219777107239 - Test accuracy: 0.5622895359992981\n",
      "Epoch 219/2000 - Loss: 2.056140899658203 - Train accuracy: 0.5897219777107239 - Test accuracy: 0.5656565427780151\n",
      "Epoch 220/2000 - Loss: 2.052992105484009 - Train accuracy: 0.5930918455123901 - Test accuracy: 0.5656565427780151\n",
      "Epoch 221/2000 - Loss: 2.0498552322387695 - Train accuracy: 0.5947767496109009 - Test accuracy: 0.5656565427780151\n",
      "Epoch 222/2000 - Loss: 2.046731948852539 - Train accuracy: 0.5939342975616455 - Test accuracy: 0.5656565427780151\n",
      "Epoch 223/2000 - Loss: 2.043625593185425 - Train accuracy: 0.5930918455123901 - Test accuracy: 0.5622895359992981\n",
      "Epoch 224/2000 - Loss: 2.040539026260376 - Train accuracy: 0.5939342975616455 - Test accuracy: 0.558922529220581\n",
      "Epoch 225/2000 - Loss: 2.0374763011932373 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 226/2000 - Loss: 2.034440040588379 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 227/2000 - Loss: 2.031435966491699 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 228/2000 - Loss: 2.0284667015075684 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 229/2000 - Loss: 2.0255370140075684 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 230/2000 - Loss: 2.022650957107544 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 231/2000 - Loss: 2.019813060760498 - Train accuracy: 0.597304105758667 - Test accuracy: 0.558922529220581\n",
      "Epoch 232/2000 - Loss: 2.017026662826538 - Train accuracy: 0.597304105758667 - Test accuracy: 0.558922529220581\n",
      "Epoch 233/2000 - Loss: 2.0142948627471924 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.558922529220581\n",
      "Epoch 234/2000 - Loss: 2.0116219520568848 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.558922529220581\n",
      "Epoch 235/2000 - Loss: 2.009009599685669 - Train accuracy: 0.597304105758667 - Test accuracy: 0.558922529220581\n",
      "Epoch 236/2000 - Loss: 2.006460666656494 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 237/2000 - Loss: 2.003976583480835 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 238/2000 - Loss: 2.001558303833008 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 239/2000 - Loss: 1.999206781387329 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.558922529220581\n",
      "Epoch 240/2000 - Loss: 1.9969218969345093 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5555555820465088\n",
      "Epoch 241/2000 - Loss: 1.9947028160095215 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.558922529220581\n",
      "Epoch 242/2000 - Loss: 1.9925495386123657 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.558922529220581\n",
      "Epoch 243/2000 - Loss: 1.9904593229293823 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5622895359992981\n",
      "Epoch 244/2000 - Loss: 1.9884308576583862 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5622895359992981\n",
      "Epoch 245/2000 - Loss: 1.986462116241455 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5622895359992981\n",
      "Epoch 246/2000 - Loss: 1.9845503568649292 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5656565427780151\n",
      "Epoch 247/2000 - Loss: 1.9826927185058594 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 248/2000 - Loss: 1.9808862209320068 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 249/2000 - Loss: 1.9791280031204224 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 250/2000 - Loss: 1.9774147272109985 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 251/2000 - Loss: 1.975743293762207 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 252/2000 - Loss: 1.9741101264953613 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 253/2000 - Loss: 1.9725133180618286 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 254/2000 - Loss: 1.9709489345550537 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 255/2000 - Loss: 1.9694147109985352 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 256/2000 - Loss: 1.9679081439971924 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 257/2000 - Loss: 1.966426968574524 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 258/2000 - Loss: 1.9649691581726074 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5690235495567322\n",
      "Epoch 259/2000 - Loss: 1.9635323286056519 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5690235495567322\n",
      "Epoch 260/2000 - Loss: 1.9621152877807617 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5690235495567322\n",
      "Epoch 261/2000 - Loss: 1.9607168436050415 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 262/2000 - Loss: 1.959335207939148 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5656565427780151\n",
      "Epoch 263/2000 - Loss: 1.9579694271087646 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5656565427780151\n",
      "Epoch 264/2000 - Loss: 1.9566190242767334 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5622895359992981\n",
      "Epoch 265/2000 - Loss: 1.95528244972229 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5622895359992981\n",
      "Epoch 266/2000 - Loss: 1.9539601802825928 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.558922529220581\n",
      "Epoch 267/2000 - Loss: 1.952650785446167 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5622895359992981\n",
      "Epoch 268/2000 - Loss: 1.951353907585144 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.558922529220581\n",
      "Epoch 269/2000 - Loss: 1.9500690698623657 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.558922529220581\n",
      "Epoch 270/2000 - Loss: 1.9487967491149902 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.558922529220581\n",
      "Epoch 271/2000 - Loss: 1.9475356340408325 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.558922529220581\n",
      "Epoch 272/2000 - Loss: 1.9462864398956299 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5656565427780151\n",
      "Epoch 273/2000 - Loss: 1.9450480937957764 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5656565427780151\n",
      "Epoch 274/2000 - Loss: 1.943820595741272 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5656565427780151\n",
      "Epoch 275/2000 - Loss: 1.9426040649414062 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5656565427780151\n",
      "Epoch 276/2000 - Loss: 1.9413979053497314 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5656565427780151\n",
      "Epoch 277/2000 - Loss: 1.940202236175537 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5656565427780151\n",
      "Epoch 278/2000 - Loss: 1.9390166997909546 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 279/2000 - Loss: 1.9378410577774048 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 280/2000 - Loss: 1.9366753101348877 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 281/2000 - Loss: 1.9355192184448242 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 282/2000 - Loss: 1.9343724250793457 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 283/2000 - Loss: 1.933234691619873 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 284/2000 - Loss: 1.9321058988571167 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5622895359992981\n",
      "Epoch 285/2000 - Loss: 1.930985927581787 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5622895359992981\n",
      "Epoch 286/2000 - Loss: 1.9298745393753052 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5622895359992981\n",
      "Epoch 287/2000 - Loss: 1.9287714958190918 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 288/2000 - Loss: 1.9276764392852783 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 289/2000 - Loss: 1.926589012145996 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 290/2000 - Loss: 1.9255098104476929 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 291/2000 - Loss: 1.924437403678894 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 292/2000 - Loss: 1.9233726263046265 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 293/2000 - Loss: 1.9223146438598633 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 294/2000 - Loss: 1.9212632179260254 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 295/2000 - Loss: 1.920218825340271 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 296/2000 - Loss: 1.919180989265442 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5622895359992981\n",
      "Epoch 297/2000 - Loss: 1.9181488752365112 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 298/2000 - Loss: 1.9171229600906372 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 299/2000 - Loss: 1.9161031246185303 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 300/2000 - Loss: 1.9150885343551636 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 301/2000 - Loss: 1.9140797853469849 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 302/2000 - Loss: 1.9130760431289673 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 303/2000 - Loss: 1.9120774269104004 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 304/2000 - Loss: 1.9110839366912842 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 305/2000 - Loss: 1.9100953340530396 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 306/2000 - Loss: 1.9091110229492188 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 307/2000 - Loss: 1.9081310033798218 - Train accuracy: 0.5956192016601562 - Test accuracy: 0.5622895359992981\n",
      "Epoch 308/2000 - Loss: 1.9071552753448486 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 309/2000 - Loss: 1.9061837196350098 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 310/2000 - Loss: 1.9052159786224365 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 311/2000 - Loss: 1.904252290725708 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5656565427780151\n",
      "Epoch 312/2000 - Loss: 1.9032917022705078 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 313/2000 - Loss: 1.9023350477218628 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 314/2000 - Loss: 1.9013808965682983 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 315/2000 - Loss: 1.9004300832748413 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5690235495567322\n",
      "Epoch 316/2000 - Loss: 1.8994821310043335 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5690235495567322\n",
      "Epoch 317/2000 - Loss: 1.8985366821289062 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5690235495567322\n",
      "Epoch 318/2000 - Loss: 1.8975940942764282 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5690235495567322\n",
      "Epoch 319/2000 - Loss: 1.8966535329818726 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5690235495567322\n",
      "Epoch 320/2000 - Loss: 1.895715594291687 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5690235495567322\n",
      "Epoch 321/2000 - Loss: 1.894779086112976 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5690235495567322\n",
      "Epoch 322/2000 - Loss: 1.893844723701477 - Train accuracy: 0.5989890694618225 - Test accuracy: 0.5656565427780151\n",
      "Epoch 323/2000 - Loss: 1.892911672592163 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 324/2000 - Loss: 1.8919800519943237 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 325/2000 - Loss: 1.8910499811172485 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 326/2000 - Loss: 1.8901206254959106 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 327/2000 - Loss: 1.8891923427581787 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 328/2000 - Loss: 1.888264775276184 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5622895359992981\n",
      "Epoch 329/2000 - Loss: 1.8873374462127686 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 330/2000 - Loss: 1.8864107131958008 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5622895359992981\n",
      "Epoch 331/2000 - Loss: 1.885483741760254 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5656565427780151\n",
      "Epoch 332/2000 - Loss: 1.8845566511154175 - Train accuracy: 0.5964616537094116 - Test accuracy: 0.5656565427780151\n",
      "Epoch 333/2000 - Loss: 1.8836294412612915 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 334/2000 - Loss: 1.8827018737792969 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 335/2000 - Loss: 1.8817733526229858 - Train accuracy: 0.597304105758667 - Test accuracy: 0.5656565427780151\n",
      "Epoch 336/2000 - Loss: 1.8808443546295166 - Train accuracy: 0.5981466174125671 - Test accuracy: 0.5656565427780151\n",
      "Epoch 337/2000 - Loss: 1.8799139261245728 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5656565427780151\n",
      "Epoch 338/2000 - Loss: 1.8789825439453125 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 339/2000 - Loss: 1.878049612045288 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 340/2000 - Loss: 1.87711501121521 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 341/2000 - Loss: 1.8761786222457886 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 342/2000 - Loss: 1.8752402067184448 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 343/2000 - Loss: 1.8742998838424683 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5690235495567322\n",
      "Epoch 344/2000 - Loss: 1.8733571767807007 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5690235495567322\n",
      "Epoch 345/2000 - Loss: 1.8724126815795898 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 346/2000 - Loss: 1.8714662790298462 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 347/2000 - Loss: 1.8705211877822876 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 348/2000 - Loss: 1.8695837259292603 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5723905563354492\n",
      "Epoch 349/2000 - Loss: 1.8686751127243042 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 350/2000 - Loss: 1.8678535223007202 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5690235495567322\n",
      "Epoch 351/2000 - Loss: 1.8673009872436523 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 352/2000 - Loss: 1.8673068284988403 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5757575631141663\n",
      "Epoch 353/2000 - Loss: 1.86836576461792 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5723905563354492\n",
      "Epoch 354/2000 - Loss: 1.8680628538131714 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5757575631141663\n",
      "Epoch 355/2000 - Loss: 1.8658310174942017 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5656565427780151\n",
      "Epoch 356/2000 - Loss: 1.862059473991394 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5723905563354492\n",
      "Epoch 357/2000 - Loss: 1.8621199131011963 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5757575631141663\n",
      "Epoch 358/2000 - Loss: 1.8632434606552124 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5690235495567322\n",
      "Epoch 359/2000 - Loss: 1.8602999448776245 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5690235495567322\n",
      "Epoch 360/2000 - Loss: 1.8581962585449219 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5723905563354492\n",
      "Epoch 361/2000 - Loss: 1.8587086200714111 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5757575631141663\n",
      "Epoch 362/2000 - Loss: 1.8576856851577759 - Train accuracy: 0.6048862934112549 - Test accuracy: 0.5690235495567322\n",
      "Epoch 363/2000 - Loss: 1.8553485870361328 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5723905563354492\n",
      "Epoch 364/2000 - Loss: 1.854767084121704 - Train accuracy: 0.6006739735603333 - Test accuracy: 0.5757575631141663\n",
      "Epoch 365/2000 - Loss: 1.8545045852661133 - Train accuracy: 0.6057287454605103 - Test accuracy: 0.5723905563354492\n",
      "Epoch 366/2000 - Loss: 1.8527470827102661 - Train accuracy: 0.5998315215110779 - Test accuracy: 0.5690235495567322\n",
      "Epoch 367/2000 - Loss: 1.851422667503357 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5757575631141663\n",
      "Epoch 368/2000 - Loss: 1.8511160612106323 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5723905563354492\n",
      "Epoch 369/2000 - Loss: 1.8500524759292603 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5723905563354492\n",
      "Epoch 370/2000 - Loss: 1.8483805656433105 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5723905563354492\n",
      "Epoch 371/2000 - Loss: 1.8477758169174194 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5723905563354492\n",
      "Epoch 372/2000 - Loss: 1.8470741510391235 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5757575631141663\n",
      "Epoch 373/2000 - Loss: 1.8454750776290894 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5723905563354492\n",
      "Epoch 374/2000 - Loss: 1.8444933891296387 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5757575631141663\n",
      "Epoch 375/2000 - Loss: 1.84385085105896 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5757575631141663\n",
      "Epoch 376/2000 - Loss: 1.8425679206848145 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5723905563354492\n",
      "Epoch 377/2000 - Loss: 1.8412827253341675 - Train accuracy: 0.6015164256095886 - Test accuracy: 0.5757575631141663\n",
      "Epoch 378/2000 - Loss: 1.8405262231826782 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5757575631141663\n",
      "Epoch 379/2000 - Loss: 1.8395097255706787 - Train accuracy: 0.6048862934112549 - Test accuracy: 0.5757575631141663\n",
      "Epoch 380/2000 - Loss: 1.8381844758987427 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5791245698928833\n",
      "Epoch 381/2000 - Loss: 1.8371880054473877 - Train accuracy: 0.6032013297080994 - Test accuracy: 0.5757575631141663\n",
      "Epoch 382/2000 - Loss: 1.8362822532653809 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5791245698928833\n",
      "Epoch 383/2000 - Loss: 1.8351155519485474 - Train accuracy: 0.6048862934112549 - Test accuracy: 0.5757575631141663\n",
      "Epoch 384/2000 - Loss: 1.8339060544967651 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5723905563354492\n",
      "Epoch 385/2000 - Loss: 1.8329493999481201 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5791245698928833\n",
      "Epoch 386/2000 - Loss: 1.8319252729415894 - Train accuracy: 0.6057287454605103 - Test accuracy: 0.5757575631141663\n",
      "Epoch 387/2000 - Loss: 1.8306913375854492 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5757575631141663\n",
      "Epoch 388/2000 - Loss: 1.8295797109603882 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5791245698928833\n",
      "Epoch 389/2000 - Loss: 1.8285692930221558 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5858585834503174\n",
      "Epoch 390/2000 - Loss: 1.827446460723877 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 391/2000 - Loss: 1.8262380361557007 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5824915766716003\n",
      "Epoch 392/2000 - Loss: 1.8251303434371948 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5858585834503174\n",
      "Epoch 393/2000 - Loss: 1.824065089225769 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5824915766716003\n",
      "Epoch 394/2000 - Loss: 1.822898268699646 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5824915766716003\n",
      "Epoch 395/2000 - Loss: 1.8217039108276367 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 396/2000 - Loss: 1.8205695152282715 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 397/2000 - Loss: 1.8194555044174194 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 398/2000 - Loss: 1.8182737827301025 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5824915766716003\n",
      "Epoch 399/2000 - Loss: 1.8170664310455322 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 400/2000 - Loss: 1.8159035444259644 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5824915766716003\n",
      "Epoch 401/2000 - Loss: 1.8147486448287964 - Train accuracy: 0.6107835173606873 - Test accuracy: 0.5824915766716003\n",
      "Epoch 402/2000 - Loss: 1.8135578632354736 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5858585834503174\n",
      "Epoch 403/2000 - Loss: 1.8123387098312378 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5858585834503174\n",
      "Epoch 404/2000 - Loss: 1.8111374378204346 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5824915766716003\n",
      "Epoch 405/2000 - Loss: 1.809954047203064 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 406/2000 - Loss: 1.808749794960022 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5858585834503174\n",
      "Epoch 407/2000 - Loss: 1.8075217008590698 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5858585834503174\n",
      "Epoch 408/2000 - Loss: 1.8062918186187744 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 409/2000 - Loss: 1.8050744533538818 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5892255902290344\n",
      "Epoch 410/2000 - Loss: 1.8038588762283325 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5892255902290344\n",
      "Epoch 411/2000 - Loss: 1.8026248216629028 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5892255902290344\n",
      "Epoch 412/2000 - Loss: 1.801378846168518 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 413/2000 - Loss: 1.800134301185608 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 414/2000 - Loss: 1.798896074295044 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5892255902290344\n",
      "Epoch 415/2000 - Loss: 1.7976576089859009 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 416/2000 - Loss: 1.796409010887146 - Train accuracy: 0.6107835173606873 - Test accuracy: 0.5892255902290344\n",
      "Epoch 417/2000 - Loss: 1.795153021812439 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 418/2000 - Loss: 1.7938956022262573 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 419/2000 - Loss: 1.7926416397094727 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 420/2000 - Loss: 1.7913906574249268 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5892255902290344\n",
      "Epoch 421/2000 - Loss: 1.790136694908142 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5892255902290344\n",
      "Epoch 422/2000 - Loss: 1.7888786792755127 - Train accuracy: 0.6057287454605103 - Test accuracy: 0.5892255902290344\n",
      "Epoch 423/2000 - Loss: 1.7876185178756714 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 424/2000 - Loss: 1.78635835647583 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 425/2000 - Loss: 1.7851008176803589 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 426/2000 - Loss: 1.783846139907837 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 427/2000 - Loss: 1.782593011856079 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 428/2000 - Loss: 1.7813403606414795 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 429/2000 - Loss: 1.780087947845459 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5892255902290344\n",
      "Epoch 430/2000 - Loss: 1.7788364887237549 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 431/2000 - Loss: 1.777586817741394 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 432/2000 - Loss: 1.7763391733169556 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 433/2000 - Loss: 1.7750943899154663 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5892255902290344\n",
      "Epoch 434/2000 - Loss: 1.7738533020019531 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5892255902290344\n",
      "Epoch 435/2000 - Loss: 1.7726150751113892 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5959596037864685\n",
      "Epoch 436/2000 - Loss: 1.7713804244995117 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 437/2000 - Loss: 1.770148754119873 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 438/2000 - Loss: 1.7689210176467896 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 439/2000 - Loss: 1.7676961421966553 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 440/2000 - Loss: 1.7664753198623657 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5925925970077515\n",
      "Epoch 441/2000 - Loss: 1.7652593851089478 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5925925970077515\n",
      "Epoch 442/2000 - Loss: 1.7640496492385864 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5925925970077515\n",
      "Epoch 443/2000 - Loss: 1.7628484964370728 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5959596037864685\n",
      "Epoch 444/2000 - Loss: 1.7616629600524902 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5925925970077515\n",
      "Epoch 445/2000 - Loss: 1.7605043649673462 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 446/2000 - Loss: 1.7594115734100342 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5925925970077515\n",
      "Epoch 447/2000 - Loss: 1.7584381103515625 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 448/2000 - Loss: 1.7578281164169312 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5925925970077515\n",
      "Epoch 449/2000 - Loss: 1.7577282190322876 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5993266105651855\n",
      "Epoch 450/2000 - Loss: 1.7594890594482422 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5959596037864685\n",
      "Epoch 451/2000 - Loss: 1.7607399225234985 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 452/2000 - Loss: 1.7642287015914917 - Train accuracy: 0.602358877658844 - Test accuracy: 0.5925925970077515\n",
      "Epoch 453/2000 - Loss: 1.7567965984344482 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5993266105651855\n",
      "Epoch 454/2000 - Loss: 1.750767707824707 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5959596037864685\n",
      "Epoch 455/2000 - Loss: 1.7498438358306885 - Train accuracy: 0.6057287454605103 - Test accuracy: 0.5858585834503174\n",
      "Epoch 456/2000 - Loss: 1.7523775100708008 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5959596037864685\n",
      "Epoch 457/2000 - Loss: 1.7530478239059448 - Train accuracy: 0.6048862934112549 - Test accuracy: 0.5959596037864685\n",
      "Epoch 458/2000 - Loss: 1.7473218441009521 - Train accuracy: 0.6116259694099426 - Test accuracy: 0.5892255902290344\n",
      "Epoch 459/2000 - Loss: 1.7450600862503052 - Train accuracy: 0.6107835173606873 - Test accuracy: 0.5959596037864685\n",
      "Epoch 460/2000 - Loss: 1.7465856075286865 - Train accuracy: 0.6065711975097656 - Test accuracy: 0.5892255902290344\n",
      "Epoch 461/2000 - Loss: 1.745835542678833 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 462/2000 - Loss: 1.7434037923812866 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5925925970077515\n",
      "Epoch 463/2000 - Loss: 1.7407679557800293 - Train accuracy: 0.607413649559021 - Test accuracy: 0.5959596037864685\n",
      "Epoch 464/2000 - Loss: 1.741200566291809 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 465/2000 - Loss: 1.7420096397399902 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5959596037864685\n",
      "Epoch 466/2000 - Loss: 1.7383865118026733 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5925925970077515\n",
      "Epoch 467/2000 - Loss: 1.7367135286331177 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5925925970077515\n",
      "Epoch 468/2000 - Loss: 1.7373379468917847 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 469/2000 - Loss: 1.7360451221466064 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5993266105651855\n",
      "Epoch 470/2000 - Loss: 1.7339744567871094 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5925925970077515\n",
      "Epoch 471/2000 - Loss: 1.7326679229736328 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5959596037864685\n",
      "Epoch 472/2000 - Loss: 1.7324525117874146 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5892255902290344\n",
      "Epoch 473/2000 - Loss: 1.7319127321243286 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5959596037864685\n",
      "Epoch 474/2000 - Loss: 1.7300162315368652 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 475/2000 - Loss: 1.7286186218261719 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5993266105651855\n",
      "Epoch 476/2000 - Loss: 1.7282010316848755 - Train accuracy: 0.6116259694099426 - Test accuracy: 0.5925925970077515\n",
      "Epoch 477/2000 - Loss: 1.7274906635284424 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5925925970077515\n",
      "Epoch 478/2000 - Loss: 1.7261686325073242 - Train accuracy: 0.6107835173606873 - Test accuracy: 0.5959596037864685\n",
      "Epoch 479/2000 - Loss: 1.7247430086135864 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5925925970077515\n",
      "Epoch 480/2000 - Loss: 1.7239192724227905 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5993266105651855\n",
      "Epoch 481/2000 - Loss: 1.7233039140701294 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 482/2000 - Loss: 1.7222955226898193 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5925925970077515\n",
      "Epoch 483/2000 - Loss: 1.7211291790008545 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5925925970077515\n",
      "Epoch 484/2000 - Loss: 1.719936490058899 - Train accuracy: 0.6082561016082764 - Test accuracy: 0.5925925970077515\n",
      "Epoch 485/2000 - Loss: 1.7190070152282715 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5925925970077515\n",
      "Epoch 486/2000 - Loss: 1.7182897329330444 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5993266105651855\n",
      "Epoch 487/2000 - Loss: 1.7174254655838013 - Train accuracy: 0.6099410057067871 - Test accuracy: 0.5925925970077515\n",
      "Epoch 488/2000 - Loss: 1.716413140296936 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 489/2000 - Loss: 1.7152361869812012 - Train accuracy: 0.6090985536575317 - Test accuracy: 0.5925925970077515\n",
      "Epoch 490/2000 - Loss: 1.7141942977905273 - Train accuracy: 0.6116259694099426 - Test accuracy: 0.5925925970077515\n",
      "Epoch 491/2000 - Loss: 1.7133052349090576 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 492/2000 - Loss: 1.712479591369629 - Train accuracy: 0.6107835173606873 - Test accuracy: 0.5959596037864685\n",
      "Epoch 493/2000 - Loss: 1.7116738557815552 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 494/2000 - Loss: 1.7107586860656738 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5993266105651855\n",
      "Epoch 495/2000 - Loss: 1.7098108530044556 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 496/2000 - Loss: 1.7087750434875488 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 497/2000 - Loss: 1.707777976989746 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 498/2000 - Loss: 1.7067980766296387 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 499/2000 - Loss: 1.7058448791503906 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5959596037864685\n",
      "Epoch 500/2000 - Loss: 1.7049099206924438 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 501/2000 - Loss: 1.7040019035339355 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5959596037864685\n",
      "Epoch 502/2000 - Loss: 1.7031147480010986 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5959596037864685\n",
      "Epoch 503/2000 - Loss: 1.7022417783737183 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5925925970077515\n",
      "Epoch 504/2000 - Loss: 1.7014025449752808 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5959596037864685\n",
      "Epoch 505/2000 - Loss: 1.700614094734192 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5993266105651855\n",
      "Epoch 506/2000 - Loss: 1.700002908706665 - Train accuracy: 0.6116259694099426 - Test accuracy: 0.5959596037864685\n",
      "Epoch 507/2000 - Loss: 1.6995545625686646 - Train accuracy: 0.6116259694099426 - Test accuracy: 0.5993266105651855\n",
      "Epoch 508/2000 - Loss: 1.7000266313552856 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5925925970077515\n",
      "Epoch 509/2000 - Loss: 1.700395107269287 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5925925970077515\n",
      "Epoch 510/2000 - Loss: 1.7040915489196777 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5959596037864685\n",
      "Epoch 511/2000 - Loss: 1.7006570100784302 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 512/2000 - Loss: 1.699534296989441 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5892255902290344\n",
      "Epoch 513/2000 - Loss: 1.6942864656448364 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5925925970077515\n",
      "Epoch 514/2000 - Loss: 1.6927714347839355 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5959596037864685\n",
      "Epoch 515/2000 - Loss: 1.6942774057388306 - Train accuracy: 0.6133108735084534 - Test accuracy: 0.5925925970077515\n",
      "Epoch 516/2000 - Loss: 1.6945022344589233 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5959596037864685\n",
      "Epoch 517/2000 - Loss: 1.6946971416473389 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5925925970077515\n",
      "Epoch 518/2000 - Loss: 1.690259337425232 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5925925970077515\n",
      "Epoch 519/2000 - Loss: 1.6885443925857544 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5993266105651855\n",
      "Epoch 520/2000 - Loss: 1.689565658569336 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 521/2000 - Loss: 1.6895923614501953 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5925925970077515\n",
      "Epoch 522/2000 - Loss: 1.6892105340957642 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5925925970077515\n",
      "Epoch 523/2000 - Loss: 1.6859501600265503 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5925925970077515\n",
      "Epoch 524/2000 - Loss: 1.6845924854278564 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5959596037864685\n",
      "Epoch 525/2000 - Loss: 1.6852391958236694 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5925925970077515\n",
      "Epoch 526/2000 - Loss: 1.6849212646484375 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5892255902290344\n",
      "Epoch 527/2000 - Loss: 1.6841758489608765 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 528/2000 - Loss: 1.6818910837173462 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5925925970077515\n",
      "Epoch 529/2000 - Loss: 1.6806493997573853 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5959596037864685\n",
      "Epoch 530/2000 - Loss: 1.6806553602218628 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5925925970077515\n",
      "Epoch 531/2000 - Loss: 1.6803117990493774 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 532/2000 - Loss: 1.6797337532043457 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5892255902290344\n",
      "Epoch 533/2000 - Loss: 1.6781116724014282 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5959596037864685\n",
      "Epoch 534/2000 - Loss: 1.6767237186431885 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5959596037864685\n",
      "Epoch 535/2000 - Loss: 1.6760706901550293 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5959596037864685\n",
      "Epoch 536/2000 - Loss: 1.6757503747940063 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5925925970077515\n",
      "Epoch 537/2000 - Loss: 1.6754624843597412 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 538/2000 - Loss: 1.6744296550750732 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5925925970077515\n",
      "Epoch 539/2000 - Loss: 1.6730656623840332 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.6026936173439026\n",
      "Epoch 540/2000 - Loss: 1.6719026565551758 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5993266105651855\n",
      "Epoch 541/2000 - Loss: 1.6712645292282104 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5925925970077515\n",
      "Epoch 542/2000 - Loss: 1.6709493398666382 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5858585834503174\n",
      "Epoch 543/2000 - Loss: 1.6704756021499634 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5925925970077515\n",
      "Epoch 544/2000 - Loss: 1.6696559190750122 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 545/2000 - Loss: 1.668474555015564 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5993266105651855\n",
      "Epoch 546/2000 - Loss: 1.667428731918335 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5925925970077515\n",
      "Epoch 547/2000 - Loss: 1.6665940284729004 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 548/2000 - Loss: 1.6659358739852905 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5959596037864685\n",
      "Epoch 549/2000 - Loss: 1.6653286218643188 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5892255902290344\n",
      "Epoch 550/2000 - Loss: 1.664690613746643 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5925925970077515\n",
      "Epoch 551/2000 - Loss: 1.6640814542770386 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 552/2000 - Loss: 1.663353681564331 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5925925970077515\n",
      "Epoch 553/2000 - Loss: 1.6626813411712646 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 554/2000 - Loss: 1.661791443824768 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 555/2000 - Loss: 1.6609582901000977 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5858585834503174\n",
      "Epoch 556/2000 - Loss: 1.6600838899612427 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5892255902290344\n",
      "Epoch 557/2000 - Loss: 1.6592968702316284 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5858585834503174\n",
      "Epoch 558/2000 - Loss: 1.6585298776626587 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5892255902290344\n",
      "Epoch 559/2000 - Loss: 1.6577699184417725 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5858585834503174\n",
      "Epoch 560/2000 - Loss: 1.6570110321044922 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 561/2000 - Loss: 1.656254768371582 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5892255902290344\n",
      "Epoch 562/2000 - Loss: 1.6555225849151611 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5892255902290344\n",
      "Epoch 563/2000 - Loss: 1.6548075675964355 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5858585834503174\n",
      "Epoch 564/2000 - Loss: 1.6540974378585815 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 565/2000 - Loss: 1.6533915996551514 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 566/2000 - Loss: 1.6526790857315063 - Train accuracy: 0.6166806817054749 - Test accuracy: 0.5925925970077515\n",
      "Epoch 567/2000 - Loss: 1.6519893407821655 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 568/2000 - Loss: 1.6513370275497437 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 569/2000 - Loss: 1.6507986783981323 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 570/2000 - Loss: 1.6504439115524292 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 571/2000 - Loss: 1.6507452726364136 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 572/2000 - Loss: 1.6517077684402466 - Train accuracy: 0.6234204173088074 - Test accuracy: 0.5892255902290344\n",
      "Epoch 573/2000 - Loss: 1.6565310955047607 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 574/2000 - Loss: 1.6576935052871704 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5791245698928833\n",
      "Epoch 575/2000 - Loss: 1.666244626045227 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 576/2000 - Loss: 1.6527928113937378 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5824915766716003\n",
      "Epoch 577/2000 - Loss: 1.6465229988098145 - Train accuracy: 0.6183656454086304 - Test accuracy: 0.5925925970077515\n",
      "Epoch 578/2000 - Loss: 1.6476855278015137 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 579/2000 - Loss: 1.6507103443145752 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5892255902290344\n",
      "Epoch 580/2000 - Loss: 1.6563607454299927 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5892255902290344\n",
      "Epoch 581/2000 - Loss: 1.6478614807128906 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5858585834503174\n",
      "Epoch 582/2000 - Loss: 1.6434870958328247 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5858585834503174\n",
      "Epoch 583/2000 - Loss: 1.6478595733642578 - Train accuracy: 0.612468421459198 - Test accuracy: 0.5892255902290344\n",
      "Epoch 584/2000 - Loss: 1.6480722427368164 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5892255902290344\n",
      "Epoch 585/2000 - Loss: 1.6462836265563965 - Train accuracy: 0.6158382296562195 - Test accuracy: 0.5892255902290344\n",
      "Epoch 586/2000 - Loss: 1.640708565711975 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5892255902290344\n",
      "Epoch 587/2000 - Loss: 1.6407262086868286 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5824915766716003\n",
      "Epoch 588/2000 - Loss: 1.6461641788482666 - Train accuracy: 0.6141533255577087 - Test accuracy: 0.5892255902290344\n",
      "Epoch 589/2000 - Loss: 1.642383098602295 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5925925970077515\n",
      "Epoch 590/2000 - Loss: 1.637465000152588 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 591/2000 - Loss: 1.6372530460357666 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5925925970077515\n",
      "Epoch 592/2000 - Loss: 1.6393152475357056 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5892255902290344\n",
      "Epoch 593/2000 - Loss: 1.6386489868164062 - Train accuracy: 0.6149957776069641 - Test accuracy: 0.5892255902290344\n",
      "Epoch 594/2000 - Loss: 1.634838342666626 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5892255902290344\n",
      "Epoch 595/2000 - Loss: 1.6342451572418213 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5824915766716003\n",
      "Epoch 596/2000 - Loss: 1.6354445219039917 - Train accuracy: 0.617523193359375 - Test accuracy: 0.5892255902290344\n",
      "Epoch 597/2000 - Loss: 1.6341590881347656 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5858585834503174\n",
      "Epoch 598/2000 - Loss: 1.6323267221450806 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5858585834503174\n",
      "Epoch 599/2000 - Loss: 1.6316750049591064 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5892255902290344\n",
      "Epoch 600/2000 - Loss: 1.6316969394683838 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5892255902290344\n",
      "Epoch 601/2000 - Loss: 1.6312289237976074 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5925925970077515\n",
      "Epoch 602/2000 - Loss: 1.6299859285354614 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 603/2000 - Loss: 1.6291762590408325 - Train accuracy: 0.6192080974578857 - Test accuracy: 0.5925925970077515\n",
      "Epoch 604/2000 - Loss: 1.6285306215286255 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5858585834503174\n",
      "Epoch 605/2000 - Loss: 1.6280461549758911 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 606/2000 - Loss: 1.6277633905410767 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 607/2000 - Loss: 1.626799464225769 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 608/2000 - Loss: 1.6257244348526 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 609/2000 - Loss: 1.6252247095108032 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5925925970077515\n",
      "Epoch 610/2000 - Loss: 1.6249938011169434 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 611/2000 - Loss: 1.6244821548461914 - Train accuracy: 0.6200505495071411 - Test accuracy: 0.5925925970077515\n",
      "Epoch 612/2000 - Loss: 1.6234065294265747 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5925925970077515\n",
      "Epoch 613/2000 - Loss: 1.622552752494812 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 614/2000 - Loss: 1.6221774816513062 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 615/2000 - Loss: 1.621745228767395 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5925925970077515\n",
      "Epoch 616/2000 - Loss: 1.6211110353469849 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5892255902290344\n",
      "Epoch 617/2000 - Loss: 1.620324730873108 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 618/2000 - Loss: 1.6196184158325195 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 619/2000 - Loss: 1.6189942359924316 - Train accuracy: 0.6217354536056519 - Test accuracy: 0.5925925970077515\n",
      "Epoch 620/2000 - Loss: 1.6183937788009644 - Train accuracy: 0.6234204173088074 - Test accuracy: 0.5925925970077515\n",
      "Epoch 621/2000 - Loss: 1.6178594827651978 - Train accuracy: 0.6208930015563965 - Test accuracy: 0.5892255902290344\n",
      "Epoch 622/2000 - Loss: 1.6173220872879028 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 623/2000 - Loss: 1.6166749000549316 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5892255902290344\n",
      "Epoch 624/2000 - Loss: 1.6159271001815796 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5925925970077515\n",
      "Epoch 625/2000 - Loss: 1.6152215003967285 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 626/2000 - Loss: 1.6146268844604492 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5892255902290344\n",
      "Epoch 627/2000 - Loss: 1.6141021251678467 - Train accuracy: 0.6225779056549072 - Test accuracy: 0.5925925970077515\n",
      "Epoch 628/2000 - Loss: 1.613533854484558 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5892255902290344\n",
      "Epoch 629/2000 - Loss: 1.6129125356674194 - Train accuracy: 0.6234204173088074 - Test accuracy: 0.5925925970077515\n",
      "Epoch 630/2000 - Loss: 1.6122965812683105 - Train accuracy: 0.6234204173088074 - Test accuracy: 0.5925925970077515\n",
      "Epoch 631/2000 - Loss: 1.611668348312378 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5925925970077515\n",
      "Epoch 632/2000 - Loss: 1.6110408306121826 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 633/2000 - Loss: 1.6103787422180176 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5925925970077515\n",
      "Epoch 634/2000 - Loss: 1.6097238063812256 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 635/2000 - Loss: 1.6091011762619019 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 636/2000 - Loss: 1.6085009574890137 - Train accuracy: 0.6242628693580627 - Test accuracy: 0.5925925970077515\n",
      "Epoch 637/2000 - Loss: 1.6079097986221313 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5892255902290344\n",
      "Epoch 638/2000 - Loss: 1.6073062419891357 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5925925970077515\n",
      "Epoch 639/2000 - Loss: 1.6067039966583252 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5892255902290344\n",
      "Epoch 640/2000 - Loss: 1.6061122417449951 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5925925970077515\n",
      "Epoch 641/2000 - Loss: 1.605544090270996 - Train accuracy: 0.6251053214073181 - Test accuracy: 0.5892255902290344\n",
      "Epoch 642/2000 - Loss: 1.604987621307373 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5925925970077515\n",
      "Epoch 643/2000 - Loss: 1.6044692993164062 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5892255902290344\n",
      "Epoch 644/2000 - Loss: 1.6039600372314453 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5925925970077515\n",
      "Epoch 645/2000 - Loss: 1.6036068201065063 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5925925970077515\n",
      "Epoch 646/2000 - Loss: 1.6032887697219849 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5959596037864685\n",
      "Epoch 647/2000 - Loss: 1.6035170555114746 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5892255902290344\n",
      "Epoch 648/2000 - Loss: 1.6035425662994385 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 649/2000 - Loss: 1.6052367687225342 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5993266105651855\n",
      "Epoch 650/2000 - Loss: 1.604885458946228 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5892255902290344\n",
      "Epoch 651/2000 - Loss: 1.6077476739883423 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5959596037864685\n",
      "Epoch 652/2000 - Loss: 1.6041831970214844 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5925925970077515\n",
      "Epoch 653/2000 - Loss: 1.6031042337417603 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5925925970077515\n",
      "Epoch 654/2000 - Loss: 1.5995779037475586 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 655/2000 - Loss: 1.5976324081420898 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5892255902290344\n",
      "Epoch 656/2000 - Loss: 1.5966442823410034 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5925925970077515\n",
      "Epoch 657/2000 - Loss: 1.5963729619979858 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5959596037864685\n",
      "Epoch 658/2000 - Loss: 1.5967483520507812 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5925925970077515\n",
      "Epoch 659/2000 - Loss: 1.596757173538208 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 660/2000 - Loss: 1.5975450277328491 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5959596037864685\n",
      "Epoch 661/2000 - Loss: 1.5965481996536255 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 662/2000 - Loss: 1.5960240364074707 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5959596037864685\n",
      "Epoch 663/2000 - Loss: 1.5943344831466675 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 664/2000 - Loss: 1.5927159786224365 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5925925970077515\n",
      "Epoch 665/2000 - Loss: 1.5912898778915405 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 666/2000 - Loss: 1.5903165340423584 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5892255902290344\n",
      "Epoch 667/2000 - Loss: 1.5898479223251343 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5925925970077515\n",
      "Epoch 668/2000 - Loss: 1.5897157192230225 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5959596037864685\n",
      "Epoch 669/2000 - Loss: 1.5897753238677979 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5959596037864685\n",
      "Epoch 670/2000 - Loss: 1.5896321535110474 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5959596037864685\n",
      "Epoch 671/2000 - Loss: 1.5895274877548218 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5959596037864685\n",
      "Epoch 672/2000 - Loss: 1.5887516736984253 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5959596037864685\n",
      "Epoch 673/2000 - Loss: 1.588263988494873 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5925925970077515\n",
      "Epoch 674/2000 - Loss: 1.5870519876480103 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5959596037864685\n",
      "Epoch 675/2000 - Loss: 1.5862853527069092 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5925925970077515\n",
      "Epoch 676/2000 - Loss: 1.585160255432129 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5959596037864685\n",
      "Epoch 677/2000 - Loss: 1.584359884262085 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5925925970077515\n",
      "Epoch 678/2000 - Loss: 1.5834654569625854 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 679/2000 - Loss: 1.582694411277771 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5925925970077515\n",
      "Epoch 680/2000 - Loss: 1.5819458961486816 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 681/2000 - Loss: 1.5812593698501587 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 682/2000 - Loss: 1.5806210041046143 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 683/2000 - Loss: 1.58003568649292 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5925925970077515\n",
      "Epoch 684/2000 - Loss: 1.5795073509216309 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 685/2000 - Loss: 1.5790246725082397 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5959596037864685\n",
      "Epoch 686/2000 - Loss: 1.578660249710083 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5892255902290344\n",
      "Epoch 687/2000 - Loss: 1.578334927558899 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5993266105651855\n",
      "Epoch 688/2000 - Loss: 1.5784273147583008 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5925925970077515\n",
      "Epoch 689/2000 - Loss: 1.578399419784546 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5959596037864685\n",
      "Epoch 690/2000 - Loss: 1.5797208547592163 - Train accuracy: 0.6259477734565735 - Test accuracy: 0.5892255902290344\n",
      "Epoch 691/2000 - Loss: 1.5797230005264282 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5858585834503174\n",
      "Epoch 692/2000 - Loss: 1.5827170610427856 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5858585834503174\n",
      "Epoch 693/2000 - Loss: 1.5805009603500366 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5858585834503174\n",
      "Epoch 694/2000 - Loss: 1.581264853477478 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5892255902290344\n",
      "Epoch 695/2000 - Loss: 1.5779259204864502 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5858585834503174\n",
      "Epoch 696/2000 - Loss: 1.5764532089233398 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5858585834503174\n",
      "Epoch 697/2000 - Loss: 1.5761808156967163 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5892255902290344\n",
      "Epoch 698/2000 - Loss: 1.5748555660247803 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5925925970077515\n",
      "Epoch 699/2000 - Loss: 1.5741407871246338 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5892255902290344\n",
      "Epoch 700/2000 - Loss: 1.5720463991165161 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5959596037864685\n",
      "Epoch 701/2000 - Loss: 1.571269154548645 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5892255902290344\n",
      "Epoch 702/2000 - Loss: 1.5706403255462646 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5959596037864685\n",
      "Epoch 703/2000 - Loss: 1.5712357759475708 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5858585834503174\n",
      "Epoch 704/2000 - Loss: 1.5712833404541016 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 705/2000 - Loss: 1.5701000690460205 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5892255902290344\n",
      "Epoch 706/2000 - Loss: 1.5683053731918335 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5925925970077515\n",
      "Epoch 707/2000 - Loss: 1.5660641193389893 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5892255902290344\n",
      "Epoch 708/2000 - Loss: 1.564888834953308 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 709/2000 - Loss: 1.5648694038391113 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5959596037864685\n",
      "Epoch 710/2000 - Loss: 1.56522536277771 - Train accuracy: 0.6284751296043396 - Test accuracy: 0.5892255902290344\n",
      "Epoch 711/2000 - Loss: 1.5652776956558228 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5959596037864685\n",
      "Epoch 712/2000 - Loss: 1.5644267797470093 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5892255902290344\n",
      "Epoch 713/2000 - Loss: 1.563279628753662 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5959596037864685\n",
      "Epoch 714/2000 - Loss: 1.5625824928283691 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5925925970077515\n",
      "Epoch 715/2000 - Loss: 1.5620067119598389 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 716/2000 - Loss: 1.5620580911636353 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5959596037864685\n",
      "Epoch 717/2000 - Loss: 1.5614365339279175 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 718/2000 - Loss: 1.5608285665512085 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5959596037864685\n",
      "Epoch 719/2000 - Loss: 1.5595149993896484 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 720/2000 - Loss: 1.5585774183273315 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5925925970077515\n",
      "Epoch 721/2000 - Loss: 1.5577504634857178 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 722/2000 - Loss: 1.5573463439941406 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5892255902290344\n",
      "Epoch 723/2000 - Loss: 1.556926965713501 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 724/2000 - Loss: 1.5564485788345337 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5892255902290344\n",
      "Epoch 725/2000 - Loss: 1.5557911396026611 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 726/2000 - Loss: 1.5550930500030518 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5892255902290344\n",
      "Epoch 727/2000 - Loss: 1.5543644428253174 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 728/2000 - Loss: 1.5540223121643066 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5892255902290344\n",
      "Epoch 729/2000 - Loss: 1.5536353588104248 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 730/2000 - Loss: 1.5539569854736328 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5892255902290344\n",
      "Epoch 731/2000 - Loss: 1.55360746383667 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 732/2000 - Loss: 1.5544439554214478 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5824915766716003\n",
      "Epoch 733/2000 - Loss: 1.5534944534301758 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 734/2000 - Loss: 1.5541770458221436 - Train accuracy: 0.6267902255058289 - Test accuracy: 0.5791245698928833\n",
      "Epoch 735/2000 - Loss: 1.5522719621658325 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 736/2000 - Loss: 1.551853060722351 - Train accuracy: 0.6301600933074951 - Test accuracy: 0.5791245698928833\n",
      "Epoch 737/2000 - Loss: 1.5498822927474976 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 738/2000 - Loss: 1.548885703086853 - Train accuracy: 0.6310025453567505 - Test accuracy: 0.5858585834503174\n",
      "Epoch 739/2000 - Loss: 1.5478572845458984 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 740/2000 - Loss: 1.547015905380249 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5892255902290344\n",
      "Epoch 741/2000 - Loss: 1.5463751554489136 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5925925970077515\n",
      "Epoch 742/2000 - Loss: 1.5454050302505493 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 743/2000 - Loss: 1.5445342063903809 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5993266105651855\n",
      "Epoch 744/2000 - Loss: 1.543557047843933 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 745/2000 - Loss: 1.5427476167678833 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 746/2000 - Loss: 1.5420700311660767 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 747/2000 - Loss: 1.541603922843933 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5892255902290344\n",
      "Epoch 748/2000 - Loss: 1.541276454925537 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 749/2000 - Loss: 1.5411587953567505 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5858585834503174\n",
      "Epoch 750/2000 - Loss: 1.5411700010299683 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 751/2000 - Loss: 1.5414232015609741 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5791245698928833\n",
      "Epoch 752/2000 - Loss: 1.541754961013794 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5892255902290344\n",
      "Epoch 753/2000 - Loss: 1.542647123336792 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5824915766716003\n",
      "Epoch 754/2000 - Loss: 1.542781949043274 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5892255902290344\n",
      "Epoch 755/2000 - Loss: 1.5442993640899658 - Train accuracy: 0.6276326775550842 - Test accuracy: 0.5892255902290344\n",
      "Epoch 756/2000 - Loss: 1.5422172546386719 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5892255902290344\n",
      "Epoch 757/2000 - Loss: 1.5419994592666626 - Train accuracy: 0.629317581653595 - Test accuracy: 0.5791245698928833\n",
      "Epoch 758/2000 - Loss: 1.5380687713623047 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5959596037864685\n",
      "Epoch 759/2000 - Loss: 1.5358844995498657 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5892255902290344\n",
      "Epoch 760/2000 - Loss: 1.5338739156723022 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5892255902290344\n",
      "Epoch 761/2000 - Loss: 1.532963752746582 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5959596037864685\n",
      "Epoch 762/2000 - Loss: 1.5327916145324707 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5824915766716003\n",
      "Epoch 763/2000 - Loss: 1.5330747365951538 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 764/2000 - Loss: 1.533647060394287 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5791245698928833\n",
      "Epoch 765/2000 - Loss: 1.5335630178451538 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5925925970077515\n",
      "Epoch 766/2000 - Loss: 1.5339360237121582 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5791245698928833\n",
      "Epoch 767/2000 - Loss: 1.532336950302124 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5959596037864685\n",
      "Epoch 768/2000 - Loss: 1.5313798189163208 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5858585834503174\n",
      "Epoch 769/2000 - Loss: 1.5293244123458862 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5959596037864685\n",
      "Epoch 770/2000 - Loss: 1.5279144048690796 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5892255902290344\n",
      "Epoch 771/2000 - Loss: 1.5267925262451172 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5892255902290344\n",
      "Epoch 772/2000 - Loss: 1.5261174440383911 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 773/2000 - Loss: 1.525774359703064 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5892255902290344\n",
      "Epoch 774/2000 - Loss: 1.5256134271621704 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5959596037864685\n",
      "Epoch 775/2000 - Loss: 1.5256476402282715 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5824915766716003\n",
      "Epoch 776/2000 - Loss: 1.5254513025283813 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5959596037864685\n",
      "Epoch 777/2000 - Loss: 1.525560975074768 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5892255902290344\n",
      "Epoch 778/2000 - Loss: 1.524994134902954 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5959596037864685\n",
      "Epoch 779/2000 - Loss: 1.524812936782837 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5892255902290344\n",
      "Epoch 780/2000 - Loss: 1.5239248275756836 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5959596037864685\n",
      "Epoch 781/2000 - Loss: 1.5233097076416016 - Train accuracy: 0.6335299015045166 - Test accuracy: 0.5892255902290344\n",
      "Epoch 782/2000 - Loss: 1.5224616527557373 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5959596037864685\n",
      "Epoch 783/2000 - Loss: 1.5216206312179565 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5892255902290344\n",
      "Epoch 784/2000 - Loss: 1.5209711790084839 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 785/2000 - Loss: 1.5200673341751099 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 786/2000 - Loss: 1.5194766521453857 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 787/2000 - Loss: 1.5185290575027466 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5892255902290344\n",
      "Epoch 788/2000 - Loss: 1.5178581476211548 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5925925970077515\n",
      "Epoch 789/2000 - Loss: 1.516983985900879 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5892255902290344\n",
      "Epoch 790/2000 - Loss: 1.5163995027542114 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5892255902290344\n",
      "Epoch 791/2000 - Loss: 1.515787124633789 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5925925970077515\n",
      "Epoch 792/2000 - Loss: 1.5156272649765015 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5892255902290344\n",
      "Epoch 793/2000 - Loss: 1.5152679681777954 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5892255902290344\n",
      "Epoch 794/2000 - Loss: 1.5157945156097412 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5892255902290344\n",
      "Epoch 795/2000 - Loss: 1.5153142213821411 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5892255902290344\n",
      "Epoch 796/2000 - Loss: 1.516356348991394 - Train accuracy: 0.6318449974060059 - Test accuracy: 0.5892255902290344\n",
      "Epoch 797/2000 - Loss: 1.5151137113571167 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5925925970077515\n",
      "Epoch 798/2000 - Loss: 1.5156707763671875 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5892255902290344\n",
      "Epoch 799/2000 - Loss: 1.5135153532028198 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 800/2000 - Loss: 1.5127887725830078 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 801/2000 - Loss: 1.5105829238891602 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 802/2000 - Loss: 1.5092264413833618 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5925925970077515\n",
      "Epoch 803/2000 - Loss: 1.5078942775726318 - Train accuracy: 0.6326874494552612 - Test accuracy: 0.5925925970077515\n",
      "Epoch 804/2000 - Loss: 1.5070648193359375 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 805/2000 - Loss: 1.5066807270050049 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5959596037864685\n",
      "Epoch 806/2000 - Loss: 1.5066230297088623 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 807/2000 - Loss: 1.507082223892212 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5959596037864685\n",
      "Epoch 808/2000 - Loss: 1.507543921470642 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5959596037864685\n",
      "Epoch 809/2000 - Loss: 1.5090919733047485 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5925925970077515\n",
      "Epoch 810/2000 - Loss: 1.5094423294067383 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5959596037864685\n",
      "Epoch 811/2000 - Loss: 1.5115413665771484 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5858585834503174\n",
      "Epoch 812/2000 - Loss: 1.509355902671814 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5959596037864685\n",
      "Epoch 813/2000 - Loss: 1.508537769317627 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 814/2000 - Loss: 1.5043103694915771 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 815/2000 - Loss: 1.5017458200454712 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 816/2000 - Loss: 1.5003455877304077 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 817/2000 - Loss: 1.5001246929168701 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 818/2000 - Loss: 1.5007083415985107 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 819/2000 - Loss: 1.5007083415985107 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 820/2000 - Loss: 1.5007896423339844 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5925925970077515\n",
      "Epoch 821/2000 - Loss: 1.499348521232605 - Train accuracy: 0.6368997693061829 - Test accuracy: 0.5959596037864685\n",
      "Epoch 822/2000 - Loss: 1.498449683189392 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5993266105651855\n",
      "Epoch 823/2000 - Loss: 1.496933937072754 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5993266105651855\n",
      "Epoch 824/2000 - Loss: 1.4960081577301025 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.5993266105651855\n",
      "Epoch 825/2000 - Loss: 1.495208501815796 - Train accuracy: 0.6352148056030273 - Test accuracy: 0.5993266105651855\n",
      "Epoch 826/2000 - Loss: 1.4947402477264404 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5993266105651855\n",
      "Epoch 827/2000 - Loss: 1.4946742057800293 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 828/2000 - Loss: 1.494563341140747 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5993266105651855\n",
      "Epoch 829/2000 - Loss: 1.4943128824234009 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5959596037864685\n",
      "Epoch 830/2000 - Loss: 1.4943063259124756 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 831/2000 - Loss: 1.4929962158203125 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5959596037864685\n",
      "Epoch 832/2000 - Loss: 1.4927066564559937 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5925925970077515\n",
      "Epoch 833/2000 - Loss: 1.4918544292449951 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5993266105651855\n",
      "Epoch 834/2000 - Loss: 1.4927295446395874 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5925925970077515\n",
      "Epoch 835/2000 - Loss: 1.4928041696548462 - Train accuracy: 0.6402695775032043 - Test accuracy: 0.5959596037864685\n",
      "Epoch 836/2000 - Loss: 1.495370864868164 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5925925970077515\n",
      "Epoch 837/2000 - Loss: 1.493044137954712 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5959596037864685\n",
      "Epoch 838/2000 - Loss: 1.4934018850326538 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 839/2000 - Loss: 1.490506649017334 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5959596037864685\n",
      "Epoch 840/2000 - Loss: 1.490180253982544 - Train accuracy: 0.6402695775032043 - Test accuracy: 0.5993266105651855\n",
      "Epoch 841/2000 - Loss: 1.4882251024246216 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.5959596037864685\n",
      "Epoch 842/2000 - Loss: 1.4872206449508667 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 843/2000 - Loss: 1.4855083227157593 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.6060606241226196\n",
      "Epoch 844/2000 - Loss: 1.484091877937317 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.6026936173439026\n",
      "Epoch 845/2000 - Loss: 1.4832799434661865 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5993266105651855\n",
      "Epoch 846/2000 - Loss: 1.4829187393188477 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6060606241226196\n",
      "Epoch 847/2000 - Loss: 1.483170986175537 - Train accuracy: 0.6402695775032043 - Test accuracy: 0.5993266105651855\n",
      "Epoch 848/2000 - Loss: 1.4828290939331055 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6060606241226196\n",
      "Epoch 849/2000 - Loss: 1.48322331905365 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 850/2000 - Loss: 1.4822673797607422 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 851/2000 - Loss: 1.4819965362548828 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5925925970077515\n",
      "Epoch 852/2000 - Loss: 1.4812970161437988 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 853/2000 - Loss: 1.480894923210144 - Train accuracy: 0.6385846734046936 - Test accuracy: 0.5959596037864685\n",
      "Epoch 854/2000 - Loss: 1.4801368713378906 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 855/2000 - Loss: 1.4794546365737915 - Train accuracy: 0.6402695775032043 - Test accuracy: 0.5959596037864685\n",
      "Epoch 856/2000 - Loss: 1.4782044887542725 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 857/2000 - Loss: 1.477086067199707 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 858/2000 - Loss: 1.475862979888916 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6026936173439026\n",
      "Epoch 859/2000 - Loss: 1.47487211227417 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 860/2000 - Loss: 1.4740849733352661 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5993266105651855\n",
      "Epoch 861/2000 - Loss: 1.473499059677124 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 862/2000 - Loss: 1.4730308055877686 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.5993266105651855\n",
      "Epoch 863/2000 - Loss: 1.4726295471191406 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 864/2000 - Loss: 1.4722007513046265 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 865/2000 - Loss: 1.4717479944229126 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 866/2000 - Loss: 1.4712318181991577 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 867/2000 - Loss: 1.4706891775131226 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 868/2000 - Loss: 1.4701206684112549 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 869/2000 - Loss: 1.4695994853973389 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 870/2000 - Loss: 1.4690992832183838 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 871/2000 - Loss: 1.4688098430633545 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 872/2000 - Loss: 1.4686166048049927 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 873/2000 - Loss: 1.4690265655517578 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 874/2000 - Loss: 1.469866394996643 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 875/2000 - Loss: 1.47174072265625 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 876/2000 - Loss: 1.4750220775604248 - Train accuracy: 0.6360572576522827 - Test accuracy: 0.5925925970077515\n",
      "Epoch 877/2000 - Loss: 1.4755431413650513 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5925925970077515\n",
      "Epoch 878/2000 - Loss: 1.4775495529174805 - Train accuracy: 0.634372353553772 - Test accuracy: 0.5959596037864685\n",
      "Epoch 879/2000 - Loss: 1.4718506336212158 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 880/2000 - Loss: 1.471425175666809 - Train accuracy: 0.6377422213554382 - Test accuracy: 0.5925925970077515\n",
      "Epoch 881/2000 - Loss: 1.4677482843399048 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 882/2000 - Loss: 1.4691765308380127 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5959596037864685\n",
      "Epoch 883/2000 - Loss: 1.4672409296035767 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 884/2000 - Loss: 1.4667636156082153 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 885/2000 - Loss: 1.4634180068969727 - Train accuracy: 0.639427125453949 - Test accuracy: 0.5959596037864685\n",
      "Epoch 886/2000 - Loss: 1.4613234996795654 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6060606241226196\n",
      "Epoch 887/2000 - Loss: 1.46122145652771 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 888/2000 - Loss: 1.461710810661316 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 889/2000 - Loss: 1.4636391401290894 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 890/2000 - Loss: 1.4617583751678467 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 891/2000 - Loss: 1.460038423538208 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 892/2000 - Loss: 1.4574432373046875 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 893/2000 - Loss: 1.4566285610198975 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 894/2000 - Loss: 1.4570934772491455 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 895/2000 - Loss: 1.4585694074630737 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 896/2000 - Loss: 1.4575622081756592 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 897/2000 - Loss: 1.4562948942184448 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 898/2000 - Loss: 1.4538483619689941 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 899/2000 - Loss: 1.4525260925292969 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 900/2000 - Loss: 1.4522298574447632 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 901/2000 - Loss: 1.4526126384735107 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 902/2000 - Loss: 1.4525295495986938 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 903/2000 - Loss: 1.4521703720092773 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 904/2000 - Loss: 1.4508070945739746 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 905/2000 - Loss: 1.4495548009872437 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 906/2000 - Loss: 1.448562741279602 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 907/2000 - Loss: 1.448089838027954 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 908/2000 - Loss: 1.4479578733444214 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 909/2000 - Loss: 1.4478510618209839 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 910/2000 - Loss: 1.4475268125534058 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 911/2000 - Loss: 1.4469316005706787 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 912/2000 - Loss: 1.446090817451477 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 913/2000 - Loss: 1.445412516593933 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 914/2000 - Loss: 1.4448509216308594 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 915/2000 - Loss: 1.445008397102356 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 916/2000 - Loss: 1.4455255270004272 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 917/2000 - Loss: 1.4481412172317505 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5925925970077515\n",
      "Epoch 918/2000 - Loss: 1.4498366117477417 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 919/2000 - Loss: 1.4584906101226807 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 920/2000 - Loss: 1.453566312789917 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 921/2000 - Loss: 1.4564419984817505 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 922/2000 - Loss: 1.4461965560913086 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 923/2000 - Loss: 1.4417297840118408 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 924/2000 - Loss: 1.4395716190338135 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 925/2000 - Loss: 1.4403959512710571 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 926/2000 - Loss: 1.444294810295105 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5925925970077515\n",
      "Epoch 927/2000 - Loss: 1.4438892602920532 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 928/2000 - Loss: 1.4460269212722778 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 929/2000 - Loss: 1.4408982992172241 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 930/2000 - Loss: 1.4381945133209229 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 931/2000 - Loss: 1.4359599351882935 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 932/2000 - Loss: 1.435774564743042 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 933/2000 - Loss: 1.4368939399719238 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5959596037864685\n",
      "Epoch 934/2000 - Loss: 1.4373528957366943 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6026936173439026\n",
      "Epoch 935/2000 - Loss: 1.437854290008545 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5925925970077515\n",
      "Epoch 936/2000 - Loss: 1.4354149103164673 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 937/2000 - Loss: 1.4334774017333984 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 938/2000 - Loss: 1.4318591356277466 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 939/2000 - Loss: 1.4313572645187378 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 940/2000 - Loss: 1.4316712617874146 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 941/2000 - Loss: 1.431930661201477 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 942/2000 - Loss: 1.43223237991333 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 943/2000 - Loss: 1.4314208030700684 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 944/2000 - Loss: 1.4307398796081543 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 945/2000 - Loss: 1.4297237396240234 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5925925970077515\n",
      "Epoch 946/2000 - Loss: 1.4294898509979248 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 947/2000 - Loss: 1.4298354387283325 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 948/2000 - Loss: 1.4310187101364136 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 949/2000 - Loss: 1.4343886375427246 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5925925970077515\n",
      "Epoch 950/2000 - Loss: 1.4344886541366577 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 951/2000 - Loss: 1.438218116760254 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 952/2000 - Loss: 1.4331598281860352 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 953/2000 - Loss: 1.4292457103729248 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5925925970077515\n",
      "Epoch 954/2000 - Loss: 1.4261040687561035 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 955/2000 - Loss: 1.4239952564239502 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 956/2000 - Loss: 1.4237929582595825 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 957/2000 - Loss: 1.4245796203613281 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 958/2000 - Loss: 1.4266804456710815 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5925925970077515\n",
      "Epoch 959/2000 - Loss: 1.4264169931411743 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 960/2000 - Loss: 1.4258997440338135 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5925925970077515\n",
      "Epoch 961/2000 - Loss: 1.4235271215438843 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 962/2000 - Loss: 1.4211112260818481 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 963/2000 - Loss: 1.4193956851959229 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5959596037864685\n",
      "Epoch 964/2000 - Loss: 1.4188623428344727 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 965/2000 - Loss: 1.419150471687317 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5925925970077515\n",
      "Epoch 966/2000 - Loss: 1.4195654392242432 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 967/2000 - Loss: 1.4197601079940796 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 968/2000 - Loss: 1.4191365242004395 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 969/2000 - Loss: 1.4187489748001099 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 970/2000 - Loss: 1.4173660278320312 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 971/2000 - Loss: 1.4169251918792725 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 972/2000 - Loss: 1.4158096313476562 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 973/2000 - Loss: 1.4150632619857788 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5925925970077515\n",
      "Epoch 974/2000 - Loss: 1.4141677618026733 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 975/2000 - Loss: 1.413411259651184 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5959596037864685\n",
      "Epoch 976/2000 - Loss: 1.4128544330596924 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 977/2000 - Loss: 1.4125334024429321 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 978/2000 - Loss: 1.4124891757965088 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 979/2000 - Loss: 1.41228449344635 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 980/2000 - Loss: 1.4124581813812256 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5925925970077515\n",
      "Epoch 981/2000 - Loss: 1.4118233919143677 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 982/2000 - Loss: 1.4118614196777344 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 983/2000 - Loss: 1.4108573198318481 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 984/2000 - Loss: 1.4106500148773193 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 985/2000 - Loss: 1.4098936319351196 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 986/2000 - Loss: 1.4096626043319702 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 987/2000 - Loss: 1.4091839790344238 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 988/2000 - Loss: 1.408819317817688 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 989/2000 - Loss: 1.4082412719726562 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5925925970077515\n",
      "Epoch 990/2000 - Loss: 1.4078352451324463 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 991/2000 - Loss: 1.4071868658065796 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5959596037864685\n",
      "Epoch 992/2000 - Loss: 1.4071695804595947 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 993/2000 - Loss: 1.4064382314682007 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 994/2000 - Loss: 1.406729817390442 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 995/2000 - Loss: 1.4056161642074585 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5959596037864685\n",
      "Epoch 996/2000 - Loss: 1.4056156873703003 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 997/2000 - Loss: 1.4043601751327515 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 998/2000 - Loss: 1.4039809703826904 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 999/2000 - Loss: 1.40318763256073 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1000/2000 - Loss: 1.4028743505477905 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1001/2000 - Loss: 1.4027457237243652 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1002/2000 - Loss: 1.4027172327041626 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1003/2000 - Loss: 1.4034653902053833 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1004/2000 - Loss: 1.4038970470428467 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1005/2000 - Loss: 1.4066001176834106 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1006/2000 - Loss: 1.4064719676971436 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1007/2000 - Loss: 1.4107930660247803 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1008/2000 - Loss: 1.4058845043182373 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1009/2000 - Loss: 1.405243158340454 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1010/2000 - Loss: 1.400365948677063 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1011/2000 - Loss: 1.3987382650375366 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1012/2000 - Loss: 1.3978888988494873 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1013/2000 - Loss: 1.3998013734817505 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1014/2000 - Loss: 1.398637294769287 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1015/2000 - Loss: 1.4001003503799438 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1016/2000 - Loss: 1.3983709812164307 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1017/2000 - Loss: 1.3968144655227661 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1018/2000 - Loss: 1.3951736688613892 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1019/2000 - Loss: 1.3930094242095947 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1020/2000 - Loss: 1.3916089534759521 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1021/2000 - Loss: 1.3911648988723755 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1022/2000 - Loss: 1.3915088176727295 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1023/2000 - Loss: 1.392199993133545 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1024/2000 - Loss: 1.3921927213668823 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1025/2000 - Loss: 1.3918719291687012 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1026/2000 - Loss: 1.391005039215088 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1027/2000 - Loss: 1.3898553848266602 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1028/2000 - Loss: 1.3897221088409424 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1029/2000 - Loss: 1.3890492916107178 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1030/2000 - Loss: 1.3898868560791016 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1031/2000 - Loss: 1.3900907039642334 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1032/2000 - Loss: 1.3933883905410767 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1033/2000 - Loss: 1.3940675258636475 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1034/2000 - Loss: 1.4021118879318237 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1035/2000 - Loss: 1.3955234289169312 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1036/2000 - Loss: 1.3970813751220703 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1037/2000 - Loss: 1.389065146446228 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1038/2000 - Loss: 1.386291265487671 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1039/2000 - Loss: 1.383231282234192 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1040/2000 - Loss: 1.3825078010559082 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1041/2000 - Loss: 1.3834084272384644 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1042/2000 - Loss: 1.384637475013733 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1043/2000 - Loss: 1.3872841596603394 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1044/2000 - Loss: 1.3863825798034668 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1045/2000 - Loss: 1.3879461288452148 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1046/2000 - Loss: 1.383991003036499 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1047/2000 - Loss: 1.3827239274978638 - Train accuracy: 0.6402695775032043 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1048/2000 - Loss: 1.3801237344741821 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1049/2000 - Loss: 1.3790216445922852 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1050/2000 - Loss: 1.3786535263061523 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1051/2000 - Loss: 1.3787444829940796 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1052/2000 - Loss: 1.3795597553253174 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1053/2000 - Loss: 1.3794020414352417 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1054/2000 - Loss: 1.3801392316818237 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1055/2000 - Loss: 1.3784658908843994 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1056/2000 - Loss: 1.3776781558990479 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1057/2000 - Loss: 1.3757697343826294 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1058/2000 - Loss: 1.374567985534668 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1059/2000 - Loss: 1.3734923601150513 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1060/2000 - Loss: 1.3727796077728271 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1061/2000 - Loss: 1.3723357915878296 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1062/2000 - Loss: 1.3721356391906738 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1063/2000 - Loss: 1.3723174333572388 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1064/2000 - Loss: 1.372435450553894 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1065/2000 - Loss: 1.3733290433883667 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1066/2000 - Loss: 1.3733407258987427 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1067/2000 - Loss: 1.375340461730957 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1068/2000 - Loss: 1.3744254112243652 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1069/2000 - Loss: 1.3771649599075317 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1070/2000 - Loss: 1.374225378036499 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1071/2000 - Loss: 1.3754738569259644 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1072/2000 - Loss: 1.3719738721847534 - Train accuracy: 0.644481897354126 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1073/2000 - Loss: 1.3716235160827637 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1074/2000 - Loss: 1.3697668313980103 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1075/2000 - Loss: 1.369667410850525 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1076/2000 - Loss: 1.3698148727416992 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1077/2000 - Loss: 1.370621681213379 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1078/2000 - Loss: 1.3729052543640137 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1079/2000 - Loss: 1.3727772235870361 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1080/2000 - Loss: 1.3755323886871338 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1081/2000 - Loss: 1.3713182210922241 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1082/2000 - Loss: 1.369931936264038 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1083/2000 - Loss: 1.3652926683425903 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1084/2000 - Loss: 1.362631916999817 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1085/2000 - Loss: 1.361009120941162 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1086/2000 - Loss: 1.3607513904571533 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1087/2000 - Loss: 1.3614963293075562 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1088/2000 - Loss: 1.3624728918075562 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1089/2000 - Loss: 1.363937258720398 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1090/2000 - Loss: 1.3636482954025269 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1091/2000 - Loss: 1.363939881324768 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1092/2000 - Loss: 1.3619086742401123 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1093/2000 - Loss: 1.3605377674102783 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1094/2000 - Loss: 1.3583723306655884 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1095/2000 - Loss: 1.3569228649139404 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1096/2000 - Loss: 1.3559346199035645 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1097/2000 - Loss: 1.3555305004119873 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1098/2000 - Loss: 1.3555134534835815 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1099/2000 - Loss: 1.3558752536773682 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1100/2000 - Loss: 1.3561158180236816 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1101/2000 - Loss: 1.3568873405456543 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1102/2000 - Loss: 1.3568971157073975 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1103/2000 - Loss: 1.3577889204025269 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1104/2000 - Loss: 1.3568150997161865 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1105/2000 - Loss: 1.3572795391082764 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1106/2000 - Loss: 1.3552641868591309 - Train accuracy: 0.6419544816017151 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1107/2000 - Loss: 1.3558357954025269 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1108/2000 - Loss: 1.3548680543899536 - Train accuracy: 0.6411120295524597 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1109/2000 - Loss: 1.358832597732544 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1110/2000 - Loss: 1.3602735996246338 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1111/2000 - Loss: 1.3730714321136475 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1112/2000 - Loss: 1.3660632371902466 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1113/2000 - Loss: 1.371278166770935 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1114/2000 - Loss: 1.3583186864852905 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1115/2000 - Loss: 1.3519697189331055 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1116/2000 - Loss: 1.347192645072937 - Train accuracy: 0.6427969932556152 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1117/2000 - Loss: 1.3470017910003662 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1118/2000 - Loss: 1.3496856689453125 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1119/2000 - Loss: 1.3520020246505737 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1120/2000 - Loss: 1.3564362525939941 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1121/2000 - Loss: 1.353519320487976 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1122/2000 - Loss: 1.3549981117248535 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1123/2000 - Loss: 1.3475687503814697 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1124/2000 - Loss: 1.3446459770202637 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1125/2000 - Loss: 1.3445171117782593 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1126/2000 - Loss: 1.3461016416549683 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1127/2000 - Loss: 1.3489017486572266 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1128/2000 - Loss: 1.3475781679153442 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1129/2000 - Loss: 1.3474715948104858 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1130/2000 - Loss: 1.3441665172576904 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1131/2000 - Loss: 1.3415018320083618 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1132/2000 - Loss: 1.3397486209869385 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1133/2000 - Loss: 1.339624047279358 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1134/2000 - Loss: 1.3403111696243286 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1135/2000 - Loss: 1.3408433198928833 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1136/2000 - Loss: 1.341543197631836 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1137/2000 - Loss: 1.3410084247589111 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1138/2000 - Loss: 1.3409913778305054 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1139/2000 - Loss: 1.3391001224517822 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1140/2000 - Loss: 1.3377325534820557 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1141/2000 - Loss: 1.3365912437438965 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1142/2000 - Loss: 1.3359736204147339 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1143/2000 - Loss: 1.3357653617858887 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1144/2000 - Loss: 1.3357058763504028 - Train accuracy: 0.644481897354126 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1145/2000 - Loss: 1.3366800546646118 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1146/2000 - Loss: 1.3370219469070435 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1147/2000 - Loss: 1.3396189212799072 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1148/2000 - Loss: 1.3388670682907104 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1149/2000 - Loss: 1.3423633575439453 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1150/2000 - Loss: 1.3388805389404297 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1151/2000 - Loss: 1.3401867151260376 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1152/2000 - Loss: 1.3356437683105469 - Train accuracy: 0.6436394453048706 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1153/2000 - Loss: 1.3343186378479004 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1154/2000 - Loss: 1.3316590785980225 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1155/2000 - Loss: 1.3304264545440674 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1156/2000 - Loss: 1.3293012380599976 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1157/2000 - Loss: 1.3287525177001953 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1158/2000 - Loss: 1.3285491466522217 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1159/2000 - Loss: 1.3285971879959106 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1160/2000 - Loss: 1.3291579484939575 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1161/2000 - Loss: 1.3297303915023804 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1162/2000 - Loss: 1.3320612907409668 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1163/2000 - Loss: 1.3328351974487305 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1164/2000 - Loss: 1.3379263877868652 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1165/2000 - Loss: 1.336705207824707 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1166/2000 - Loss: 1.3418225049972534 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1167/2000 - Loss: 1.3368595838546753 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1168/2000 - Loss: 1.3362534046173096 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1169/2000 - Loss: 1.3325786590576172 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1170/2000 - Loss: 1.3279814720153809 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1171/2000 - Loss: 1.327180027961731 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1172/2000 - Loss: 1.3255279064178467 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1173/2000 - Loss: 1.3281596899032593 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1174/2000 - Loss: 1.328373670578003 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1175/2000 - Loss: 1.3324111700057983 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1176/2000 - Loss: 1.3278992176055908 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1177/2000 - Loss: 1.3262782096862793 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1178/2000 - Loss: 1.3218892812728882 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1179/2000 - Loss: 1.3193737268447876 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1180/2000 - Loss: 1.3184553384780884 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1181/2000 - Loss: 1.3189444541931152 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1182/2000 - Loss: 1.3202388286590576 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1183/2000 - Loss: 1.3208895921707153 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1184/2000 - Loss: 1.32253098487854 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1185/2000 - Loss: 1.3210712671279907 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1186/2000 - Loss: 1.3210961818695068 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1187/2000 - Loss: 1.3185287714004517 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1188/2000 - Loss: 1.3175636529922485 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1189/2000 - Loss: 1.3164805173873901 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1190/2000 - Loss: 1.3169338703155518 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1191/2000 - Loss: 1.3168665170669556 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1192/2000 - Loss: 1.3190853595733643 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1193/2000 - Loss: 1.318852424621582 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1194/2000 - Loss: 1.3205070495605469 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1195/2000 - Loss: 1.3176559209823608 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1196/2000 - Loss: 1.3168463706970215 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1197/2000 - Loss: 1.3135260343551636 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1198/2000 - Loss: 1.3118408918380737 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1199/2000 - Loss: 1.3104511499404907 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1200/2000 - Loss: 1.3098499774932861 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1201/2000 - Loss: 1.3097763061523438 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1202/2000 - Loss: 1.3100777864456177 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1203/2000 - Loss: 1.3106091022491455 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1204/2000 - Loss: 1.3112547397613525 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1205/2000 - Loss: 1.3120030164718628 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1206/2000 - Loss: 1.3128252029418945 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1207/2000 - Loss: 1.3132390975952148 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1208/2000 - Loss: 1.3141286373138428 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1209/2000 - Loss: 1.3133314847946167 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1210/2000 - Loss: 1.3150157928466797 - Train accuracy: 0.6453243494033813 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1211/2000 - Loss: 1.3130465745925903 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1212/2000 - Loss: 1.3164006471633911 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1213/2000 - Loss: 1.3145365715026855 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1214/2000 - Loss: 1.3216997385025024 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1215/2000 - Loss: 1.3167634010314941 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1216/2000 - Loss: 1.3239995241165161 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1217/2000 - Loss: 1.3107222318649292 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1218/2000 - Loss: 1.3062783479690552 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1219/2000 - Loss: 1.3024382591247559 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1220/2000 - Loss: 1.3015539646148682 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1221/2000 - Loss: 1.303161382675171 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1222/2000 - Loss: 1.3052902221679688 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1223/2000 - Loss: 1.3102201223373413 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1224/2000 - Loss: 1.3079290390014648 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1225/2000 - Loss: 1.3113725185394287 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1226/2000 - Loss: 1.3059113025665283 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1227/2000 - Loss: 1.3049393892288208 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1228/2000 - Loss: 1.3020325899124146 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1229/2000 - Loss: 1.301877737045288 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1230/2000 - Loss: 1.301641821861267 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1231/2000 - Loss: 1.3016982078552246 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1232/2000 - Loss: 1.302207589149475 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1233/2000 - Loss: 1.2998156547546387 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1234/2000 - Loss: 1.2985128164291382 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1235/2000 - Loss: 1.2964341640472412 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1236/2000 - Loss: 1.2956713438034058 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1237/2000 - Loss: 1.2952804565429688 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1238/2000 - Loss: 1.2958579063415527 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1239/2000 - Loss: 1.2966358661651611 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1240/2000 - Loss: 1.298596978187561 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1241/2000 - Loss: 1.2993037700653076 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1242/2000 - Loss: 1.3017868995666504 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1243/2000 - Loss: 1.300548791885376 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1244/2000 - Loss: 1.3022725582122803 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1245/2000 - Loss: 1.2984477281570435 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1246/2000 - Loss: 1.2979316711425781 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1247/2000 - Loss: 1.2943589687347412 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1248/2000 - Loss: 1.293497085571289 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1249/2000 - Loss: 1.292025089263916 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1250/2000 - Loss: 1.292490839958191 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1251/2000 - Loss: 1.2913767099380493 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1252/2000 - Loss: 1.2917002439498901 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1253/2000 - Loss: 1.289958119392395 - Train accuracy: 0.6470092535018921 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1254/2000 - Loss: 1.2890375852584839 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1255/2000 - Loss: 1.2875808477401733 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1256/2000 - Loss: 1.2866599559783936 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1257/2000 - Loss: 1.2859158515930176 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1258/2000 - Loss: 1.285407543182373 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1259/2000 - Loss: 1.2850878238677979 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1260/2000 - Loss: 1.2849100828170776 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1261/2000 - Loss: 1.2848607301712036 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1262/2000 - Loss: 1.2846741676330566 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1263/2000 - Loss: 1.2847377061843872 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1264/2000 - Loss: 1.2845138311386108 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1265/2000 - Loss: 1.2846211194992065 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1266/2000 - Loss: 1.284189224243164 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1267/2000 - Loss: 1.284318208694458 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1268/2000 - Loss: 1.2837074995040894 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1269/2000 - Loss: 1.283735752105713 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1270/2000 - Loss: 1.2836543321609497 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1271/2000 - Loss: 1.2842360734939575 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1272/2000 - Loss: 1.2872201204299927 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1273/2000 - Loss: 1.2905423641204834 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1274/2000 - Loss: 1.3063050508499146 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1275/2000 - Loss: 1.303422451019287 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1276/2000 - Loss: 1.3225443363189697 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1277/2000 - Loss: 1.2951301336288452 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1278/2000 - Loss: 1.285577654838562 - Train accuracy: 0.6486941576004028 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1279/2000 - Loss: 1.2797021865844727 - Train accuracy: 0.649536669254303 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1280/2000 - Loss: 1.2825756072998047 - Train accuracy: 0.6478517055511475 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1281/2000 - Loss: 1.2900744676589966 - Train accuracy: 0.649536669254303 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1282/2000 - Loss: 1.2904878854751587 - Train accuracy: 0.6461668014526367 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1283/2000 - Loss: 1.2984260320663452 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1284/2000 - Loss: 1.2855552434921265 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1285/2000 - Loss: 1.278920292854309 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1286/2000 - Loss: 1.2763944864273071 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1287/2000 - Loss: 1.279252052307129 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1288/2000 - Loss: 1.2812453508377075 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1289/2000 - Loss: 1.281611442565918 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1290/2000 - Loss: 1.2818995714187622 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1291/2000 - Loss: 1.2766602039337158 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1292/2000 - Loss: 1.2739804983139038 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1293/2000 - Loss: 1.2738282680511475 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1294/2000 - Loss: 1.2756386995315552 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1295/2000 - Loss: 1.2759449481964111 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1296/2000 - Loss: 1.277730941772461 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1297/2000 - Loss: 1.2735559940338135 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1298/2000 - Loss: 1.2705270051956177 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1299/2000 - Loss: 1.269333839416504 - Train accuracy: 0.6503791213035583 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1300/2000 - Loss: 1.2698863744735718 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.6161616444587708\n",
      "Epoch 1301/2000 - Loss: 1.271652102470398 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1302/2000 - Loss: 1.271943211555481 - Train accuracy: 0.6512215733528137 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1303/2000 - Loss: 1.2727642059326172 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1304/2000 - Loss: 1.270148754119873 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1305/2000 - Loss: 1.2689192295074463 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1306/2000 - Loss: 1.2676422595977783 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1307/2000 - Loss: 1.2675753831863403 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1308/2000 - Loss: 1.2676154375076294 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1309/2000 - Loss: 1.2688688039779663 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1310/2000 - Loss: 1.2683695554733276 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1311/2000 - Loss: 1.2687855958938599 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1312/2000 - Loss: 1.2675328254699707 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1313/2000 - Loss: 1.2675002813339233 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1314/2000 - Loss: 1.2663522958755493 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1315/2000 - Loss: 1.2671924829483032 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1316/2000 - Loss: 1.2667310237884521 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1317/2000 - Loss: 1.2692077159881592 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1318/2000 - Loss: 1.2675213813781738 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1319/2000 - Loss: 1.2698335647583008 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1320/2000 - Loss: 1.2663644552230835 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1321/2000 - Loss: 1.2667919397354126 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1322/2000 - Loss: 1.264458417892456 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1323/2000 - Loss: 1.2650939226150513 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1324/2000 - Loss: 1.2635928392410278 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1325/2000 - Loss: 1.2641446590423584 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1326/2000 - Loss: 1.2626733779907227 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1327/2000 - Loss: 1.2626750469207764 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1328/2000 - Loss: 1.2609376907348633 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1329/2000 - Loss: 1.2603788375854492 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6161616444587708\n",
      "Epoch 1330/2000 - Loss: 1.258898377418518 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1331/2000 - Loss: 1.2582004070281982 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1332/2000 - Loss: 1.2572933435440063 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1333/2000 - Loss: 1.2569972276687622 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1334/2000 - Loss: 1.2566087245941162 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1335/2000 - Loss: 1.2569588422775269 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1336/2000 - Loss: 1.256875991821289 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1337/2000 - Loss: 1.2582815885543823 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1338/2000 - Loss: 1.2581137418746948 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1339/2000 - Loss: 1.2610119581222534 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1340/2000 - Loss: 1.2598981857299805 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1341/2000 - Loss: 1.2637898921966553 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1342/2000 - Loss: 1.2607125043869019 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1343/2000 - Loss: 1.2636295557022095 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1344/2000 - Loss: 1.2594228982925415 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1345/2000 - Loss: 1.2597920894622803 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1346/2000 - Loss: 1.2562429904937744 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1347/2000 - Loss: 1.2558536529541016 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1348/2000 - Loss: 1.2538442611694336 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1349/2000 - Loss: 1.253412127494812 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6161616444587708\n",
      "Epoch 1350/2000 - Loss: 1.253067135810852 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1351/2000 - Loss: 1.2525516748428345 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1352/2000 - Loss: 1.2527992725372314 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1353/2000 - Loss: 1.2512964010238647 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6161616444587708\n",
      "Epoch 1354/2000 - Loss: 1.2509359121322632 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1355/2000 - Loss: 1.249066710472107 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1356/2000 - Loss: 1.2481176853179932 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1357/2000 - Loss: 1.2467833757400513 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1358/2000 - Loss: 1.2460006475448608 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1359/2000 - Loss: 1.245418667793274 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1360/2000 - Loss: 1.2451350688934326 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1361/2000 - Loss: 1.2450673580169678 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1362/2000 - Loss: 1.2453914880752563 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1363/2000 - Loss: 1.245948076248169 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1364/2000 - Loss: 1.2477763891220093 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1365/2000 - Loss: 1.2494934797286987 - Train accuracy: 0.661331057548523 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1366/2000 - Loss: 1.255517601966858 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1367/2000 - Loss: 1.25706148147583 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1368/2000 - Loss: 1.268733024597168 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1369/2000 - Loss: 1.2598392963409424 - Train accuracy: 0.661331057548523 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1370/2000 - Loss: 1.2609474658966064 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1371/2000 - Loss: 1.248838186264038 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1372/2000 - Loss: 1.243281364440918 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1373/2000 - Loss: 1.240081548690796 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1374/2000 - Loss: 1.2402702569961548 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1375/2000 - Loss: 1.242871642112732 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1376/2000 - Loss: 1.2458723783493042 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1377/2000 - Loss: 1.2512599229812622 - Train accuracy: 0.6520640254020691 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1378/2000 - Loss: 1.2498406171798706 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1379/2000 - Loss: 1.25199294090271 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1380/2000 - Loss: 1.2448338270187378 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1381/2000 - Loss: 1.2414956092834473 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1382/2000 - Loss: 1.2383586168289185 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1383/2000 - Loss: 1.2385104894638062 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1384/2000 - Loss: 1.2397388219833374 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1385/2000 - Loss: 1.2433207035064697 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1386/2000 - Loss: 1.2423179149627686 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1387/2000 - Loss: 1.24211847782135 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1388/2000 - Loss: 1.2382944822311401 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6127946376800537\n",
      "Epoch 1389/2000 - Loss: 1.2355295419692993 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1390/2000 - Loss: 1.233755111694336 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1391/2000 - Loss: 1.2332801818847656 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1392/2000 - Loss: 1.2338770627975464 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1393/2000 - Loss: 1.2347047328948975 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1394/2000 - Loss: 1.236563801765442 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1395/2000 - Loss: 1.235924243927002 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6094276309013367\n",
      "Epoch 1396/2000 - Loss: 1.2371468544006348 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1397/2000 - Loss: 1.2350504398345947 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1398/2000 - Loss: 1.2360804080963135 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1399/2000 - Loss: 1.2356104850769043 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1400/2000 - Loss: 1.2403632402420044 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1401/2000 - Loss: 1.241044282913208 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1402/2000 - Loss: 1.2508198022842407 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1403/2000 - Loss: 1.2437103986740112 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1404/2000 - Loss: 1.2458680868148804 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1405/2000 - Loss: 1.2358496189117432 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1406/2000 - Loss: 1.2325319051742554 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1407/2000 - Loss: 1.229257583618164 - Train accuracy: 0.661331057548523 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1408/2000 - Loss: 1.2288943529129028 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1409/2000 - Loss: 1.2291110754013062 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1410/2000 - Loss: 1.2299809455871582 - Train accuracy: 0.6663858294487 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1411/2000 - Loss: 1.2314199209213257 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1412/2000 - Loss: 1.231284499168396 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1413/2000 - Loss: 1.2333481311798096 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1414/2000 - Loss: 1.2315800189971924 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1415/2000 - Loss: 1.23345947265625 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1416/2000 - Loss: 1.2310614585876465 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1417/2000 - Loss: 1.2334110736846924 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1418/2000 - Loss: 1.2297712564468384 - Train accuracy: 0.661331057548523 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1419/2000 - Loss: 1.2307204008102417 - Train accuracy: 0.661331057548523 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1420/2000 - Loss: 1.2265735864639282 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1421/2000 - Loss: 1.2252147197723389 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1422/2000 - Loss: 1.2229034900665283 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1423/2000 - Loss: 1.2217047214508057 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1424/2000 - Loss: 1.221038818359375 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1425/2000 - Loss: 1.2208884954452515 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1426/2000 - Loss: 1.2212356328964233 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6060606241226196\n",
      "Epoch 1427/2000 - Loss: 1.2217044830322266 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1428/2000 - Loss: 1.2232556343078613 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1429/2000 - Loss: 1.2235018014907837 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1430/2000 - Loss: 1.226498007774353 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1431/2000 - Loss: 1.2252837419509888 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1432/2000 - Loss: 1.228888750076294 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1433/2000 - Loss: 1.2261611223220825 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1434/2000 - Loss: 1.2294001579284668 - Train accuracy: 0.6545913815498352 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1435/2000 - Loss: 1.2260525226593018 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1436/2000 - Loss: 1.2283663749694824 - Train accuracy: 0.6529064774513245 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1437/2000 - Loss: 1.2245817184448242 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1438/2000 - Loss: 1.2250394821166992 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1439/2000 - Loss: 1.2218801975250244 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1440/2000 - Loss: 1.2208986282348633 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1441/2000 - Loss: 1.219225525856018 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1442/2000 - Loss: 1.2178035974502563 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1443/2000 - Loss: 1.2169852256774902 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1444/2000 - Loss: 1.2156885862350464 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1445/2000 - Loss: 1.2152224779129028 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1446/2000 - Loss: 1.2144445180892944 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1447/2000 - Loss: 1.2145428657531738 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1448/2000 - Loss: 1.2146085500717163 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1449/2000 - Loss: 1.2161096334457397 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1450/2000 - Loss: 1.2169147729873657 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1451/2000 - Loss: 1.2210077047348022 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1452/2000 - Loss: 1.2208726406097412 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1453/2000 - Loss: 1.2267241477966309 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1454/2000 - Loss: 1.2220183610916138 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1455/2000 - Loss: 1.223694920539856 - Train accuracy: 0.6537489295005798 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1456/2000 - Loss: 1.2170096635818481 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1457/2000 - Loss: 1.2146302461624146 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1458/2000 - Loss: 1.2110016345977783 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1459/2000 - Loss: 1.209201693534851 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1460/2000 - Loss: 1.2081892490386963 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1461/2000 - Loss: 1.2078933715820312 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1462/2000 - Loss: 1.2081298828125 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1463/2000 - Loss: 1.2087026834487915 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1464/2000 - Loss: 1.2100896835327148 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1465/2000 - Loss: 1.2110477685928345 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1466/2000 - Loss: 1.2142993211746216 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1467/2000 - Loss: 1.2143901586532593 - Train accuracy: 0.6663858294487 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1468/2000 - Loss: 1.2188407182693481 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1469/2000 - Loss: 1.2153526544570923 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1470/2000 - Loss: 1.216734528541565 - Train accuracy: 0.6554338932037354 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1471/2000 - Loss: 1.2112469673156738 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1472/2000 - Loss: 1.2092444896697998 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1473/2000 - Loss: 1.205942988395691 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1474/2000 - Loss: 1.204337239265442 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1475/2000 - Loss: 1.203353762626648 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1476/2000 - Loss: 1.2031465768814087 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1477/2000 - Loss: 1.2033908367156982 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1478/2000 - Loss: 1.2042237520217896 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1479/2000 - Loss: 1.2053190469741821 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1480/2000 - Loss: 1.2070066928863525 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1481/2000 - Loss: 1.2087100744247437 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1482/2000 - Loss: 1.210585594177246 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1483/2000 - Loss: 1.2114754915237427 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1484/2000 - Loss: 1.2111674547195435 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1485/2000 - Loss: 1.2096916437149048 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1486/2000 - Loss: 1.2064597606658936 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1487/2000 - Loss: 1.2043431997299194 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1488/2000 - Loss: 1.201683759689331 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1489/2000 - Loss: 1.2011103630065918 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1490/2000 - Loss: 1.2010306119918823 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1491/2000 - Loss: 1.2040060758590698 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1492/2000 - Loss: 1.2048817873001099 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1493/2000 - Loss: 1.2130025625228882 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1494/2000 - Loss: 1.2075672149658203 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1495/2000 - Loss: 1.2117010354995728 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1496/2000 - Loss: 1.2044316530227661 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1497/2000 - Loss: 1.2049565315246582 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1498/2000 - Loss: 1.202089548110962 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.6026936173439026\n",
      "Epoch 1499/2000 - Loss: 1.2036466598510742 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1500/2000 - Loss: 1.2016077041625977 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1501/2000 - Loss: 1.202329397201538 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1502/2000 - Loss: 1.19992995262146 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1503/2000 - Loss: 1.1988005638122559 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1504/2000 - Loss: 1.1965837478637695 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1505/2000 - Loss: 1.1949249505996704 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1506/2000 - Loss: 1.1934716701507568 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1507/2000 - Loss: 1.1924946308135986 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1508/2000 - Loss: 1.1918659210205078 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1509/2000 - Loss: 1.1915534734725952 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1510/2000 - Loss: 1.1914958953857422 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1511/2000 - Loss: 1.191596269607544 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1512/2000 - Loss: 1.19192373752594 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1513/2000 - Loss: 1.1922690868377686 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1514/2000 - Loss: 1.1933021545410156 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1515/2000 - Loss: 1.1939834356307983 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1516/2000 - Loss: 1.197039008140564 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1517/2000 - Loss: 1.1978225708007812 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5993266105651855\n",
      "Epoch 1518/2000 - Loss: 1.2051562070846558 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1519/2000 - Loss: 1.2030822038650513 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1520/2000 - Loss: 1.2125179767608643 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1521/2000 - Loss: 1.2021487951278687 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1522/2000 - Loss: 1.2043616771697998 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1523/2000 - Loss: 1.1946402788162231 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1524/2000 - Loss: 1.1928648948669434 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1525/2000 - Loss: 1.1894848346710205 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1526/2000 - Loss: 1.1889595985412598 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1527/2000 - Loss: 1.1889288425445557 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1528/2000 - Loss: 1.1894680261611938 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5959596037864685\n",
      "Epoch 1529/2000 - Loss: 1.1919399499893188 - Train accuracy: 0.6562763452529907 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1530/2000 - Loss: 1.1922470331192017 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1531/2000 - Loss: 1.1966655254364014 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1532/2000 - Loss: 1.1937201023101807 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1533/2000 - Loss: 1.1966067552566528 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1534/2000 - Loss: 1.191114902496338 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1535/2000 - Loss: 1.191124677658081 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1536/2000 - Loss: 1.1870596408843994 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1537/2000 - Loss: 1.1863001585006714 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1538/2000 - Loss: 1.1846030950546265 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1539/2000 - Loss: 1.1842303276062012 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1540/2000 - Loss: 1.1841356754302979 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1541/2000 - Loss: 1.1842091083526611 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5925925970077515\n",
      "Epoch 1542/2000 - Loss: 1.1852612495422363 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1543/2000 - Loss: 1.185187578201294 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1544/2000 - Loss: 1.1870025396347046 - Train accuracy: 0.6596461534500122 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1545/2000 - Loss: 1.186028242111206 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1546/2000 - Loss: 1.187862515449524 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1547/2000 - Loss: 1.1857393980026245 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1548/2000 - Loss: 1.187286615371704 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1549/2000 - Loss: 1.1844969987869263 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1550/2000 - Loss: 1.1853878498077393 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1551/2000 - Loss: 1.1826456785202026 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1552/2000 - Loss: 1.1827211380004883 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1553/2000 - Loss: 1.1805740594863892 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1554/2000 - Loss: 1.1800819635391235 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1555/2000 - Loss: 1.1786556243896484 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1556/2000 - Loss: 1.1780738830566406 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1557/2000 - Loss: 1.1772204637527466 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1558/2000 - Loss: 1.1767101287841797 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1559/2000 - Loss: 1.1761856079101562 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1560/2000 - Loss: 1.1758273839950562 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1561/2000 - Loss: 1.1755105257034302 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1562/2000 - Loss: 1.1752983331680298 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1563/2000 - Loss: 1.1752357482910156 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1564/2000 - Loss: 1.1753185987472534 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1565/2000 - Loss: 1.1759436130523682 - Train accuracy: 0.6604886054992676 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1566/2000 - Loss: 1.1768206357955933 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1567/2000 - Loss: 1.1798114776611328 - Train accuracy: 0.6579612493515015 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1568/2000 - Loss: 1.1822192668914795 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1569/2000 - Loss: 1.1920279264450073 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1570/2000 - Loss: 1.1915547847747803 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1571/2000 - Loss: 1.2054363489151 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1572/2000 - Loss: 1.1898058652877808 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1573/2000 - Loss: 1.1859734058380127 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1574/2000 - Loss: 1.1758002042770386 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1575/2000 - Loss: 1.171576976776123 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1576/2000 - Loss: 1.1705995798110962 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1577/2000 - Loss: 1.1724114418029785 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1578/2000 - Loss: 1.176990270614624 - Train accuracy: 0.6621735692024231 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1579/2000 - Loss: 1.1794480085372925 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1580/2000 - Loss: 1.186844825744629 - Train accuracy: 0.661331057548523 - Test accuracy: 0.558922529220581\n",
      "Epoch 1581/2000 - Loss: 1.1817511320114136 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1582/2000 - Loss: 1.1827212572097778 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1583/2000 - Loss: 1.1743239164352417 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1584/2000 - Loss: 1.1707684993743896 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1585/2000 - Loss: 1.168892502784729 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1586/2000 - Loss: 1.169825553894043 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1587/2000 - Loss: 1.17217218875885 - Train accuracy: 0.6588037014007568 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1588/2000 - Loss: 1.1751714944839478 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5892255902290344\n",
      "Epoch 1589/2000 - Loss: 1.1772555112838745 - Train accuracy: 0.6571187973022461 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1590/2000 - Loss: 1.1774852275848389 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1591/2000 - Loss: 1.1757283210754395 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1592/2000 - Loss: 1.1718262434005737 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5858585834503174\n",
      "Epoch 1593/2000 - Loss: 1.168283224105835 - Train accuracy: 0.661331057548523 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1594/2000 - Loss: 1.1659836769104004 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1595/2000 - Loss: 1.1650352478027344 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1596/2000 - Loss: 1.1654986143112183 - Train accuracy: 0.6663858294487 - Test accuracy: 0.558922529220581\n",
      "Epoch 1597/2000 - Loss: 1.166532039642334 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1598/2000 - Loss: 1.168331265449524 - Train accuracy: 0.6630160212516785 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1599/2000 - Loss: 1.1685434579849243 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1600/2000 - Loss: 1.169869065284729 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.558922529220581\n",
      "Epoch 1601/2000 - Loss: 1.1682989597320557 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1602/2000 - Loss: 1.1685923337936401 - Train accuracy: 0.6638584733009338 - Test accuracy: 0.558922529220581\n",
      "Epoch 1603/2000 - Loss: 1.166766881942749 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1604/2000 - Loss: 1.1675529479980469 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1605/2000 - Loss: 1.1673904657363892 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1606/2000 - Loss: 1.172601580619812 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5824915766716003\n",
      "Epoch 1607/2000 - Loss: 1.171352505683899 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1608/2000 - Loss: 1.1792123317718506 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1609/2000 - Loss: 1.1705037355422974 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1610/2000 - Loss: 1.1694552898406982 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1611/2000 - Loss: 1.164374589920044 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1612/2000 - Loss: 1.1636943817138672 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1613/2000 - Loss: 1.1627488136291504 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1614/2000 - Loss: 1.1635231971740723 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.558922529220581\n",
      "Epoch 1615/2000 - Loss: 1.1630159616470337 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1616/2000 - Loss: 1.1634622812271118 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1617/2000 - Loss: 1.1621203422546387 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1618/2000 - Loss: 1.161511778831482 - Train accuracy: 0.6655433773994446 - Test accuracy: 0.558922529220581\n",
      "Epoch 1619/2000 - Loss: 1.160081148147583 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1620/2000 - Loss: 1.1593096256256104 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.558922529220581\n",
      "Epoch 1621/2000 - Loss: 1.158530831336975 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1622/2000 - Loss: 1.1585012674331665 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1623/2000 - Loss: 1.1586402654647827 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1624/2000 - Loss: 1.1604652404785156 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1625/2000 - Loss: 1.1614124774932861 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1626/2000 - Loss: 1.1673035621643066 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1627/2000 - Loss: 1.16632878780365 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1628/2000 - Loss: 1.1758047342300415 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1629/2000 - Loss: 1.1676671504974365 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1630/2000 - Loss: 1.17149817943573 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1631/2000 - Loss: 1.1631795167922974 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1632/2000 - Loss: 1.1620128154754639 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1633/2000 - Loss: 1.1583160161972046 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1634/2000 - Loss: 1.157592535018921 - Train accuracy: 0.6663858294487 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1635/2000 - Loss: 1.1558847427368164 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1636/2000 - Loss: 1.1552133560180664 - Train accuracy: 0.671440601348877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1637/2000 - Loss: 1.1544842720031738 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1638/2000 - Loss: 1.1540127992630005 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1639/2000 - Loss: 1.154071569442749 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1640/2000 - Loss: 1.1536918878555298 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1641/2000 - Loss: 1.1545379161834717 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1642/2000 - Loss: 1.1546640396118164 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1643/2000 - Loss: 1.1573854684829712 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1644/2000 - Loss: 1.1577870845794678 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1645/2000 - Loss: 1.1639288663864136 - Train accuracy: 0.671440601348877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1646/2000 - Loss: 1.1614032983779907 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1647/2000 - Loss: 1.1676472425460815 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1648/2000 - Loss: 1.1604301929473877 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1649/2000 - Loss: 1.1607259511947632 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1650/2000 - Loss: 1.1545580625534058 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1651/2000 - Loss: 1.1523898839950562 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1652/2000 - Loss: 1.1497139930725098 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1653/2000 - Loss: 1.1484243869781494 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1654/2000 - Loss: 1.1477389335632324 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1655/2000 - Loss: 1.1475671529769897 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1656/2000 - Loss: 1.1477679014205933 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1657/2000 - Loss: 1.148197054862976 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1658/2000 - Loss: 1.1493254899978638 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1659/2000 - Loss: 1.1500537395477295 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1660/2000 - Loss: 1.152803897857666 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1661/2000 - Loss: 1.153098225593567 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1662/2000 - Loss: 1.1576859951019287 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1663/2000 - Loss: 1.1549299955368042 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1664/2000 - Loss: 1.1583640575408936 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1665/2000 - Loss: 1.152958869934082 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1666/2000 - Loss: 1.1530787944793701 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.558922529220581\n",
      "Epoch 1667/2000 - Loss: 1.1489332914352417 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1668/2000 - Loss: 1.1485475301742554 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1669/2000 - Loss: 1.1468689441680908 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.558922529220581\n",
      "Epoch 1670/2000 - Loss: 1.1476554870605469 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1671/2000 - Loss: 1.1474575996398926 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1672/2000 - Loss: 1.1491448879241943 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1673/2000 - Loss: 1.1496812105178833 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1674/2000 - Loss: 1.1511166095733643 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1675/2000 - Loss: 1.1513290405273438 - Train accuracy: 0.6647009253501892 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1676/2000 - Loss: 1.1510586738586426 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5791245698928833\n",
      "Epoch 1677/2000 - Loss: 1.151047945022583 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1678/2000 - Loss: 1.1488473415374756 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1679/2000 - Loss: 1.14905846118927 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1680/2000 - Loss: 1.1465885639190674 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1681/2000 - Loss: 1.1474789381027222 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1682/2000 - Loss: 1.1459050178527832 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1683/2000 - Loss: 1.1485636234283447 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1684/2000 - Loss: 1.1469852924346924 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1685/2000 - Loss: 1.1515121459960938 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1686/2000 - Loss: 1.1473244428634644 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1687/2000 - Loss: 1.149259090423584 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1688/2000 - Loss: 1.1440608501434326 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1689/2000 - Loss: 1.1428028345108032 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1690/2000 - Loss: 1.1398676633834839 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1691/2000 - Loss: 1.1386067867279053 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1692/2000 - Loss: 1.1376285552978516 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1693/2000 - Loss: 1.1372439861297607 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1694/2000 - Loss: 1.137130856513977 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1695/2000 - Loss: 1.1372636556625366 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1696/2000 - Loss: 1.1374872922897339 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1697/2000 - Loss: 1.1378436088562012 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1698/2000 - Loss: 1.1382410526275635 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1699/2000 - Loss: 1.1387131214141846 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1700/2000 - Loss: 1.1391689777374268 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1701/2000 - Loss: 1.1400095224380493 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1702/2000 - Loss: 1.140389323234558 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1703/2000 - Loss: 1.1425013542175293 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1704/2000 - Loss: 1.1428155899047852 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1705/2000 - Loss: 1.1484159231185913 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1706/2000 - Loss: 1.146972894668579 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1707/2000 - Loss: 1.155977725982666 - Train accuracy: 0.6680707931518555 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1708/2000 - Loss: 1.1475940942764282 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1709/2000 - Loss: 1.1512314081192017 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1710/2000 - Loss: 1.141793131828308 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1711/2000 - Loss: 1.1422368288040161 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.558922529220581\n",
      "Epoch 1712/2000 - Loss: 1.137877106666565 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1713/2000 - Loss: 1.1384117603302002 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1714/2000 - Loss: 1.1362566947937012 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1715/2000 - Loss: 1.1356886625289917 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1716/2000 - Loss: 1.1347535848617554 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1717/2000 - Loss: 1.1338473558425903 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1718/2000 - Loss: 1.1345546245574951 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1719/2000 - Loss: 1.1345007419586182 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1720/2000 - Loss: 1.1376649141311646 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1721/2000 - Loss: 1.137281894683838 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1722/2000 - Loss: 1.142866611480713 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1723/2000 - Loss: 1.1381611824035645 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1724/2000 - Loss: 1.1406415700912476 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1725/2000 - Loss: 1.1344681978225708 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1726/2000 - Loss: 1.1329870223999023 - Train accuracy: 0.671440601348877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1727/2000 - Loss: 1.129830002784729 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1728/2000 - Loss: 1.1284688711166382 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1729/2000 - Loss: 1.1274330615997314 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1730/2000 - Loss: 1.1269195079803467 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1731/2000 - Loss: 1.126685619354248 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1732/2000 - Loss: 1.1266204118728638 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.558922529220581\n",
      "Epoch 1733/2000 - Loss: 1.126732349395752 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1734/2000 - Loss: 1.126844882965088 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1735/2000 - Loss: 1.1273601055145264 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1736/2000 - Loss: 1.127519130706787 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1737/2000 - Loss: 1.1288994550704956 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.558922529220581\n",
      "Epoch 1738/2000 - Loss: 1.1290464401245117 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1739/2000 - Loss: 1.1324632167816162 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1740/2000 - Loss: 1.1322295665740967 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1741/2000 - Loss: 1.139399528503418 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1742/2000 - Loss: 1.1361873149871826 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1743/2000 - Loss: 1.144352674484253 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1744/2000 - Loss: 1.135911464691162 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1745/2000 - Loss: 1.1375750303268433 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1746/2000 - Loss: 1.130685806274414 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1747/2000 - Loss: 1.129493236541748 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1748/2000 - Loss: 1.1266008615493774 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1749/2000 - Loss: 1.125767707824707 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1750/2000 - Loss: 1.125325083732605 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1751/2000 - Loss: 1.1248447895050049 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1752/2000 - Loss: 1.125707983970642 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.558922529220581\n",
      "Epoch 1753/2000 - Loss: 1.1248893737792969 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1754/2000 - Loss: 1.1263620853424072 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1755/2000 - Loss: 1.1252055168151855 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1756/2000 - Loss: 1.1277060508728027 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1757/2000 - Loss: 1.1264777183532715 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1758/2000 - Loss: 1.1303675174713135 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1759/2000 - Loss: 1.1279616355895996 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1760/2000 - Loss: 1.1314051151275635 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1761/2000 - Loss: 1.1272639036178589 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1762/2000 - Loss: 1.128031849861145 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1763/2000 - Loss: 1.12398362159729 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1764/2000 - Loss: 1.1228772401809692 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1765/2000 - Loss: 1.1204686164855957 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.558922529220581\n",
      "Epoch 1766/2000 - Loss: 1.1192790269851685 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1767/2000 - Loss: 1.1182621717453003 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1768/2000 - Loss: 1.1176594495773315 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1769/2000 - Loss: 1.117559790611267 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.558922529220581\n",
      "Epoch 1770/2000 - Loss: 1.1175192594528198 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1771/2000 - Loss: 1.1183744668960571 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.558922529220581\n",
      "Epoch 1772/2000 - Loss: 1.1187615394592285 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1773/2000 - Loss: 1.121414065361023 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1774/2000 - Loss: 1.1215795278549194 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1775/2000 - Loss: 1.1269242763519287 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1776/2000 - Loss: 1.1243444681167603 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1777/2000 - Loss: 1.129603385925293 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1778/2000 - Loss: 1.1233185529708862 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1779/2000 - Loss: 1.1241165399551392 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1780/2000 - Loss: 1.1188554763793945 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1781/2000 - Loss: 1.1175376176834106 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1782/2000 - Loss: 1.115052580833435 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1783/2000 - Loss: 1.113998532295227 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1784/2000 - Loss: 1.1130248308181763 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1785/2000 - Loss: 1.112532615661621 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1786/2000 - Loss: 1.1122074127197266 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1787/2000 - Loss: 1.1121011972427368 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1788/2000 - Loss: 1.1122366189956665 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1789/2000 - Loss: 1.1124945878982544 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1790/2000 - Loss: 1.113398790359497 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1791/2000 - Loss: 1.1140365600585938 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1792/2000 - Loss: 1.116390347480774 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1793/2000 - Loss: 1.1168479919433594 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1794/2000 - Loss: 1.1205345392227173 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.558922529220581\n",
      "Epoch 1795/2000 - Loss: 1.1186484098434448 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1796/2000 - Loss: 1.120749831199646 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.558922529220581\n",
      "Epoch 1797/2000 - Loss: 1.1162168979644775 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1798/2000 - Loss: 1.1159731149673462 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.558922529220581\n",
      "Epoch 1799/2000 - Loss: 1.1128172874450684 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1800/2000 - Loss: 1.1144267320632935 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1801/2000 - Loss: 1.115288257598877 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1802/2000 - Loss: 1.1248055696487427 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.558922529220581\n",
      "Epoch 1803/2000 - Loss: 1.1257973909378052 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1804/2000 - Loss: 1.1439813375473022 - Train accuracy: 0.6697556972503662 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1805/2000 - Loss: 1.128674030303955 - Train accuracy: 0.6689132452011108 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1806/2000 - Loss: 1.1288176774978638 - Train accuracy: 0.6672282814979553 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1807/2000 - Loss: 1.1169735193252563 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1808/2000 - Loss: 1.111042857170105 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1809/2000 - Loss: 1.1084712743759155 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1810/2000 - Loss: 1.1087065935134888 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1811/2000 - Loss: 1.1139389276504517 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1812/2000 - Loss: 1.1155306100845337 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1813/2000 - Loss: 1.1235694885253906 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1814/2000 - Loss: 1.1160982847213745 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1815/2000 - Loss: 1.115567684173584 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1816/2000 - Loss: 1.107789158821106 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1817/2000 - Loss: 1.1044045686721802 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1818/2000 - Loss: 1.1031943559646606 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1819/2000 - Loss: 1.104210615158081 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1820/2000 - Loss: 1.1071397066116333 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1821/2000 - Loss: 1.1087113618850708 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1822/2000 - Loss: 1.1135516166687012 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1823/2000 - Loss: 1.1096473932266235 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1824/2000 - Loss: 1.1097668409347534 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1825/2000 - Loss: 1.105437994003296 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1826/2000 - Loss: 1.1043670177459717 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1827/2000 - Loss: 1.1027318239212036 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1828/2000 - Loss: 1.103050708770752 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1829/2000 - Loss: 1.1030113697052002 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1830/2000 - Loss: 1.1036700010299683 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1831/2000 - Loss: 1.1041386127471924 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1832/2000 - Loss: 1.1039596796035767 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1833/2000 - Loss: 1.1035767793655396 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1834/2000 - Loss: 1.1026878356933594 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1835/2000 - Loss: 1.101891040802002 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1836/2000 - Loss: 1.1005114316940308 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1837/2000 - Loss: 1.0995464324951172 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1838/2000 - Loss: 1.098535180091858 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1839/2000 - Loss: 1.0978307723999023 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1840/2000 - Loss: 1.0973149538040161 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.558922529220581\n",
      "Epoch 1841/2000 - Loss: 1.0970789194107056 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1842/2000 - Loss: 1.0970723628997803 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1843/2000 - Loss: 1.097629427909851 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1844/2000 - Loss: 1.0983017683029175 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.558922529220581\n",
      "Epoch 1845/2000 - Loss: 1.1009852886199951 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1846/2000 - Loss: 1.1023528575897217 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1847/2000 - Loss: 1.1105353832244873 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1848/2000 - Loss: 1.1086317300796509 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1849/2000 - Loss: 1.1208937168121338 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1850/2000 - Loss: 1.1081507205963135 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1851/2000 - Loss: 1.1095126867294312 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1852/2000 - Loss: 1.1010990142822266 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1853/2000 - Loss: 1.1001615524291992 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1854/2000 - Loss: 1.0978477001190186 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1855/2000 - Loss: 1.098412275314331 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1856/2000 - Loss: 1.0983357429504395 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1857/2000 - Loss: 1.099318265914917 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1858/2000 - Loss: 1.0996744632720947 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1859/2000 - Loss: 1.0997976064682007 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1860/2000 - Loss: 1.0992544889450073 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1861/2000 - Loss: 1.0974693298339844 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1862/2000 - Loss: 1.0955947637557983 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1863/2000 - Loss: 1.0935558080673218 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1864/2000 - Loss: 1.091870903968811 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.558922529220581\n",
      "Epoch 1865/2000 - Loss: 1.0907198190689087 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1866/2000 - Loss: 1.0901048183441162 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1867/2000 - Loss: 1.0901165008544922 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1868/2000 - Loss: 1.09060537815094 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.558922529220581\n",
      "Epoch 1869/2000 - Loss: 1.0924848318099976 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1870/2000 - Loss: 1.0942689180374146 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1871/2000 - Loss: 1.1017749309539795 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1872/2000 - Loss: 1.1018791198730469 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.558922529220581\n",
      "Epoch 1873/2000 - Loss: 1.1176204681396484 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1874/2000 - Loss: 1.1039998531341553 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1875/2000 - Loss: 1.1069910526275635 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1876/2000 - Loss: 1.0963020324707031 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1877/2000 - Loss: 1.095200777053833 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1878/2000 - Loss: 1.092029333114624 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1879/2000 - Loss: 1.0921485424041748 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1880/2000 - Loss: 1.0917904376983643 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5757575631141663\n",
      "Epoch 1881/2000 - Loss: 1.0916142463684082 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1882/2000 - Loss: 1.091605544090271 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.558922529220581\n",
      "Epoch 1883/2000 - Loss: 1.0899296998977661 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1884/2000 - Loss: 1.088903784751892 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1885/2000 - Loss: 1.0869842767715454 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1886/2000 - Loss: 1.086302638053894 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.558922529220581\n",
      "Epoch 1887/2000 - Loss: 1.0856391191482544 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1888/2000 - Loss: 1.0865674018859863 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1889/2000 - Loss: 1.0876750946044922 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1890/2000 - Loss: 1.092624545097351 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1891/2000 - Loss: 1.0941441059112549 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1892/2000 - Loss: 1.1053894758224487 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1893/2000 - Loss: 1.099189281463623 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1894/2000 - Loss: 1.1056923866271973 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1895/2000 - Loss: 1.092468500137329 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1896/2000 - Loss: 1.0880337953567505 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1897/2000 - Loss: 1.0829447507858276 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1898/2000 - Loss: 1.081076741218567 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1899/2000 - Loss: 1.0808618068695068 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5387205481529236\n",
      "Epoch 1900/2000 - Loss: 1.0818933248519897 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1901/2000 - Loss: 1.0840271711349487 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1902/2000 - Loss: 1.0855677127838135 - Train accuracy: 0.681550145149231 - Test accuracy: 0.558922529220581\n",
      "Epoch 1903/2000 - Loss: 1.0894877910614014 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1904/2000 - Loss: 1.0885796546936035 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1905/2000 - Loss: 1.0922043323516846 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1906/2000 - Loss: 1.087127923965454 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1907/2000 - Loss: 1.0863559246063232 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1908/2000 - Loss: 1.0822182893753052 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1909/2000 - Loss: 1.0810598134994507 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1910/2000 - Loss: 1.0796682834625244 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1911/2000 - Loss: 1.0804927349090576 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1912/2000 - Loss: 1.0811307430267334 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1913/2000 - Loss: 1.084298014640808 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1914/2000 - Loss: 1.0852450132369995 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1915/2000 - Loss: 1.0890376567840576 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1916/2000 - Loss: 1.0860298871994019 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1917/2000 - Loss: 1.0863267183303833 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1918/2000 - Loss: 1.0815160274505615 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.558922529220581\n",
      "Epoch 1919/2000 - Loss: 1.0803440809249878 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1920/2000 - Loss: 1.078566551208496 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1921/2000 - Loss: 1.0807418823242188 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1922/2000 - Loss: 1.08175790309906 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5690235495567322\n",
      "Epoch 1923/2000 - Loss: 1.0891832113265991 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1924/2000 - Loss: 1.08724844455719 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1925/2000 - Loss: 1.0943049192428589 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1926/2000 - Loss: 1.0857996940612793 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1927/2000 - Loss: 1.0849521160125732 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1928/2000 - Loss: 1.0775278806686401 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.558922529220581\n",
      "Epoch 1929/2000 - Loss: 1.074230432510376 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1930/2000 - Loss: 1.0721465349197388 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1931/2000 - Loss: 1.0717717409133911 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.558922529220581\n",
      "Epoch 1932/2000 - Loss: 1.0725620985031128 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1933/2000 - Loss: 1.0738917589187622 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1934/2000 - Loss: 1.0759100914001465 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1935/2000 - Loss: 1.076812982559204 - Train accuracy: 0.681550145149231 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1936/2000 - Loss: 1.0792052745819092 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1937/2000 - Loss: 1.077963948249817 - Train accuracy: 0.6832350492477417 - Test accuracy: 0.5723905563354492\n",
      "Epoch 1938/2000 - Loss: 1.0794647932052612 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5387205481529236\n",
      "Epoch 1939/2000 - Loss: 1.076186180114746 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1940/2000 - Loss: 1.0766260623931885 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1941/2000 - Loss: 1.074175477027893 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1942/2000 - Loss: 1.0762890577316284 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1943/2000 - Loss: 1.075836181640625 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1944/2000 - Loss: 1.0826572179794312 - Train accuracy: 0.676495373249054 - Test accuracy: 0.558922529220581\n",
      "Epoch 1945/2000 - Loss: 1.0803076028823853 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1946/2000 - Loss: 1.0872958898544312 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1947/2000 - Loss: 1.0792216062545776 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1948/2000 - Loss: 1.0779540538787842 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1949/2000 - Loss: 1.07174551486969 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1950/2000 - Loss: 1.069851040840149 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1951/2000 - Loss: 1.068027138710022 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1952/2000 - Loss: 1.0684407949447632 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1953/2000 - Loss: 1.0688194036483765 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1954/2000 - Loss: 1.0703591108322144 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5387205481529236\n",
      "Epoch 1955/2000 - Loss: 1.070610761642456 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1956/2000 - Loss: 1.072499394416809 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1957/2000 - Loss: 1.0717705488204956 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1958/2000 - Loss: 1.0734549760818481 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1959/2000 - Loss: 1.0712262392044067 - Train accuracy: 0.6781802773475647 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1960/2000 - Loss: 1.0725257396697998 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1961/2000 - Loss: 1.0697332620620728 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.558922529220581\n",
      "Epoch 1962/2000 - Loss: 1.072068691253662 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1963/2000 - Loss: 1.0701913833618164 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5656565427780151\n",
      "Epoch 1964/2000 - Loss: 1.075128197669983 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1965/2000 - Loss: 1.071977972984314 - Train accuracy: 0.676495373249054 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1966/2000 - Loss: 1.0773955583572388 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1967/2000 - Loss: 1.071687936782837 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1968/2000 - Loss: 1.0731532573699951 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1969/2000 - Loss: 1.0676558017730713 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1970/2000 - Loss: 1.0660514831542969 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1971/2000 - Loss: 1.063027024269104 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1972/2000 - Loss: 1.0622361898422241 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5353535413742065\n",
      "Epoch 1973/2000 - Loss: 1.0615804195404053 - Train accuracy: 0.6807076930999756 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1974/2000 - Loss: 1.0621978044509888 - Train accuracy: 0.6722830533981323 - Test accuracy: 0.5387205481529236\n",
      "Epoch 1975/2000 - Loss: 1.062368392944336 - Train accuracy: 0.6823925971984863 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1976/2000 - Loss: 1.0637308359146118 - Train accuracy: 0.671440601348877 - Test accuracy: 0.5387205481529236\n",
      "Epoch 1977/2000 - Loss: 1.0638834238052368 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1978/2000 - Loss: 1.0665138959884644 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1979/2000 - Loss: 1.0658776760101318 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5622895359992981\n",
      "Epoch 1980/2000 - Loss: 1.0697263479232788 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1981/2000 - Loss: 1.0667775869369507 - Train accuracy: 0.676495373249054 - Test accuracy: 0.558922529220581\n",
      "Epoch 1982/2000 - Loss: 1.0695487260818481 - Train accuracy: 0.6756529211997986 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1983/2000 - Loss: 1.064903974533081 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.558922529220581\n",
      "Epoch 1984/2000 - Loss: 1.0664050579071045 - Train accuracy: 0.6731255054473877 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1985/2000 - Loss: 1.0626221895217896 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1986/2000 - Loss: 1.0641467571258545 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1987/2000 - Loss: 1.061784267425537 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1988/2000 - Loss: 1.0641601085662842 - Train accuracy: 0.6773378252983093 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1989/2000 - Loss: 1.0621135234832764 - Train accuracy: 0.6739679574966431 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1990/2000 - Loss: 1.0638611316680908 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.558922529220581\n",
      "Epoch 1991/2000 - Loss: 1.061237096786499 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5454545617103577\n",
      "Epoch 1992/2000 - Loss: 1.0610582828521729 - Train accuracy: 0.681550145149231 - Test accuracy: 0.558922529220581\n",
      "Epoch 1993/2000 - Loss: 1.0584683418273926 - Train accuracy: 0.676495373249054 - Test accuracy: 0.558922529220581\n",
      "Epoch 1994/2000 - Loss: 1.0578417778015137 - Train accuracy: 0.6790227293968201 - Test accuracy: 0.5488215684890747\n",
      "Epoch 1995/2000 - Loss: 1.0562695264816284 - Train accuracy: 0.681550145149231 - Test accuracy: 0.5521885752677917\n",
      "Epoch 1996/2000 - Loss: 1.0569578409194946 - Train accuracy: 0.6748104691505432 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1997/2000 - Loss: 1.056828498840332 - Train accuracy: 0.6832350492477417 - Test accuracy: 0.5555555820465088\n",
      "Epoch 1998/2000 - Loss: 1.0596407651901245 - Train accuracy: 0.6705981492996216 - Test accuracy: 0.5420875549316406\n",
      "Epoch 1999/2000 - Loss: 1.0597739219665527 - Train accuracy: 0.6798651814460754 - Test accuracy: 0.558922529220581\n",
      "0.558922529220581\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "MODEL_NEURONS = 100\n",
    "MODEL_EPOCHS= 2000\n",
    "MODEL_LR = 1.0e-1\n",
    "MODEL_LABEL_NUM = len(np.unique(y_train))\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(x_train.shape[1], n_neurons)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_neurons, MODEL_LABEL_NUM)\n",
    "        self.ac2 = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        logits = self.fc2(x)\n",
    "        x = self.ac2(logits)\n",
    "        return x\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train).float()\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "x_test_tensor = torch.tensor(x_test).float()\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "label_onehot = torch.zeros(y_train.shape[0], MODEL_LABEL_NUM)\n",
    "label_onehot.scatter_(1, y_train_tensor.unsqueeze(1), 1)\n",
    "class_weights = 1.0/label_onehot.mean(axis=0)\n",
    "print(class_weights)\n",
    "\n",
    "network = MLP(MODEL_NEURONS)\n",
    "loss = torch.nn.BCELoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=MODEL_LR)#, weight_decay=5e-3)\n",
    "\n",
    "for epoch in range(MODEL_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    preds = network(x_train_tensor)\n",
    "    label_onehot = torch.zeros(y_train.shape[0], MODEL_LABEL_NUM)\n",
    "    label_onehot.scatter_(1, y_train_tensor.unsqueeze(1), 1)\n",
    "    loss_value = loss(preds, label_onehot)\n",
    "    loss_value.backward()        \n",
    "    optimizer.step()\n",
    "\n",
    "    train_accuracy = (preds.argmax(dim=1) == y_train_tensor).float().mean() \n",
    "\n",
    "    test_preds = network.forward(x_test_tensor)        \n",
    "    test_accuracy = (test_preds.argmax(dim=1) == y_test_tensor).float().mean() \n",
    "    print(f'Epoch {epoch}/{MODEL_EPOCHS} - Loss: {loss_value.item()} - Train accuracy: {train_accuracy} - Test accuracy: {test_accuracy}')  \n",
    "    if test_accuracy > 0.75: # Undertrained\n",
    "        break\n",
    "    \n",
    "print(test_accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(network.state_dict(), os.path.join(PROJ_DIR,'assets','models','htru2-mlp.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
