{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "import pickle\n",
    "\n",
    "DICT_PATH_TRAIN = os.path.join(PROJ_DIR, 'data', 'cmnist_train_dict.pickle')\n",
    "DICT_PATH_TEST = os.path.join(PROJ_DIR, 'data', 'cmnist_test_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'x', 'y', 's_box', 's_digit', 's_area'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "BATCH_SIZE_TRAIN = 256\n",
    "BATCH_SIZE_TEST = 256\n",
    "\n",
    "class CMNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dict_file_path:str):\n",
    "        with open(os.path.join(PROJ_DIR, 'data', 'cmnist_train_dict.pickle'), 'rb') as fIn:\n",
    "            self.data = pickle.load(fIn)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]['x'], self.data[idx]['y']\n",
    "    \n",
    "train_set = CMNISTDataset(dict_file_path=DICT_PATH_TRAIN)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=4)\n",
    "\n",
    "test_set = CMNISTDataset(dict_file_path=DICT_PATH_TEST)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5QUlEQVR4nO3de3iU9Zk38O9kMjM5TDI5ZxKSQMIh4ZS4poBRRBRKoK0LhXcF7b7F6qWvGtxF1lN2PeFho9gqrYtody3UtkhrK6K04gElajkoCAKCETBIMAcgJDOTSTIzyTzvHyzTjgly/yDhl4Tv57rmusjMN3d+zzwzc/PM4R6TYRgGiIiIzrMI3QsgIqILExsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEFE/tWTJEhQUFCAYDCr/7r333osJEyb0wqqI5NiAaMDbtGkTHnroITQ3N+teSo9xu9144okncM899yAi4m9345aWFixcuBBZWVmw2WwYOXIkli9f3uX3Fy5ciE8//RSvvfba+Vw2URg2IBrwNm3ahMWLFw+oBvSrX/0KHR0duPbaa0PndXZ2orS0FMuXL8c111yDpUuXIj8/H7fddhv+8z//M+z3nU4nZs6ciZ/+9Kfne+lEIWxARP2E1+sN/XvFihX4x3/8R0RFRYXOe+WVV7Bp0yYsX74cTz31FG699Va8+uqrmDNnDh555BEcPXo0rN4111yDDz/8EF9++eV52waiv8cGRAPaQw89hLvuugsAkJubC5PJBJPJhEOHDgEAfvvb36K4uBjR0dFISkrCvHnzUFNTE1Zj8uTJGDNmDPbu3Ysrr7wSMTExGDRoEJYsWdLl7z3zzDMYPXo0YmJikJiYiO985ztYtWpVWGbHjh2YMWMG4uPjYbfbMWXKFGzZsiUss3LlSphMJlRWVuK2225DWloasrKyAADV1dXYtWsXpk6dGvY7H3zwAQBg3rx5YefPmzcP7e3tWLt2bdj5p37/m+cTnS9sQDSgzZ49O/Q01dNPP43f/OY3+M1vfoPU1FQ89thj+PGPf4zhw4fjqaeewsKFC7FhwwZMmjSpy9N1TU1NmD59OoqKivCzn/0MBQUFuOeee/DGG2+EMv/93/+Nf/mXf8GoUaOwdOlSLF68GBdddBG2bt0aynz22We4/PLL8emnn+Luu+/G/fffj+rqakyePDksd8ptt92GvXv34oEHHsC9994L4ORTigBw8cUXh2V9Ph/MZjOsVmvY+TExMQCA7du3h53vcDgwdOhQ/PWvf1W5Sol6jkE0wD355JMGAKO6ujp03qFDhwyz2Ww89thjYdndu3cbkZGRYedfccUVBgDjxRdfDJ3n8/kMp9NpzJkzJ3TezJkzjdGjR3/rWmbNmmVYrVbj4MGDofNqa2uNuLg4Y9KkSaHzVqxYYQAwJk6caHR0dITVuO+++wwAhsfjCTv/Zz/7mQHA+OCDD8LOv/feew0Axg9+8IMu65k2bZoxcuTIb10zUW/hERBdkF555RUEg0Fcc801OH78eOjkdDoxfPhwvPfee2F5u92Of/7nfw79bLVaMX78+LDXTxISEnDkyBF8/PHH3f7Nzs5OvPXWW5g1axby8vJC52dkZOC6667Dhx9+CLfbHfY7N910E8xmc9h5jY2NiIyMhN1uDzv/uuuug8PhwA033IC3334bhw4dwi9/+Us8++yzAIC2trYua0pMTMTx48e/7aoi6jVsQHRB2r9/PwzDwPDhw5Gamhp22rdvX5cX7LOysmAymcLOS0xMRFNTU+jne+65B3a7HePHj8fw4cNRVlYW9vTWsWPH0Nraivz8/C7rGTlyJILBYJfXn3Jzc8Xb5HQ68dprr8Hn82HatGnIzc3FXXfdhWeeeQYAujQsADAMo8t2EZ0vkboXQKRDMBiEyWTCG2+80eUIA+j6YN1dBjj5AH7KyJEjUVVVhXXr1mH9+vX405/+hGeffRYPPPAAFi9efFbrjI6O7nJecnIyOjo64PF4EBcXF3bZpEmT8OWXX2L37t3wer0oKipCbW0tAGDEiBFdajU1NSElJeWs1kZ0rtiAaMDr7n/4Q4cOhWEYyM3N7faB+WzFxsZi7ty5mDt3Lvx+P2bPno3HHnsM5eXlSE1NRUxMDKqqqrr83ueff46IiAhkZ2ef8W8UFBQAOPluuMLCwi6Xm81mXHTRRaGf33nnHQDo8q65UzWKioqkm0fUo/gUHA14sbGxABD2zrbZs2fDbDZj8eLFYUcxwMmjmsbGRuW/883fsVqtGDVqFAzDQCAQgNlsxrRp07B27drQ28ABoKGhAatWrcLEiRMRHx9/xr9TUlICANi2bdsZs8eOHcMTTzyBwsLCLg3I5XLh4MGDuPTSSwVbR9TzeAREA15xcTEA4D/+4z8wb948WCwWXH311Xj00UdRXl6OQ4cOYdasWYiLi0N1dTXWrFmDm2++GXfeeafS35k2bRqcTicuu+wypKenY9++ffiv//ovfP/73w89Vfboo4/i7bffxsSJE3HbbbchMjISzz//PHw+X7efK+pOXl4exowZg3feeQc33HBD2GVXXHEFSkpKMGzYMNTX1+OXv/wlWlpasG7durCRPcDJIyPDMDBz5kyl7STqMfregEd0/jzyyCPGoEGDjIiIiLC3ZP/pT38yJk6caMTGxhqxsbFGQUGBUVZWZlRVVYV+94orruj27dXz5883Bg8eHPr5+eefNyZNmmQkJycbNpvNGDp0qHHXXXcZLpcr7Pc++eQTo7S01LDb7UZMTIxx5ZVXGps2bQrLnHob9scff9zt9jz11FOG3W43Wltbw86/4447jLy8PMNmsxmpqanGddddF/aW7783d+5cY+LEiae9zoh6m8kwvvH8AxH1eS6XC3l5eViyZAluvPFG5d+vr69Hbm4uVq9ezSMg0oavARH1Qw6HA3fffTeefPLJs/o6hqVLl2Ls2LFsPqQVj4CIiEgLHgEREZEWbEBERKQFGxAREWnBBkRERFr0uQ+iBoNB1NbWIi4ujkMSiYj6IcMw4PF4kJmZ2eUD0H+vzzWg2tpa0TwsIiLq22pqakLf5NudPteATo0sqa6pEc3FOqlTXD/S0/1U49OyymsHbWq1I1wd8rDDq1S7GQ5xNkGpMuALupTyNtjE2ZZAlFJtu7lFnO2IjFGqHanwDLW3Q+2zOLGRAaW8zy/Pmn1qd+tIn8Iz8SmtSrV9HfK1eE+0K9Vui/SIs9HNCUq1XXFq9zePIX+2JqFT7ZmdjEj5fbkzTu12aOuU37BMsfJ96XZ7kJ09osu09m/qtQa0bNkyPPnkk6ivr0dRURGeeeYZjB8//oy/d+ppt/j4+N5pQKY+1IAMhQYUr1Y7COl1B4XkSb6g2kfHVBpQhHIDkj949mYDMvfnBtSu0IDi1WqrNCBzwHrm0N+JVFhKdKfarTwYp/byuKHQgOIUG1B8pHztnfF9owGFfucML6P0ypsQfv/732PRokV48MEH8cknn6CoqAilpaVdvuSLiIguXL3SgJ566incdNNN+MlPfoJRo0bhueeeQ0xMDH71q191yfp8Prjd7rATERENfD3egPx+P7Zv3x723SMRERGYOnUqNm/e3CVfUVEBh8MROvENCEREF4Yeb0DHjx9HZ2cn0tPTw85PT09HfX19l3x5eTlcLlfoVFNT09NLIiKiPkj7u+BsNhtsNvmL1ERENDD0+BFQSkoKzGYzGhoaws5vaGiA0+ns6T9HRET9VI83IKvViuLiYmzYsCF0XjAYxIYNG0LfZU9ERNQrT8EtWrQI8+fPx3e+8x2MHz8eS5cuhdfrxU9+8pPe+HNERNQP9UoDmjt3Lo4dO4YHHngA9fX1uOiii7B+/foub0z41oV1tCOyQ/bBNG+k/MOLbd/+wdwu4trlHwCNUPtsIQyb/OrvCKgtPMEn/7Co4Vf7YJzJLv9kNgD4ffIrJhhQ+yCd3yr/cKkloLadRxPl645uVfxex5g2pbgRTBBnG81NarXj7eJs4Cu1CQFoPCSO1rjUrsPGZvl2utrVPt7hcx9RypsUPvyblqn2Tl/rhFHirCNqmFJtwy/fnyaPwgeFPbIn13rtTQgLFizAggULeqs8ERH1c/w6BiIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItJC+9cxnFbAd/IkEBspH+HR3BGttg6zfGSKz9KpVNoWVBgjo1g74LOIs5FJjUq1g+1q16HZJt/OVsVRSfEKo0Sa7bFKtc0n2sVZC9RG1NR5E5Ty/kj5KJmjn6p9p5bXqBVnj53wKNWuPVwlzjbsUhtPtNdcJ87GB04o1W50y+8/AJCY6BJnh9aOUKodk9sizhZCPpYMAEzZOeJswCofZeU2/KIcj4CIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi06Luz4DqiT54EPD75LLgE+TgjAECNVV47G3a14grj3QKoVyrtt8s3NHAiSam2q00+lwwAfI5mcdbylfz6BoDGaPkMri9OmJVq+73yuWfNbvm8LgCwt6n93+945CfibFO1fL4XABw4vF6cdR0MKNU+1iCfS3ek+bhSbU9QvhZfp9r+gdGqFI9NHSLOukd+rlTbuWuUPHup2u1qRJv8Oo+OTlWqLcEjICIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLTou6N47NaTJ4EWk3ycRJTLprSMTGuUONsMtXEfEYZ8LS3HFOb2AGj4Uj7SJtC8V6n2lziklLd5vOJsXavarCRzU5M423yiTan2sWO14mx7a7NS7aYWtbteR6BOnI11BJVq1+87Js4GTnQo1fYnnJCHzfFKtRNrvxZnj0bKb4MA4PUnKOVjh/rF2eZDDUq1D8XsEWfTEpKVagejvyPOjs5MFGeNDtnthEdARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWvTZWXABUxABk2ymVUZAPvuqw6G2DnNQ3qMDEe1Ktb1H6sXZuuojSrX3NMjnZB2r2aFU+9gJ+ewwADCfkM/T+7pDfp0AQH2jfMZXe7PaHDOrzS6v3aK2bkunRynvbwmIs5F2tZmE8bHy/ZN5aYFSbY8nTpyNbTqqVLu2KVacTfSmKtWOS41Ryrcdlc+C64xSm0e5+aN14mxLq9rtqiUof+y0Xyl/LPS4ZevgERAREWnR4w3ooYcegslkCjsVFKj9r4mIiAa+XnkKbvTo0XjnnXf+9kci++wzfUREpEmvdIbIyEg4nc7eKE1ERANEr7wGtH//fmRmZiIvLw8/+tGPcPjw4dNmfT4f3G532ImIiAa+Hm9AEyZMwMqVK7F+/XosX74c1dXVuPzyy+HxdP+uiIqKCjgcjtApOzu7p5dERER9UI83oBkzZuCf/umfUFhYiNLSUvzlL39Bc3Mz/vCHP3SbLy8vh8vlCp1qamp6eklERNQH9fq7AxISEjBixAgcOHCg28ttNhtsNrX3xRMRUf/X658DamlpwcGDB5GRkdHbf4qIiPqRHm9Ad955JyorK3Ho0CFs2rQJP/zhD2E2m3Httdf29J8iIqJ+rMefgjty5AiuvfZaNDY2IjU1FRMnTsSWLVuQmqo2CsOCCFiE/dFtSRbXjVdaBeCOkI+2+Hr36d/t151PN+wTZz/6+G2l2m6vfKyJP6g2QqjN06SUr6lvFmdb/PKxMACQFHdCnA0G05VqN/k7xVlzs3xUDgDE2uW1ASAqWX69WC1pSrWPG/JxRuYDXyjVNuxDxFlfXatS7SMR8nx6snxsDwB4DbXbYaypTpz1fZWgVNsySP6otfuQ2jijxC0fibNjC0eJsy0tsnFQPd6AVq9e3dMliYhoAOIsOCIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLTo9a9jOGvB/z0JxEfI5g4BAE44lJbxZWu9OPvF1s+Ualcd3irOxkcrlYYzQT5777hfbY7ZH6rl1wkARHl84mxKikWpdnNDkjibHK02q8+cYhdnTTlqs8OOf6k2lTDGJZ/xFRNjVard2iGfBbfLrFQaaZ3yWX2GVW2GnT2mTZw1W+X7EgCS9qt9M3OE1ynOdqTUKtX2VseJs+YhXynV/muV/PFw3Gd7xdnWVtmcPh4BERGRFmxARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpEWfHcXjbwX8wtVZo+TjJDqCnUrraPzoE3F21/6/KNXuOGETZ53parN4Ghvk43WqP/9SqXaSRe06bEk0ibPmVr9SbYtNPo7Fa1Ybx9LZIc/av1QbxWPPVBtnFDwgv63YjCal2pFW+SirIWmjlWp/HdgvX0eU2niiRI985FCw7YBS7bSiHKV8XKJ8dM9Q72Cl2q3J8ofp6mi1fZ8cIxuZAwAqA7ukWR4BERGRFmxARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERadFnZ8FZbSdPEgGTfB7Y59WHlNaxe9Pn4uzBL44o1fa1eOS1P5PPUwMA+xD5TLUAgkq1A15DKe+0yGf1BdGsVNvSOkycjUo7oVTb6pVnW61q10lSQGWyFpCYLN//LQG1u3X6oBJx1gT53DgASIxJE2cN45hS7WNt8us8Iy9TqfaPSouV8ocOyGeqfRX4Wqn20Bz5HMhgtMKNFsAg6yBxNskcK87azLLbK4+AiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItOizs+DaOnywdPhE2a/3HRbX/WDzy0rrONK4RZxNRbtS7RHTZ4uzw1Lls90AYP2OSnG24YBLqXakqUkpf9TtFGezBpmVagf88rla0UaUUm1/h3wGV0dWh1LtjsZUpXxnIFGcnVJkV6rd6Jbv/2NW+fxCAAg2y2+3MRHyWWMAUJAinzM3b5583h0A7G9Ru0984vpSnB2TlqBUO3tMnDh75aCLlWof65Bfh8mJFnHWZpVleQRERERaKDeg999/H1dffTUyMzNhMpnw6quvhl1uGAYeeOABZGRkIDo6GlOnTsX+/ft7ar1ERDRAKDcgr9eLoqIiLFu2rNvLlyxZgl/84hd47rnnsHXrVsTGxqK0tBTt7WpPTxER0cCm/BrQjBkzMGPGjG4vMwwDS5cuxX333YeZM2cCAF588UWkp6fj1Vdfxbx5885ttURENGD06GtA1dXVqK+vx9SpU0PnORwOTJgwAZs3b+72d3w+H9xud9iJiIgGvh5tQPX19QCA9PT0sPPT09NDl31TRUUFHA5H6JSdnd2TSyIioj5K+7vgysvL4XK5QqeamhrdSyIiovOgRxuQ03ny8x4NDQ1h5zc0NIQu+yabzYb4+PiwExERDXw92oByc3PhdDqxYcOG0Hlutxtbt25FSYnaB8GIiGhgU34XXEtLCw4cOBD6ubq6Gjt37kRSUhJycnKwcOFCPProoxg+fDhyc3Nx//33IzMzE7NmzerJdRMRUT+n3IC2bduGK6+8MvTzokWLAADz58/HypUrcffdd8Pr9eLmm29Gc3MzJk6ciPXr1yMqSm0MiqstEkGLbHk1+47L637ecObQ3ykYOVacvfiSf1CqneGQj6hZ//qGM4f+zqH35e8mdDWalGrbM5OV8o6AfKxJq5GjVNuX2v2bW7qt7VfbzqaOFnG2uLFTqbbXnH7m0N/JGSYbSwUAbp98vAoAuFtrxdmvG4NKtSPs8us8PW20Uu2YZPkIrt375aNyAGB7ldq7cWuq5Y8rZTfLH1MAIDJLftvq+Eo+PgoAgnb5WC1/onz/+C2ykU3KDWjy5MkwDOO0l5tMJjz88MN4+OGHVUsTEdEFRPu74IiI6MLEBkRERFqwARERkRZsQEREpAUbEBERacEGREREWrABERGRFmxARESkBRsQERFpwQZERERaKI/iOV9snW2I6rCIsieC1eK6Fp9XaR0TS/9ZnB1eNEqp9icv/16c/dWfK5VqD2q3irORnfJZYAAQ4Vab69dmtYmzKQGHUu246DpxtiMlRql2UpR8HpgvOUOp9hhLolK+3SefNearPqhUO9KZJM4WZKk9ZES3y+c0Oga3K9UemnGxONsWkM/1A4CsK4uU8jE/GCTO5hWq7fsvD8jnta2t3qNUO//yGeLs5Bz5/EK3WzaTjkdARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERadFnR/GYY4/DbPeJsvX7a8R1P2lWGztz1XH5OBbXVx1KtTe+f0CcTYlQW3drsnxshq1NbQRKdKxdKZ+UKR89kmXpVKrdaowUZ01+l1LtptQ4cdbwmZVqx6T4lfLGUZM4mzokRam2b5B8FE/nMaXS8KTKr3NnrHxkEwD8YN50cfYPq19Xqj3cJh9lBQBjfjRCnG3ad1Sp9taP5fdPV0A2AueU3Oh8cTYYJ98/QUOW5REQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWrABERGRFn12Fpz/xGD4AvGibHuqLAcA/mNqM7s2HfxEnN26+02l2ruqNomz0ZYEpdqREfKZahHJuUq1UzLVZsGlZSvsH89xpdqBr+XZ2EhDqbY7Qj7bLwMOpdr7XG1K+WpLmjj7Y6fabL+24/Ir0ReVrVQ7Yr9XnE2ckKdU23v4S3E22vSVUu0x49X2p7dKPqvviV/8Van2ts/ka5l909VKtdNGDBVnHUF5XZMwyyMgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItOi7o3iSmuGPl81zSAmkiOueaFcbx/LVmj3irCuyUam21SwfC2RODSjVRpt8NIgVSUqlk6C2lrovmsXZjlS/Uu3MBPmYkoig2himuEb5beWTGLV1/8f//X9KeUuqfB89//wapdr/x3ZInK0yy0frAIDZZBNn4+pq1WoPk4+QKhg+Wan2ni/ko6wA4Ldvycdwff652v2ndOIocXZG4USl2gU5ieJsRIRLIeuW5cQViYiIehAbEBERaaHcgN5//31cffXVyMzMhMlkwquvvhp2+fXXXw+TyRR2mj59ek+tl4iIBgjlBuT1elFUVIRly5adNjN9+nTU1dWFTi+99NI5LZKIiAYe5TchzJgxAzNmzPjWjM1mg9PpPOtFERHRwNcrrwFt3LgRaWlpyM/Px6233orGxtO/O8zn88HtdoediIho4OvxBjR9+nS8+OKL2LBhA5544glUVlZixowZ6Ozs/m2NFRUVcDgcoVN2tto3LhIRUf/U458DmjdvXujfY8eORWFhIYYOHYqNGzdiypQpXfLl5eVYtGhR6Ge3280mRER0Aej1t2Hn5eUhJSUFBw4c6PZym82G+Pj4sBMREQ18vd6Ajhw5gsbGRmRkZPT2nyIion5E+Sm4lpaWsKOZ6upq7Ny5E0lJSUhKSsLixYsxZ84cOJ1OHDx4EHfffTeGDRuG0tLSHl04ERH1b8oNaNu2bbjyyitDP596/Wb+/PlYvnw5du3ahV//+tdobm5GZmYmpk2bhkceeQQ2m3wmFABEeyyIgUWUTRgpnwV3yWC1I7GOSPnsK/PxZqXasHjktS1xSqUT2+TzplyIVaptiZfPhAKA1ECMOGtujVaqHWuRzQsEgOPNajO40m3y2pnF45Rqf1r9uVL+8HtN4uz1ih/8/uMvloqzUy5VmxsYO2ykOOtJT1Oq/cr67eLsnha1GXbVn+5Wyp+AXZy97IrvK9Ued2mxOJuekaVU2xwtn3cY9Mofg4JeWV3lBjR58mQYxumLv/mmfCgfERFduDgLjoiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLRgAyIiIi16/PuAeophsSNokc1XiggeE9c1R3yttI4Iq3z+UaTR/ZfunTbfLs+me5KVansCbeJs2uBWpdr+gMLCAdhS5LPm2lLVaruba8TZqLYhSrX/Z/82cfaa4slKtXdteU8pP84vnzX252S12+HoKyaIs+aovUq1k3LGirMr3q9Sqv3mhkpxNipZPo8QAEYPvUgpf824EnH24tEXK9XOHTNcnI3JcyrVtspHwSFg8YuznZYOUY5HQEREpAUbEBERacEGREREWrABERGRFmxARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnRZ0fxRHY2wtIpG/3QdNgnrvvFkTqldUSZ5fkOq3zkDABkW0zirD+qSan24MEjxdkWt3xsDwDAbFWKu0/IRyUlN6stxZcgHz2S4FCYOwIgsTFBnI1uVrtdHdq5RylfOO4icXbd82uVat+8aJ44m5ChNurFkXCROFsXsUOptjVG/vBVMma0Uu3Lv3eNUr6oIF+cHZstH6sEAObkYeKsPSh/LAQAPwLirLUzWpy1dJpFOR4BERGRFmxARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERadFnZ8E1Nnrh98n64wHPl+K6dZEtSusIRsnnuzl87Uq1c9PixVmP36NU217bLM4GotRuBlGtjUr5SL98fphpuHxuHADEQj6fyuRTm3l3z/wscXazW+066TiRrZQvKZLPGnvt8FGl2t8dNkmcfeCnv1KqPb74A3H26z8fVKo9dux4cba0+LtKtS8aL7++ASA99SJx1mGxKdXuiHDLwy75YwoARNoU1hItnxuHQFAU4xEQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWvTZUTztpkZEmnyibO2BWnHd/JTBSutINMlHW7iijyjV9lfJR8O0DbEo1Y5LrhFnvbFDlGpHGGrjPmymTnE24G9Vqj0oUj4uxx0vGw9yykUXDxdn3153Qqn27f9+lVJ+T5vsvgAAd1x/k1Lt3JHyUUkFl8hHHwHAr1e+Kc6mpKs9HOWPHifO2sfLx/YAwD9kTlDKI1J+G4dZsXS7/P5mJKjV7lRYtrtN/hgkzfIIiIiItGADIiIiLZQaUEVFBcaNG4e4uDikpaVh1qxZqKqqCsu0t7ejrKwMycnJsNvtmDNnDhoaGnp00URE1P8pNaDKykqUlZVhy5YtePvttxEIBDBt2jR4vd5Q5o477sDrr7+Ol19+GZWVlaitrcXs2bN7fOFERNS/Kb3qt379+rCfV65cibS0NGzfvh2TJk2Cy+XCCy+8gFWrVuGqq06+yLpixQqMHDkSW7ZswSWXXNKlps/ng8/3txdY3W6F774gIqJ+65xeA3K5XACApKQkAMD27dsRCAQwderUUKagoAA5OTnYvHlztzUqKirgcDhCp+xstS/qIiKi/umsG1AwGMTChQtx2WWXYcyYMQCA+vp6WK1WJCQkhGXT09NRX1/fbZ3y8nK4XK7QqaZG/vZhIiLqv876c0BlZWXYs2cPPvzww3NagM1mg03la2GJiGhAOKsjoAULFmDdunV47733kJX1tw8COp1O+P1+NDc3h+UbGhrgdMo/7EZERAOfUgMyDAMLFizAmjVr8O677yI3Nzfs8uLiYlgsFmzYsCF0XlVVFQ4fPoySkpKeWTEREQ0ISk/BlZWVYdWqVVi7di3i4uJCr+s4HA5ER0fD4XDgxhtvxKJFi5CUlIT4+HjcfvvtKCkp6fYdcEREdOFSakDLly8HAEyePDns/BUrVuD6668HADz99NOIiIjAnDlz4PP5UFpaimeffVZ5Ya7GTnS0d4iy0Rb5fKrIxBildUzILxBnDeQp1d61cYc4W+dSm5F2LEZ+nSQNSVCq7YiwK+VtDvnNrPV4lFJtc2SSOJsdk6pUu7VTfh0e2b1JqXb9oJ8o5b9f/D1xdq91i1LtR3/5mjg7NCCfjwcAjhz5fERnQqxS7TaFm8pov9r9vrOjSSnfZLGKs3GRattpi5TPATRB7fV0i8JzYBaj57NKDcgwzlw1KioKy5Ytw7Jly1RKExHRBYaz4IiISAs2ICIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEiLs/46ht4WEXccEXbZ+Jn2Ey5x3UOHZeN9TinOl8+fiGtxqNWecqk4G/mpfGwPAPh97eKsp1U+6gMAYhVvNbYW+bfcmhTGKgGASWHkUGbmMKXaH236szh77SWjlWr//Jf/qZRfm/xbcdYUFVCqfSIoz19/2/9Tqt32yVFxNtb+XaXacZDf770JaiOemr2JSvkYhbu++pfPBBWSavs+Qv4wgdgYvzjb2eGV/X35nyciIuo5bEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWrABERGRFmxARESkBRsQERFp0WdnwcV2pMPeYRdlBw0dJK7bVN2gtI5PP/pCnI2NULs6k4fHirMFRblKtfcpbGfzx7VKtTOvGKKUb2yVr+V4bbNSbdMRedYejFeqnTdafp0fr1WbYfdIhVMp/9nGJnH2C488CwCdiSnibEeb2v9ZJ+YWi7NNMfLZbgBgTkoWZ03px5RqJ1uGKuVVHkrVJi8CZjSLswF/hlJtm8JozAAs4qwPnaIcj4CIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSos+O4rEnJSAuLk6U9frc4rpfdB5UWkejd5g4OyJCvg4AiKxuk2cDCjMzAJRkyXftpmbZ2IxTju1Xuw7NFvmYmtjMPKXaiGgXRz/84M9KpUePv0yczctsUard2iEfHwUAabHy/ysGM2KUakd1yO5nANC4c7dS7WFF2eLssz9/Van28Bvko5I8X8vHXgGAZ7xZKS+/BgFbU1CpdjBOPl4n2upXqg2rfDutCscrVhiiHI+AiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItOizs+DibCmIt8WLsoPyh4vrRq7/UGkddVv3iLMdUYOVatfny+c25SbUKNWu3p8gzo4aL7/+AMBz2KSUP+g5Is4641xKtb+fM0acXX10p1LtHdt2ibNfp8tnBgJA5qCAUj5CPg4M2e0qk8mARGeaOPvYX95Xqm3s2iTOTp81Tam2I16+nUNi1B7qbEG12X4tJvlMNXui2lqaOi3ibLK/Val2OxLE2YigR5wNtMuuPx4BERGRFkoNqKKiAuPGjUNcXBzS0tIwa9YsVFVVhWUmT54Mk8kUdrrlllt6dNFERNT/KTWgyspKlJWVYcuWLXj77bcRCAQwbdo0eL3esNxNN92Eurq60GnJkiU9umgiIur/lJ6MXL9+fdjPK1euRFpaGrZv345JkyaFzo+JiYHT6eyZFRIR0YB0Tq8BuVwnXzBOSkoKO/93v/sdUlJSMGbMGJSXl6O19fQvjPl8Prjd7rATERENfGf9LrhgMIiFCxfisssuw5gxf3sn0nXXXYfBgwcjMzMTu3btwj333IOqqiq88sor3dapqKjA4sWLz3YZRETUT511AyorK8OePXvw4Yfhb2u++eabQ/8eO3YsMjIyMGXKFBw8eBBDhw7tUqe8vByLFi0K/ex2u5GdLf8aXyIi6p/OqgEtWLAA69atw/vvv4+srKxvzU6YMAEAcODAgW4bkM1mg81mO5tlEBFRP6bUgAzDwO233441a9Zg48aNyM3NPePv7Ny5EwCQkaHwSToiIhrwlBpQWVkZVq1ahbVr1yIuLg719fUAAIfDgejoaBw8eBCrVq3C9773PSQnJ2PXrl244447MGnSJBQWFvbKBhARUf+k1ICWL18O4OSHTf/eihUrcP3118NqteKdd97B0qVL4fV6kZ2djTlz5uC+++7rsQUTEdHAoPwU3LfJzs5GZWXlOS3olKR4C+LjZTOQxo0tEddtKW1SWsdbez8QZ+sOVCvVdh+Rz21qc6Uo1c4ZHBRnvQfkM54AALlqs+OSG+Tbaf5K7W34X8XK8664rq9Bfpua3fK5dDaz2uyw2LRopbzdknTm0Km1xKvNmWuLbhBnX3vtp0q139ohn6Xo9anNMcuLGiXOOrOjlGpbO9Tm6VkVHkl9LZ1KtR1x8tmLnZ0JSrXb4BNn46Os4qzZL8tyFhwREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWrABERGRFmxARESkBRsQERFpwQZERERanPX3AfW66KiTJ4ERCUPEZSNm5iktIyotWZz9OO6QUu29u7eKs4eaa5VqWyAf32FEOpRqR3+2TymfOSxBnHVXNyrV3rJTPvpp4pjLlGpH3nu5OHv868+Uare3tCnljZFDxNmhniNKtb+qTRVnn3n3faXaEZ/JRyVNKJ6hVHvEdy8WZ6MdmUq18e1Tx7qS391gi1QblQSY5VGr2kioRNjF2dZ2eV1fu+wrdngEREREWrABERGRFmxARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpEWfnQUXMJ08ScTnyuYOAcBF0d9VWkdHrHwGW2Z2ilLtjHR5///6RL1S7c76VnHWFKs2l6x1f5xS/liHfDaZ2epXqm3yxYqzccOLlGqPz79KnD2SnaNU2xQ8pJT/2iWfSfje1q+Uau//Yr84m5UjnxsHAOn5k8TZglFq95+RFoUZhvKRdCfJb1YnmU+Io83RSUqlE6Aw382IVqodNPnE2Riz/HG2Qzi+jkdARESkBRsQERFpwQZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERadF3R/EYJ08SMdZ4cd2vc9R6bkGHfOxMysXFSrUTHSPE2Ub3bqXarQH5rj3ikY8bAoDmxK+V8l/tE+5IAKZ4tbVccdXl4mzhuPFKtb/cK7/OI2OtSrUPB9XGGTV7D4iz1iFqtS9yXCrOOgqHKtW+JFc+XseZkK5Uuy1FPi8nGvLRVADg9sco5eM75fe3OHO7Um3ALk42mzuVKlsD8vE6Nou8bqcwyyMgIiLSgg2IiIi0YAMiIiIt2ICIiEgLNiAiItKCDYiIiLRgAyIiIi3YgIiISAs2ICIi0oINiIiItGADIiIiLfrsLLhgZxDBzqAsrLAVDoXZbgBgz5PnY+qUSsN5eaM8HMxWqt1wzCvOuk0Bpdqu/CalfP1w+Ryzww1qc+aGZY0SZzvdSqWRlpMnztqiHEq1M/1tSvlgWr446/lOi1Jti0s+x64jZpBS7cRs+W3LYjIr1bZ1yOe7BdrVZrtFm48o5Vujk8TZGMWH3Tb5KEUkQO06hF9hRp5Ffjsxo0OU4xEQERFpodSAli9fjsLCQsTHxyM+Ph4lJSV44403Qpe3t7ejrKwMycnJsNvtmDNnDhoaGnp80URE1P8pNaCsrCw8/vjj2L59O7Zt24arrroKM2fOxGeffQYAuOOOO/D666/j5ZdfRmVlJWprazF79uxeWTgREfVvSk9GXn311WE/P/bYY1i+fDm2bNmCrKwsvPDCC1i1ahWuuuoqAMCKFSswcuRIbNmyBZdccknPrZqIiPq9s34NqLOzE6tXr4bX60VJSQm2b9+OQCCAqVOnhjIFBQXIycnB5s2bT1vH5/PB7XaHnYiIaOBTbkC7d++G3W6HzWbDLbfcgjVr1mDUqFGor6+H1WpFQkJCWD49PR319fWnrVdRUQGHwxE6ZWervduLiIj6J+UGlJ+fj507d2Lr1q249dZbMX/+fOzdu/esF1BeXg6XyxU61dTUnHUtIiLqP5Q/B2S1WjFs2DAAQHFxMT7++GP8/Oc/x9y5c+H3+9Hc3Bx2FNTQ0ACn03naejabDTab/HvJiYhoYDjnzwEFg0H4fD4UFxfDYrFgw4YNocuqqqpw+PBhlJSUnOufISKiAUbpCKi8vBwzZsxATk4OPB4PVq1ahY0bN+LNN9+Ew+HAjTfeiEWLFiEpKQnx8fG4/fbbUVJSwnfAERFRF0oN6OjRo/jxj3+Muro6OBwOFBYW4s0338R3v/tdAMDTTz+NiIgIzJkzBz6fD6WlpXj22WfPbmHuVkRKlyefggG72a62ENlECQBAdJraSJtYc7I461eqDOQbwjFGAE5YXUq12x2nf0q1OwVj5WNQ2o5nKNWua5KPhrFGya9vAMgcJM8HFN+8aclsV8oHXYnibIJVbdxUa3u8OJucpLbugMKYJ1tA8b4ZIb9XWOzy0VQAgEC6UtwCkzhrKL7yYVIalSVfBwA0xEaJswoPswgIn1xTuiZeeOGFb708KioKy5Ytw7Jly1TKEhHRBYiz4IiISAs2ICIi0oINiIiItGADIiIiLdiAiIhICzYgIiLSgg2IiIi0YAMiIiIt2ICIiEgL5WnYvc0wDACAx+MR/45fZSsURtQAADrl0aDSyAwgwmwRZ1VH8Vjc8u30WNXmyLS3mZXywWCLvHaL2sgUr1de2+NRm7rudsv3j/IoHpPaLwQV1tJmVZgfBaBNfleDxaY4iicoz9sCarcrlVE8MKvdNxGwquUtvTeKxwf52v2Ko3g8CscgKqv2/O8Xi556PO+JmufFqcYzrLBA80qIiOhceDweOByO015uMs7Uos6zYDCI2tpaxMXFwWT6Wzd3u93Izs5GTU0N4uPlwxP7G27nwHEhbCPA7RxoemI7DcOAx+NBZmYmIiJOf5TV546AIiIikJWVddrL4+PjB/TOP4XbOXBcCNsIcDsHmnPdzm878jmFb0IgIiIt2ICIiEiLftOAbDYbHnzwQdhsau9k6m+4nQPHhbCNALdzoDmf29nn3oRAREQXhn5zBERERAMLGxAREWnBBkRERFqwARERkRZsQEREpEW/aUDLli3DkCFDEBUVhQkTJuCjjz7SvaQe9dBDD8FkMoWdCgr69zy8999/H1dffTUyMzNhMpnw6quvhl1uGAYeeOABZGRkIDo6GlOnTsX+/fv1LPYcnGk7r7/++i77dvr06XoWe5YqKiowbtw4xMXFIS0tDbNmzUJVVVVYpr29HWVlZUhOTobdbsecOXPQ0NCgacVnR7KdkydP7rI/b7nlFk0rPjvLly9HYWFhaNpBSUkJ3njjjdDl52tf9osG9Pvf/x6LFi3Cgw8+iE8++QRFRUUoLS3F0aNHdS+tR40ePRp1dXWh04cffqh7SefE6/WiqKgIy5Yt6/byJUuW4Be/+AWee+45bN26FbGxsSgtLUV7u9rEZd3OtJ0AMH369LB9+9JLL53HFZ67yspKlJWVYcuWLXj77bcRCAQwbdo0eL1/m15+xx134PXXX8fLL7+MyspK1NbWYvbs2RpXrU6ynQBw0003he3PJUuWaFrx2cnKysLjjz+O7du3Y9u2bbjqqqswc+ZMfPbZZwDO4740+oHx48cbZWVloZ87OzuNzMxMo6KiQuOqetaDDz5oFBUV6V5GrwFgrFmzJvRzMBg0nE6n8eSTT4bOa25uNmw2m/HSSy9pWGHP+OZ2GoZhzJ8/35g5c6aW9fSWo0ePGgCMyspKwzBO7juLxWK8/PLLocy+ffsMAMbmzZt1LfOcfXM7DcMwrrjiCuNf//Vf9S2qlyQmJhr/8z//c173ZZ8/AvL7/di+fTumTp0aOi8iIgJTp07F5s2bNa6s5+3fvx+ZmZnIy8vDj370Ixw+fFj3knpNdXU16uvrw/arw+HAhAkTBtx+BYCNGzciLS0N+fn5uPXWW9HY2Kh7SefE5XIBAJKSkgAA27dvRyAQCNufBQUFyMnJ6df785vbecrvfvc7pKSkYMyYMSgvL0dra6uO5fWIzs5OrF69Gl6vFyUlJed1X/a5adjfdPz4cXR2diI9PT3s/PT0dHz++eeaVtXzJkyYgJUrVyI/Px91dXVYvHgxLr/8cuzZswdxcXG6l9fj6uvrAaDb/XrqsoFi+vTpmD17NnJzc3Hw4EH8+7//O2bMmIHNmzfDbFb8ErY+IBgMYuHChbjsssswZswYACf3p9VqRUJCQli2P+/P7rYTAK677joMHjwYmZmZ2LVrF+655x5UVVXhlVde0bhadbt370ZJSQna29tht9uxZs0ajBo1Cjt37jxv+7LPN6ALxYwZM0L/LiwsxIQJEzB48GD84Q9/wI033qhxZXSu5s2bF/r32LFjUVhYiKFDh2Ljxo2YMmWKxpWdnbKyMuzZs6ffv0Z5Jqfbzptvvjn077FjxyIjIwNTpkzBwYMHMXTo0PO9zLOWn5+PnTt3wuVy4Y9//CPmz5+PysrK87qGPv8UXEpKCsxmc5d3YDQ0NMDpdGpaVe9LSEjAiBEjcODAAd1L6RWn9t2Ftl8BIC8vDykpKf1y3y5YsADr1q3De++9F/a9XU6nE36/H83NzWH5/ro/T7ed3ZkwYQIA9Lv9abVaMWzYMBQXF6OiogJFRUX4+c9/fl73ZZ9vQFarFcXFxdiwYUPovGAwiA0bNqCkpETjynpXS0sLDh48iIyMDN1L6RW5ublwOp1h+9XtdmPr1q0Der8CwJEjR9DY2Niv9q1hGFiwYAHWrFmDd999F7m5uWGXFxcXw2KxhO3PqqoqHD58uF/tzzNtZ3d27twJAP1qf3YnGAzC5/Od333Zo29p6CWrV682bDabsXLlSmPv3r3GzTffbCQkJBj19fW6l9Zj/u3f/s3YuHGjUV1dbfz1r381pk6daqSkpBhHjx7VvbSz5vF4jB07dhg7duwwABhPPfWUsWPHDuOrr74yDMMwHn/8cSMhIcFYu3atsWvXLmPmzJlGbm6u0dbWpnnlar5tOz0ej3HnnXcamzdvNqqrq4133nnHuPjii43hw4cb7e3tupcuduuttxoOh8PYuHGjUVdXFzq1traGMrfccouRk5NjvPvuu8a2bduMkpISo6SkROOq1Z1pOw8cOGA8/PDDxrZt24zq6mpj7dq1Rl5enjFp0iTNK1dz7733GpWVlUZ1dbWxa9cu49577zVMJpPx1ltvGYZx/vZlv2hAhmEYzzzzjJGTk2NYrVZj/PjxxpYtW3QvqUfNnTvXyMjIMKxWqzFo0CBj7ty5xoEDB3Qv65y89957BoAup/nz5xuGcfKt2Pfff7+Rnp5u2Gw2Y8qUKUZVVZXeRZ+Fb9vO1tZWY9q0aUZqaqphsViMwYMHGzfddFO/+89Td9sHwFixYkUo09bWZtx2221GYmKiERMTY/zwhz806urq9C36LJxpOw8fPmxMmjTJSEpKMmw2mzFs2DDjrrvuMlwul96FK7rhhhuMwYMHG1ar1UhNTTWmTJkSaj6Gcf72Jb8PiIiItOjzrwEREdHAxAZERERasAEREZEWbEBERKQFGxAREWnBBkRERFqwARERkRZsQEREpAUbEBERacEGREREWrABERGRFv8fIsJTjct6hFIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "SAMPLE_NUM = 16\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "plt.imshow(np.moveaxis(x_batch[SAMPLE_NUM].numpy(), 0, -1))\n",
    "plt.title(y_batch[SAMPLE_NUM])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# Load the pre-trained ResNet18 model.\n",
    "model = torchvision.models.resnet18(weights='DEFAULT')\n",
    "\n",
    "# Freeze all the pre-trained layers.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Modify the last layer for MNIST\n",
    "num_classes = 10\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch num:1/235\tLoss:2.6263\n",
      "Batch num:2/235\tLoss:25.1076\n",
      "Batch num:3/235\tLoss:23.1554\n",
      "Batch num:4/235\tLoss:27.4883\n",
      "Batch num:5/235\tLoss:18.0134\n",
      "Batch num:6/235\tLoss:14.3099\n",
      "Batch num:7/235\tLoss:11.4375\n",
      "Batch num:8/235\tLoss:6.6901\n",
      "Batch num:9/235\tLoss:6.2084\n",
      "Batch num:10/235\tLoss:4.0386\n",
      "Batch num:11/235\tLoss:8.1189\n",
      "Batch num:12/235\tLoss:5.9070\n",
      "Batch num:13/235\tLoss:5.6278\n",
      "Batch num:14/235\tLoss:5.4418\n",
      "Batch num:15/235\tLoss:4.2891\n",
      "Batch num:16/235\tLoss:4.1592\n",
      "Batch num:17/235\tLoss:3.9144\n",
      "Batch num:18/235\tLoss:4.8787\n",
      "Batch num:19/235\tLoss:5.4575\n",
      "Batch num:20/235\tLoss:4.9076\n",
      "Batch num:21/235\tLoss:3.9220\n",
      "Batch num:22/235\tLoss:2.8573\n",
      "Batch num:23/235\tLoss:5.3998\n",
      "Batch num:24/235\tLoss:5.6732\n",
      "Batch num:25/235\tLoss:3.6862\n",
      "Batch num:26/235\tLoss:3.5768\n",
      "Batch num:27/235\tLoss:2.6629\n",
      "Batch num:28/235\tLoss:2.7807\n",
      "Batch num:29/235\tLoss:3.0094\n",
      "Batch num:30/235\tLoss:2.6552\n",
      "Batch num:31/235\tLoss:2.9682\n",
      "Batch num:32/235\tLoss:2.7273\n",
      "Batch num:33/235\tLoss:2.7877\n",
      "Batch num:34/235\tLoss:2.3488\n",
      "Batch num:35/235\tLoss:2.3625\n",
      "Batch num:36/235\tLoss:2.5918\n",
      "Batch num:37/235\tLoss:2.4526\n",
      "Batch num:38/235\tLoss:2.3061\n",
      "Batch num:39/235\tLoss:2.3944\n",
      "Batch num:40/235\tLoss:2.4209\n",
      "Batch num:41/235\tLoss:2.3595\n",
      "Batch num:42/235\tLoss:2.3604\n",
      "Batch num:43/235\tLoss:2.3674\n",
      "Batch num:44/235\tLoss:2.3690\n",
      "Batch num:45/235\tLoss:2.3879\n",
      "Batch num:46/235\tLoss:2.3860\n",
      "Batch num:47/235\tLoss:2.3855\n",
      "Batch num:48/235\tLoss:2.3417\n",
      "Batch num:49/235\tLoss:2.3144\n",
      "Batch num:50/235\tLoss:2.3641\n",
      "Batch num:51/235\tLoss:2.3883\n",
      "Batch num:52/235\tLoss:2.3611\n",
      "Batch num:53/235\tLoss:2.3143\n",
      "Batch num:54/235\tLoss:2.3108\n",
      "Batch num:55/235\tLoss:2.4050\n",
      "Batch num:56/235\tLoss:2.3359\n",
      "Batch num:57/235\tLoss:2.3706\n",
      "Batch num:58/235\tLoss:2.3620\n",
      "Batch num:59/235\tLoss:2.3132\n",
      "Batch num:60/235\tLoss:2.3022\n",
      "Batch num:61/235\tLoss:2.3055\n",
      "Batch num:62/235\tLoss:2.3113\n",
      "Batch num:63/235\tLoss:2.3301\n",
      "Batch num:64/235\tLoss:2.3214\n",
      "Batch num:65/235\tLoss:2.3753\n",
      "Batch num:66/235\tLoss:2.3292\n",
      "Batch num:67/235\tLoss:2.3489\n",
      "Batch num:68/235\tLoss:2.3126\n",
      "Batch num:69/235\tLoss:2.3093\n",
      "Batch num:70/235\tLoss:2.3107\n",
      "Batch num:71/235\tLoss:2.3004\n",
      "Batch num:72/235\tLoss:2.3334\n",
      "Batch num:73/235\tLoss:2.3154\n",
      "Batch num:74/235\tLoss:2.3150\n",
      "Batch num:75/235\tLoss:2.2982\n",
      "Batch num:76/235\tLoss:2.3184\n",
      "Batch num:77/235\tLoss:2.3081\n",
      "Batch num:78/235\tLoss:2.3125\n",
      "Batch num:79/235\tLoss:2.3292\n",
      "Batch num:80/235\tLoss:2.3179\n",
      "Batch num:81/235\tLoss:2.3017\n",
      "Batch num:82/235\tLoss:2.3207\n",
      "Batch num:83/235\tLoss:2.3125\n",
      "Batch num:84/235\tLoss:2.3084\n",
      "Batch num:85/235\tLoss:2.3214\n",
      "Batch num:86/235\tLoss:2.3167\n",
      "Batch num:87/235\tLoss:2.2968\n",
      "Batch num:88/235\tLoss:2.2980\n",
      "Batch num:89/235\tLoss:2.3003\n",
      "Batch num:90/235\tLoss:2.3308\n",
      "Batch num:91/235\tLoss:2.3170\n",
      "Batch num:92/235\tLoss:2.3289\n",
      "Batch num:93/235\tLoss:2.3067\n",
      "Batch num:94/235\tLoss:2.2985\n",
      "Batch num:95/235\tLoss:2.3216\n",
      "Batch num:96/235\tLoss:2.3088\n",
      "Batch num:97/235\tLoss:2.3045\n",
      "Batch num:98/235\tLoss:2.2977\n",
      "Batch num:99/235\tLoss:2.3022\n",
      "Batch num:100/235\tLoss:2.3012\n",
      "Batch num:101/235\tLoss:2.2970\n",
      "Batch num:102/235\tLoss:2.3062\n",
      "Batch num:103/235\tLoss:2.3038\n",
      "Batch num:104/235\tLoss:2.2869\n",
      "Batch num:105/235\tLoss:2.3108\n",
      "Batch num:106/235\tLoss:2.3120\n",
      "Batch num:107/235\tLoss:2.3039\n",
      "Batch num:108/235\tLoss:2.3090\n",
      "Batch num:109/235\tLoss:2.3095\n",
      "Batch num:110/235\tLoss:2.3125\n",
      "Batch num:111/235\tLoss:2.3081\n",
      "Batch num:112/235\tLoss:2.3008\n",
      "Batch num:113/235\tLoss:2.3001\n",
      "Batch num:114/235\tLoss:2.3061\n",
      "Batch num:115/235\tLoss:2.3051\n",
      "Batch num:116/235\tLoss:2.3069\n",
      "Batch num:117/235\tLoss:2.2971\n",
      "Batch num:118/235\tLoss:2.3020\n",
      "Batch num:119/235\tLoss:2.3098\n",
      "Batch num:120/235\tLoss:2.3119\n",
      "Batch num:121/235\tLoss:2.3098\n",
      "Batch num:122/235\tLoss:2.3102\n",
      "Batch num:123/235\tLoss:2.3108\n",
      "Batch num:124/235\tLoss:2.3015\n",
      "Batch num:125/235\tLoss:2.3029\n",
      "Batch num:126/235\tLoss:2.3048\n",
      "Batch num:127/235\tLoss:2.3092\n",
      "Batch num:128/235\tLoss:2.2997\n",
      "Batch num:129/235\tLoss:2.3032\n",
      "Batch num:130/235\tLoss:2.2951\n",
      "Batch num:131/235\tLoss:2.2943\n",
      "Batch num:132/235\tLoss:2.3190\n",
      "Batch num:133/235\tLoss:2.3067\n",
      "Batch num:134/235\tLoss:2.2996\n",
      "Batch num:135/235\tLoss:2.3092\n",
      "Batch num:136/235\tLoss:2.3004\n",
      "Batch num:137/235\tLoss:2.3031\n",
      "Batch num:138/235\tLoss:2.3022\n",
      "Batch num:139/235\tLoss:2.3028\n",
      "Batch num:140/235\tLoss:2.3015\n",
      "Batch num:141/235\tLoss:2.3128\n",
      "Batch num:142/235\tLoss:2.2978\n",
      "Batch num:143/235\tLoss:2.3063\n",
      "Batch num:144/235\tLoss:2.3066\n",
      "Batch num:145/235\tLoss:2.3033\n",
      "Batch num:146/235\tLoss:2.3092\n",
      "Batch num:147/235\tLoss:2.3030\n",
      "Batch num:148/235\tLoss:2.3063\n",
      "Batch num:149/235\tLoss:2.3015\n",
      "Batch num:150/235\tLoss:2.3029\n",
      "Batch num:151/235\tLoss:2.3026\n",
      "Batch num:152/235\tLoss:2.3075\n",
      "Batch num:153/235\tLoss:2.3065\n",
      "Batch num:154/235\tLoss:2.2994\n",
      "Batch num:155/235\tLoss:2.3120\n",
      "Batch num:156/235\tLoss:2.2975\n",
      "Batch num:157/235\tLoss:2.3032\n",
      "Batch num:158/235\tLoss:2.2997\n",
      "Batch num:159/235\tLoss:2.3025\n",
      "Batch num:160/235\tLoss:2.3006\n",
      "Batch num:161/235\tLoss:2.3046\n",
      "Batch num:162/235\tLoss:2.3006\n",
      "Batch num:163/235\tLoss:2.2993\n",
      "Batch num:164/235\tLoss:2.3048\n",
      "Batch num:165/235\tLoss:2.3022\n",
      "Batch num:166/235\tLoss:2.2962\n",
      "Batch num:167/235\tLoss:2.3040\n",
      "Batch num:168/235\tLoss:2.3031\n",
      "Batch num:169/235\tLoss:2.3011\n",
      "Batch num:170/235\tLoss:2.3020\n",
      "Batch num:171/235\tLoss:2.3089\n",
      "Batch num:172/235\tLoss:2.2959\n",
      "Batch num:173/235\tLoss:2.3135\n",
      "Batch num:174/235\tLoss:2.2984\n",
      "Batch num:175/235\tLoss:2.3083\n",
      "Batch num:176/235\tLoss:2.3088\n",
      "Batch num:177/235\tLoss:2.3105\n",
      "Batch num:178/235\tLoss:2.3037\n",
      "Batch num:179/235\tLoss:2.2935\n",
      "Batch num:180/235\tLoss:2.3093\n",
      "Batch num:181/235\tLoss:2.3040\n",
      "Batch num:182/235\tLoss:2.3006\n",
      "Batch num:183/235\tLoss:2.2992\n",
      "Batch num:184/235\tLoss:2.3088\n",
      "Batch num:185/235\tLoss:2.3040\n",
      "Batch num:186/235\tLoss:2.3068\n",
      "Batch num:187/235\tLoss:2.3008\n",
      "Batch num:188/235\tLoss:2.3036\n",
      "Batch num:189/235\tLoss:2.3011\n",
      "Batch num:190/235\tLoss:2.3018\n",
      "Batch num:191/235\tLoss:2.3031\n",
      "Batch num:192/235\tLoss:2.2993\n",
      "Batch num:193/235\tLoss:2.3008\n",
      "Batch num:194/235\tLoss:2.3011\n",
      "Batch num:195/235\tLoss:2.2984\n",
      "Batch num:196/235\tLoss:2.2949\n",
      "Batch num:197/235\tLoss:2.2992\n",
      "Batch num:198/235\tLoss:2.3090\n",
      "Batch num:199/235\tLoss:2.2989\n",
      "Batch num:200/235\tLoss:2.3008\n",
      "Batch num:201/235\tLoss:2.3012\n",
      "Batch num:202/235\tLoss:2.3011\n",
      "Batch num:203/235\tLoss:2.3070\n",
      "Batch num:204/235\tLoss:2.2978\n",
      "Batch num:205/235\tLoss:2.3009\n",
      "Batch num:206/235\tLoss:2.2993\n",
      "Batch num:207/235\tLoss:2.3078\n",
      "Batch num:208/235\tLoss:2.3094\n",
      "Batch num:209/235\tLoss:2.3149\n",
      "Batch num:210/235\tLoss:2.3013\n",
      "Batch num:211/235\tLoss:2.2945\n",
      "Batch num:212/235\tLoss:2.3023\n",
      "Batch num:213/235\tLoss:2.3084\n",
      "Batch num:214/235\tLoss:2.3003\n",
      "Batch num:215/235\tLoss:2.3067\n",
      "Batch num:216/235\tLoss:2.3040\n",
      "Batch num:217/235\tLoss:2.3053\n",
      "Batch num:218/235\tLoss:2.3024\n",
      "Batch num:219/235\tLoss:2.3004\n",
      "Batch num:220/235\tLoss:2.3014\n",
      "Batch num:221/235\tLoss:2.3014\n",
      "Batch num:222/235\tLoss:2.3048\n",
      "Batch num:223/235\tLoss:2.3124\n",
      "Batch num:224/235\tLoss:2.3036\n",
      "Batch num:225/235\tLoss:2.3020\n",
      "Batch num:226/235\tLoss:2.3015\n",
      "Batch num:227/235\tLoss:2.3020\n",
      "Batch num:228/235\tLoss:2.2957\n",
      "Batch num:229/235\tLoss:2.2936\n",
      "Batch num:230/235\tLoss:2.3078\n",
      "Batch num:231/235\tLoss:2.3007\n",
      "Batch num:232/235\tLoss:2.3101\n",
      "Batch num:233/235\tLoss:2.3071\n",
      "Batch num:234/235\tLoss:2.3172\n",
      "Batch num:235/235\tLoss:2.3135\n",
      "Epoch 0/2 - Loss: 2.3134613037109375 - Test accuracy: 0.13671875\n",
      "Batch num:1/235\tLoss:2.3035\n",
      "Batch num:2/235\tLoss:2.2975\n",
      "Batch num:3/235\tLoss:2.3077\n",
      "Batch num:4/235\tLoss:2.3060\n",
      "Batch num:5/235\tLoss:2.3040\n",
      "Batch num:6/235\tLoss:2.3101\n",
      "Batch num:7/235\tLoss:2.3059\n",
      "Batch num:8/235\tLoss:2.2972\n",
      "Batch num:9/235\tLoss:2.3017\n",
      "Batch num:10/235\tLoss:2.3001\n",
      "Batch num:11/235\tLoss:2.3097\n",
      "Batch num:12/235\tLoss:2.3106\n",
      "Batch num:13/235\tLoss:2.3010\n",
      "Batch num:14/235\tLoss:2.3001\n",
      "Batch num:15/235\tLoss:2.3011\n",
      "Batch num:16/235\tLoss:2.3049\n",
      "Batch num:17/235\tLoss:2.3066\n",
      "Batch num:18/235\tLoss:2.3053\n",
      "Batch num:19/235\tLoss:2.3030\n",
      "Batch num:20/235\tLoss:2.3120\n",
      "Batch num:21/235\tLoss:2.2953\n",
      "Batch num:22/235\tLoss:2.3037\n",
      "Batch num:23/235\tLoss:2.3060\n",
      "Batch num:24/235\tLoss:2.3046\n",
      "Batch num:25/235\tLoss:2.2999\n",
      "Batch num:26/235\tLoss:2.3073\n",
      "Batch num:27/235\tLoss:2.3039\n",
      "Batch num:28/235\tLoss:2.3069\n",
      "Batch num:29/235\tLoss:2.2956\n",
      "Batch num:30/235\tLoss:2.2981\n",
      "Batch num:31/235\tLoss:2.3101\n",
      "Batch num:32/235\tLoss:2.3031\n",
      "Batch num:33/235\tLoss:2.2999\n",
      "Batch num:34/235\tLoss:2.3025\n",
      "Batch num:35/235\tLoss:2.2923\n",
      "Batch num:36/235\tLoss:2.3007\n",
      "Batch num:37/235\tLoss:2.3219\n",
      "Batch num:38/235\tLoss:2.3150\n",
      "Batch num:39/235\tLoss:2.3018\n",
      "Batch num:40/235\tLoss:2.3111\n",
      "Batch num:41/235\tLoss:2.3011\n",
      "Batch num:42/235\tLoss:2.3001\n",
      "Batch num:43/235\tLoss:2.3033\n",
      "Batch num:44/235\tLoss:2.3127\n",
      "Batch num:45/235\tLoss:2.3032\n",
      "Batch num:46/235\tLoss:2.3021\n",
      "Batch num:47/235\tLoss:2.3043\n",
      "Batch num:48/235\tLoss:2.3101\n",
      "Batch num:49/235\tLoss:2.3035\n",
      "Batch num:50/235\tLoss:2.3063\n",
      "Batch num:51/235\tLoss:2.3064\n",
      "Batch num:52/235\tLoss:2.3091\n",
      "Batch num:53/235\tLoss:2.3039\n",
      "Batch num:54/235\tLoss:2.3067\n",
      "Batch num:55/235\tLoss:2.3068\n",
      "Batch num:56/235\tLoss:2.3037\n",
      "Batch num:57/235\tLoss:2.3000\n",
      "Batch num:58/235\tLoss:2.2952\n",
      "Batch num:59/235\tLoss:2.3027\n",
      "Batch num:60/235\tLoss:2.3029\n",
      "Batch num:61/235\tLoss:2.2934\n",
      "Batch num:62/235\tLoss:2.3042\n",
      "Batch num:63/235\tLoss:2.3016\n",
      "Batch num:64/235\tLoss:2.3022\n",
      "Batch num:65/235\tLoss:2.3131\n",
      "Batch num:66/235\tLoss:2.3086\n",
      "Batch num:67/235\tLoss:2.3103\n",
      "Batch num:68/235\tLoss:2.2954\n",
      "Batch num:69/235\tLoss:2.3075\n",
      "Batch num:70/235\tLoss:2.3059\n",
      "Batch num:71/235\tLoss:2.3087\n",
      "Batch num:72/235\tLoss:2.2926\n",
      "Batch num:73/235\tLoss:2.3005\n",
      "Batch num:74/235\tLoss:2.2966\n",
      "Batch num:75/235\tLoss:2.3015\n",
      "Batch num:76/235\tLoss:2.3051\n",
      "Batch num:77/235\tLoss:2.2965\n",
      "Batch num:78/235\tLoss:2.2991\n",
      "Batch num:79/235\tLoss:2.3002\n",
      "Batch num:80/235\tLoss:2.3136\n",
      "Batch num:81/235\tLoss:2.3096\n",
      "Batch num:82/235\tLoss:2.3027\n",
      "Batch num:83/235\tLoss:2.3024\n",
      "Batch num:84/235\tLoss:2.3151\n",
      "Batch num:85/235\tLoss:2.3057\n",
      "Batch num:86/235\tLoss:2.3096\n",
      "Batch num:87/235\tLoss:2.3022\n",
      "Batch num:88/235\tLoss:2.2990\n",
      "Batch num:89/235\tLoss:2.3043\n",
      "Batch num:90/235\tLoss:2.3019\n",
      "Batch num:91/235\tLoss:2.3003\n",
      "Batch num:92/235\tLoss:2.3028\n",
      "Batch num:93/235\tLoss:2.3013\n",
      "Batch num:94/235\tLoss:2.3045\n",
      "Batch num:95/235\tLoss:2.3118\n",
      "Batch num:96/235\tLoss:2.3059\n",
      "Batch num:97/235\tLoss:2.3112\n",
      "Batch num:98/235\tLoss:2.3109\n",
      "Batch num:99/235\tLoss:2.3050\n",
      "Batch num:100/235\tLoss:2.3082\n",
      "Batch num:101/235\tLoss:2.3075\n",
      "Batch num:102/235\tLoss:2.3016\n",
      "Batch num:103/235\tLoss:2.2998\n",
      "Batch num:104/235\tLoss:2.2907\n",
      "Batch num:105/235\tLoss:2.3033\n",
      "Batch num:106/235\tLoss:2.3019\n",
      "Batch num:107/235\tLoss:2.3007\n",
      "Batch num:108/235\tLoss:2.3025\n",
      "Batch num:109/235\tLoss:2.2982\n",
      "Batch num:110/235\tLoss:2.3035\n",
      "Batch num:111/235\tLoss:2.3330\n",
      "Batch num:112/235\tLoss:2.3156\n",
      "Batch num:113/235\tLoss:2.3085\n",
      "Batch num:114/235\tLoss:2.2988\n",
      "Batch num:115/235\tLoss:2.3049\n",
      "Batch num:116/235\tLoss:2.3080\n",
      "Batch num:117/235\tLoss:2.3000\n",
      "Batch num:118/235\tLoss:2.2922\n",
      "Batch num:119/235\tLoss:2.3020\n",
      "Batch num:120/235\tLoss:2.3261\n",
      "Batch num:121/235\tLoss:2.2964\n",
      "Batch num:122/235\tLoss:2.3077\n",
      "Batch num:123/235\tLoss:2.3051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m     20\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss(preds, y_batch)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch num:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_train_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_EPOCHS= 2\n",
    "MODEL_LR = 1.0e-2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=MODEL_LR, momentum=MOMENTUM)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=MODEL_LR)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=MODEL_LR)\n",
    "\n",
    "x_test_batch, y_test_batch = next(iter(test_loader))\n",
    "num_train_batches = len(train_set) // BATCH_SIZE_TRAIN +  1 if len(train_set) % BATCH_SIZE_TRAIN > 0 else 0\n",
    "\n",
    "for epoch in range(MODEL_EPOCHS):\n",
    "    batch_num = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        batch_num += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(x_batch)\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()        \n",
    "        optimizer.step()\n",
    "        print(f'Batch num:{batch_num}/{num_train_batches}\\tLoss:{loss_value.item():.4f}\\r')\n",
    "\n",
    "    test_preds = model.forward(x_test_batch)        \n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test_batch).float().mean() \n",
    "    print(f'Epoch {epoch}/{MODEL_EPOCHS} - Loss: {loss_value.item()} - Test accuracy: {accuracy}')  \n",
    "    \n",
    "model.eval()\n",
    "\n",
    "test_hits = 0\n",
    "for x_batch, y_batch in test_loader:\n",
    "    test_preds = model.forward(x_batch)        \n",
    "    test_hits += (test_preds.argmax(dim=1) == y_batch).float().sum()\n",
    "print(test_hits / len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(PROJ_DIR,'assets','models','cmnist-resnet18.pth'))\n",
    "\n",
    "import json\n",
    "MODELS_PATH = os.path.join(PROJ_DIR,'assets','models')\n",
    "with open(os.path.join(MODELS_PATH, 'model-accuracies.json')) as fIn:\n",
    "    models = json.load(fIn)\n",
    "models['cmnist-resnet18'] = accuracy.item()\n",
    "with open(os.path.join(MODELS_PATH, 'model-accuracies.json'), 'w') as fOut:\n",
    "    json.dump(models, fOut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-anna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
