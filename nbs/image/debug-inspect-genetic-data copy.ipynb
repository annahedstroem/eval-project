{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2a87bd-f32b-4a02-85b0-ab3c182a2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "\n",
    "import xai_faithfulness_experiments_lib_edits as ff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e320534-158a-402d-b392-1aed8fe94c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "l 8\n",
      "new_l 574\n",
      "l 2\n",
      "new_l 481\n",
      "l 8\n",
      "new_l 574\n",
      "l 5\n",
      "new_l 566\n",
      "l 2\n",
      "new_l 481\n",
      "l 1\n",
      "new_l 217\n",
      "l 2\n",
      "new_l 481\n",
      "l 8\n",
      "new_l 574\n",
      "l 9\n",
      "new_l 701\n",
      "l 8\n",
      "new_l 574\n",
      "l 7\n",
      "new_l 571\n",
      "l 6\n",
      "new_l 569\n",
      "l 0\n",
      "new_l 0\n",
      "l 2\n",
      "new_l 481\n",
      "l 3\n",
      "new_l 491\n",
      "l 5\n",
      "new_l 566\n",
      "l 2\n",
      "new_l 481\n",
      "l 3\n",
      "new_l 491\n",
      "l 5\n",
      "new_l 566\n",
      "l 0\n",
      "new_l 0\n",
      "l 0\n",
      "new_l 0\n",
      "l 1\n",
      "new_l 217\n",
      "l 9\n",
      "new_l 701\n",
      "l 8\n",
      "new_l 574\n",
      "l 5\n",
      "new_l 566\n",
      "l 5\n",
      "new_l 566\n",
      "l 6\n",
      "new_l 569\n",
      "l 5\n",
      "new_l 566\n",
      "l 0\n",
      "new_l 0\n",
      "l 4\n",
      "new_l 497\n",
      "l 1\n",
      "new_l 217\n",
      "l 5\n",
      "new_l 566\n",
      "l 5\n",
      "new_l 566\n",
      "l 4\n",
      "new_l 497\n",
      "l 7\n",
      "new_l 571\n",
      "l 1\n",
      "new_l 217\n",
      "l 9\n",
      "new_l 701\n",
      "l 1\n",
      "new_l 217\n",
      "l 4\n",
      "new_l 497\n",
      "l 6\n",
      "new_l 569\n",
      "l 7\n",
      "new_l 571\n",
      "l 2\n",
      "new_l 481\n",
      "l 2\n",
      "new_l 481\n",
      "l 4\n",
      "new_l 497\n",
      "l 0\n",
      "new_l 0\n",
      "l 7\n",
      "new_l 571\n",
      "l 9\n",
      "new_l 701\n",
      "l 8\n",
      "new_l 574\n",
      "l 4\n",
      "new_l 497\n",
      "l 0\n",
      "new_l 0\n",
      "l 9\n",
      "new_l 701\n",
      "l 0\n",
      "new_l 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import PIL\n",
    "batch_size = 256\n",
    "IMAGENETTE_PATH = os.path.join(PROJ_DIR, 'data', 'imagenette')\n",
    "IMAGENETTE_CLASS_DICT = {'n01440764':0, 'n02102040':217, 'n02979186':481, 'n03000684':491, 'n03028079':497, 'n03394916':566, 'n03417042':569, 'n03425413':571, 'n03445777':574, 'n03888257':701}\n",
    "IMAGENETTE_CLASS_DIRS = sorted(list(IMAGENETTE_CLASS_DICT.keys()))\n",
    "\n",
    "def get_imagenette_dataset(is_test=False, project_path:str='../'):\n",
    "    ''' Loads the imagenette dataset. By default it loads the train partition, unless otherwise indicated'''\n",
    "    def transform_labels(l):\n",
    "        print('l', l)\n",
    "        new_l = IMAGENETTE_CLASS_DICT[IMAGENETTE_CLASS_DIRS[l]]\n",
    "        print('new_l', new_l)\n",
    "        return new_l\n",
    "\n",
    "    def load_sample(path: str) -> dict:\n",
    "        \"\"\"Read data as image and path. \"\"\"\n",
    "        return PIL.Image.open(path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "    DATA_TRAIN_PATH = os.path.join(project_path, IMAGENETTE_PATH, 'train')\n",
    "    DATA_TEST_PATH = os.path.join(project_path, IMAGENETTE_PATH, 'val')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Resize(256), \n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "    # Load test data and make loaders.\n",
    "    dataset = torchvision.datasets.DatasetFolder(DATA_TEST_PATH if is_test else DATA_TRAIN_PATH, \n",
    "                                                loader=load_sample, \n",
    "                                                is_valid_file=lambda path: path[-5:]==\".JPEG\",\n",
    "                                                transform=transform, # Should we do this here or work with the full images for the RL process??\n",
    "                                                target_transform=transform_labels)\n",
    "    return dataset\n",
    "\n",
    "def get_imagenette_train_loader(batch_size:int = 24, project_path:str='../') -> torch.utils.data.DataLoader:\n",
    "    dataset = get_imagenette_dataset(project_path=project_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, shuffle=False, batch_size=batch_size)\n",
    "    return train_loader\n",
    "\n",
    "def get_imagenette_test_loader(batch_size:int = 24, project_path:str='../') -> torch.utils.data.DataLoader:\n",
    "    dataset = get_imagenette_dataset(True, project_path=project_path)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, shuffle=False, batch_size=batch_size)\n",
    "    return test_loader\n",
    "\n",
    "train_loader = get_imagenette_train_loader(52, PROJ_DIR)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (x_train, y_train) = next(examples)\n",
    "\n",
    "MODEL_NAME = 'resnet50w'\n",
    "# Load model\n",
    "class ResNet50Wrapper(torch.nn.Module):\n",
    "    def __init__(self, weights='DEFAULT', device='cpu'):\n",
    "        super(ResNet50Wrapper, self).__init__()\n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet50 = torchvision.models.resnet50(weights=weights).to(device)\n",
    "        # Set the model to evaluation mode\n",
    "        self.resnet50.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the pre-trained ResNet50\n",
    "        logits = self.resnet50(x)\n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "\n",
    "# Use the wrapper\n",
    "network = ResNet50Wrapper(weights=\"DEFAULT\", device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f0f07f-880b-4882-a25d-8c5030e160b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10\n",
      "tensor(571, device='cuda:0') tensor(0.1561, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(571, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_NUM = 10\n",
    "print('Processing', SAMPLE_NUM)\n",
    "row = x_train[SAMPLE_NUM].clone().detach().to(device)\n",
    "label = y_train[SAMPLE_NUM].clone().detach().to(device)\n",
    "\n",
    "print(network(row.unsqueeze(dim=0)).argmax(), network(row.unsqueeze(dim=0)).max())\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
