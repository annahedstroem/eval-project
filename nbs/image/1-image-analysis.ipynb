{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST analysis\n",
    "\n",
    "This notebook loads the MNIST dataset and a pretrained model and computes Qinv and Qbas for 100.000 random rankings.\n",
    "\n",
    ":warning:\n",
    "# There's a .py version for this script in the src folder which is the one that should be used to generate the files:\n",
    "`src/extract_mnist_measures.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "DATASET = 'mnist'\n",
    "MODEL_NAME = 'ood-mean'\n",
    "GENERATOR = '_genetic'\n",
    "DATASET_PATH = os.path.join(PROJ_DIR,'assets', 'data', f'{DATASET}.npz')\n",
    "MODEL_PATH = os.path.join(PROJ_DIR,'assets', 'models', f'{DATASET}-{MODEL_NAME}-mlp.pth')\n",
    "SAMPLE_NUM = 10 # Select one of the training examples in the batch to be explained\n",
    "\n",
    "# Load dataset\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "MNIST_PATH = os.path.join(PROJ_DIR, 'data', 'mnist')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(MNIST_PATH, train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size, shuffle=True)\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (x_train, y_train) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MNISTClassifier(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "import torch\n",
    "MODEL_LABEL_NUM = 10\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "#https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, MODEL_LABEL_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x#F.softmax(x)\n",
    "\n",
    "network = MNISTClassifier()\n",
    "network.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "network.eval()\n",
    "network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_rankings = 100\n",
    "NUM_VARS  = 1\n",
    "INPUT_SHAPE = x_train.shape[1:]\n",
    "for d in x_train.shape[1:]:\n",
    "    NUM_VARS *= d\n",
    "NUM_SAMPLES = min(fl.NUM_SAMPLES, NUM_VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import quantus\n",
    "\n",
    "print('Processing', SAMPLE_NUM)\n",
    "\n",
    "masking_values = torch.from_numpy(np.zeros(x_train.shape[1:])).float().to(device)\n",
    "if MODEL_NAME == 'ood-mean':\n",
    "    masking_values[:] = 0.1307\n",
    "\n",
    "row = x_train[SAMPLE_NUM].clone().detach().to(device)\n",
    "label = y_train[SAMPLE_NUM].clone().detach().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating _genetic rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 330.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 - Avg. fitness 0.11624401062726974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 342.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 - Avg. fitness 0.19961901009082794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 347.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 - Avg. fitness 0.21035704016685486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 358.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 - Avg. fitness 0.24756036698818207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 354.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 - Avg. fitness 0.26364871859550476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 358.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 - Avg. fitness 0.2788974642753601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 361.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 - Avg. fitness 0.2671501338481903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 359.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/10 - Avg. fitness 0.2996326684951782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 353.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/10 - Avg. fitness 0.3009408116340637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 356.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - Avg. fitness 0.32609090209007263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import genetic_generator as gg\n",
    "print(f'Generating {GENERATOR} rankings...')\n",
    "if GENERATOR == \"_genetic\":\n",
    "    # Genetically optimized\n",
    "    def fitness(ranking:np.ndarray) -> float:\n",
    "        measures = fl.get_measures_for_ranking(row, torch.tensor(ranking, dtype=torch.float32).to(device), label, network, num_samples=NUM_SAMPLES, with_inverse=True, with_random=True, masking_values=masking_values)\n",
    "        return measures['mean']\n",
    "    all_rankings = gg.generate_rankings(num_rankings, INPUT_SHAPE, fitness, new_random_elements_per_iteration=100)\n",
    "else:\n",
    "    #Random\n",
    "    all_rankings = np.zeros((num_rankings, *INPUT_SHAPE)) # To be randomly generated on the first loop\n",
    "    for i in range(num_rankings):\n",
    "        all_rankings[i] = fl._get_random_ranking_row(row.shape) # Random generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these measures will be stored\n",
    "suffixes = ['', '_inv', '_bas']\n",
    "size1_prefixes = ['mean', 'at_first_argmax', 'auc']\n",
    "sizeNUM_SAMPLES_prefixes = ['output_curve', 'is_hit_curve']\n",
    "keys = ['ranking']\n",
    "for p in size1_prefixes+sizeNUM_SAMPLES_prefixes:\n",
    "    for s in suffixes:\n",
    "        keys.append(p+s)\n",
    "\n",
    "# Dict to store all results\n",
    "all_measures = {}\n",
    "# Initialize all np arrays to speed up the process\n",
    "for k in size1_prefixes:\n",
    "    for s in suffixes:\n",
    "        all_measures[k+s] = np.zeros((num_rankings, 1), dtype=np.float32)\n",
    "\n",
    "for k in sizeNUM_SAMPLES_prefixes:\n",
    "    for s in suffixes:\n",
    "        all_measures[k+s] = np.zeros((num_rankings, NUM_SAMPLES), dtype=np.float32 if 'is_hit' not in k else bool)\n",
    "all_measures['ranking'] = np.zeros((num_rankings, *INPUT_SHAPE), dtype=np.float32)\n",
    "\n",
    "# Compute the results for each possible ranking\n",
    "for i in tqdm(range(num_rankings), miniters=10000):\n",
    "    measures = fl.get_measures_for_ranking(row, torch.tensor(all_rankings[i], dtype=torch.float32).to(device), label, network, num_samples=NUM_SAMPLES, with_inverse=True, with_random=True, masking_values=masking_values)\n",
    "    measures['ranking'] = all_rankings[i]\n",
    "    # Save all results for this rankings to the i-th position\n",
    "    for k in keys:\n",
    "        all_measures[k][i] = measures[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve and store Quantus' faithfulness metrics\n",
    "# To be used by Quantus\n",
    "x_batch_pt = torch.unsqueeze(row, dim=0)\n",
    "x_batch = x_batch_pt.to('cpu').numpy()\n",
    "y_batch = torch.unsqueeze(label, dim=0).to('cpu').numpy()\n",
    "\n",
    "all_measures['faithfulness_correlation'] = np.zeros(num_rankings, dtype=np.float32)\n",
    "all_measures['monotonicity_correlation'] = np.zeros(num_rankings, dtype=np.float32)\n",
    "all_measures['pixel_flipping'] = np.zeros((num_rankings,NUM_VARS), dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(num_rankings)):#,  miniters=10000):\n",
    "    #For each ranking, retrieve and store Quantus' faithfulness metrics\n",
    "    a_batch = np.expand_dims(all_rankings[i], 0)\n",
    "    #print('x_batch shape:',x_batch.shape)\n",
    "    #print('y_batch shape:',y_batch.shape)\n",
    "    #print('a_batch shape:',a_batch.shape)\n",
    "    #print('network(x_batch) shape:',network(torch.tensor(x_batch).to(device)).shape)\n",
    "    #print(a_batch)\n",
    "    all_measures['faithfulness_correlation'][i] = quantus.FaithfulnessCorrelation(\n",
    "                                                    nr_runs=10,\n",
    "                                                    subset_size=4,  \n",
    "                                                    perturb_baseline=\"black\",\n",
    "                                                    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                    similarity_func=quantus.similarity_func.correlation_pearson,  \n",
    "                                                    abs=False,  \n",
    "                                                    return_aggregate=False,\n",
    "                                                    disable_warnings=True\n",
    "                                                )(model=network, \n",
    "                                                x_batch=x_batch, \n",
    "                                                y_batch=y_batch,\n",
    "                                                a_batch=a_batch,\n",
    "                                                device=device,\n",
    "                                                channel_first=True)[0]\n",
    "    all_measures['monotonicity_correlation'][i] = quantus.MonotonicityCorrelation(\n",
    "                                                    nr_samples=10,\n",
    "                                                    features_in_step=2 if NUM_VARS % 2 == 0 else 1,\n",
    "                                                    perturb_baseline=\"black\",\n",
    "                                                    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                    similarity_func=quantus.similarity_func.correlation_spearman,\n",
    "                                                    disable_warnings=True\n",
    "                                                )(model=network, \n",
    "                                                x_batch=x_batch,\n",
    "                                                y_batch=y_batch,\n",
    "                                                a_batch=a_batch,\n",
    "                                                device=device,\n",
    "                                                channel_first=True)[0]\n",
    "    all_measures['pixel_flipping'][i] = quantus.PixelFlipping(\n",
    "                                                    features_in_step=1,\n",
    "                                                    perturb_baseline=\"black\",\n",
    "                                                    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                    disable_warnings=True\n",
    "                                                )(model=network,\n",
    "                                                    x_batch=x_batch,\n",
    "                                                    y_batch=y_batch,\n",
    "                                                    a_batch=a_batch,\n",
    "                                                    device=device,\n",
    "                                                channel_first=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(PROJ_DIR, 'results', f'{DATASET}_{SAMPLE_NUM}_{MODEL_NAME}{GENERATOR}_measures.npz'), \\\n",
    "        row=row.to('cpu').numpy(), \\\n",
    "        label=label.to('cpu').numpy(), \\\n",
    "        rankings=all_measures['ranking'], \\\n",
    "        faithfulness_correlations=all_measures['faithfulness_correlation'], \\\n",
    "        monotonicity_correlations=all_measures['monotonicity_correlation'], \\\n",
    "        pixel_flippings=all_measures['pixel_flipping'], \\\n",
    "        qmeans=all_measures['mean'], \\\n",
    "        qmean_invs=all_measures['mean_inv'], \\\n",
    "        qmean_bas=all_measures['mean_bas'], \\\n",
    "        qargmaxs=all_measures['at_first_argmax'], \\\n",
    "        qargmax_invs=all_measures['at_first_argmax_inv'], \\\n",
    "        qargmax_bas=all_measures['at_first_argmax_bas'], \\\n",
    "        qaucs=all_measures['auc'], \\\n",
    "        qauc_invs=all_measures['auc_inv'], \\\n",
    "        qauc_bas=all_measures['auc_bas'], \\\n",
    "        output_curves=all_measures['output_curve'], \\\n",
    "        is_hit_curves=all_measures['is_hit_curve'], \\\n",
    "        output_curves_inv=all_measures['output_curve_inv'], \\\n",
    "        is_hit_curves_inv=all_measures['is_hit_curve_inv'], \\\n",
    "        output_curves_bas=all_measures['output_curve_bas'], \\\n",
    "        is_hit_curves_bas=all_measures['is_hit_curve_bas'])#, \\\n",
    "        #inv_lookup=inv_lookup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b297cc45ec3b3804f1c0db7a06ed5081ea647c50a60ca6b31b53a357bc80d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
