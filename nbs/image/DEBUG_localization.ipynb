{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250e9af-c0e3-4fc9-88f4-11bd6e7a60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Measure performance\n",
    "# This notebook loads a file with precomputed measures (*qmeans*, *qbas* & *qinv*) for a set of rankings for a given instance of the dataset and measures the performance of the different alternative measures\n",
    "# \n",
    "# ## 1. Load libraries, model and data\n",
    "\n",
    "# %%\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from matplotlib import pyplot as plt\n",
    "from quantus import AttributionLocalisation\n",
    "\n",
    "DATASET = 'cmnist'\n",
    "MODEL_NAME = 'resnet18'\n",
    "REFERENCE_MODEL_NAME = MODEL_NAME#'resnet50w'\n",
    "GENERATION = '_randomattr'\n",
    "TARGET_MEASURE = 'AttributionLocalisation'#'faithfulness_correlation'\n",
    "at = AttributionLocalisation(abs=False, normalise=False, disable_warnings=True)\n",
    "network = fl.load_pretrained_cmnist_resnet18_model(os.path.join(PROJ_DIR,'assets','models','cmnist-resnet18.pth'))\n",
    "\n",
    "DATA_MEAN = [0.2675, 0.2565, 0.2761]\n",
    "DATA_STD = [0.5071, 0.4867, 0.4408]\n",
    "\n",
    "q_invs = []\n",
    "q_invs_file = []\n",
    "q_bas = []\n",
    "\n",
    "\n",
    "for FILENAME in os.listdir(os.path.join(PROJ_DIR,'results')):\n",
    "    if FILENAME.startswith(DATASET) and FILENAME.endswith(f'{MODEL_NAME}{GENERATION}_localization_s_area_measures.npz'):\n",
    "        print(FILENAME)\n",
    "\n",
    "        # Load data\n",
    "        data = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "        \n",
    "        qmeans = data[TARGET_MEASURE]\n",
    "        qmeans_inv = data[TARGET_MEASURE + '_inv']\n",
    "        rankings = data['rankings']\n",
    "        mask = data['s_mask']\n",
    "        maskb = mask.astype(bool).flatten()\n",
    "\n",
    "        for i in range(min(rankings.shape[0], 5)):\n",
    "            c = rankings[i]\n",
    "            c_inv = fl.get_inverse(c)\n",
    "            c_positive =  c#np.where(c>0, c, 0)\n",
    "            cinv_positive =  c_inv#np.where(c_inv>0, c_inv, 0)\n",
    "            fig, axs = plt.subplots(2,3)\n",
    "            axs[0][0].imshow(np.moveaxis(data['row'], 0, -1) * DATA_STD + DATA_MEAN, cmap='winter')\n",
    "            axs[0][1].imshow(np.moveaxis(c, 0, -1).sum(axis=2))\n",
    "            axs[0][2].imshow(np.moveaxis(c_inv, 0, -1).sum(axis=2))\n",
    "            axs[1][0].imshow(np.moveaxis(mask, 0, -1))\n",
    "            axs[1][1].imshow(np.moveaxis((c_positive*mask), 0, -1).sum(axis=2))\n",
    "            axs[1][2].imshow(np.moveaxis((cinv_positive*mask), 0, -1).sum(axis=2))\n",
    "            plt.title(f'{data[\"label\"]} ({data[\"label\"]})')\n",
    "            plt.show()\n",
    "            \n",
    "            # Prepare shapes.\n",
    "            a = c.sum(axis=0).flatten()\n",
    "            s = np.expand_dims(data['s_mask'], axis=0).flatten().astype(bool)\n",
    "\n",
    "            # Compute ratio.\n",
    "            size_bbox = float(np.sum(s))\n",
    "            size_data = s.size\n",
    "            ratio = size_bbox / size_data\n",
    "\n",
    "            # Compute inside/outside ratio.\n",
    "            inside_attribution = np.sum(a[s])\n",
    "            total_attribution = np.sum(a)\n",
    "            inside_attribution_ratio = float(inside_attribution / total_attribution)\n",
    "\n",
    "            print('inside_attribution', inside_attribution)\n",
    "            print('total_attribution', total_attribution)\n",
    "            print('inside_attribution_ratio', inside_attribution_ratio)\n",
    "\n",
    "            localization = at(model=network, \n",
    "                            x_batch=np.expand_dims(data['row'], axis=0), \n",
    "                            y_batch=np.expand_dims(data['label'], axis=0),\n",
    "                            a_batch=np.expand_dims(c.sum(axis=0, keepdims=True), axis=0),\n",
    "                            s_batch=np.expand_dims(data['s_mask'], axis=0))[0]\n",
    "            localization_random = at(model=network, \n",
    "                            x_batch=np.expand_dims(data['row'], axis=0), \n",
    "                            y_batch=np.expand_dims(data['label'], axis=0),\n",
    "                            a_batch=np.expand_dims(np.random.normal(size=c.shape).sum(axis=0, keepdims=True), axis=0),\n",
    "                            s_batch=np.expand_dims(data['s_mask'], axis=0))[0]\n",
    "            print('localization:',localization)\n",
    "            localization_inv = at(model=network, \n",
    "                            x_batch=np.expand_dims(data['row'], axis=0), \n",
    "                            y_batch=np.expand_dims(data['label'], axis=0),\n",
    "                            a_batch=np.expand_dims(c_inv.sum(axis=0, keepdims=True), axis=0),\n",
    "                            s_batch=np.expand_dims(data['s_mask'], axis=0))[0]\n",
    "            print('localization_inv:',localization_inv)\n",
    "            print('localization_random:',localization_random)\n",
    "            print('localization wrt inv:',localization - localization_inv)\n",
    "            print('localization_bas:',localization - localization_random)\n",
    "            #print((np.moveaxis(c_positive, 0, -1).sum(axis=2)*mask).sum())\n",
    "            #print((np.moveaxis(cinv_positive, 0, -1).sum(axis=2)*mask).sum())\n",
    "            print('qmeans',qmeans[i])\n",
    "            print('qmeans_inv',qmeans_inv[i])\n",
    "            print('-'*20)\n",
    "            q_invs.append((localization, localization - localization_inv))\n",
    "            q_bas.append((localization, localization - localization_random))\n",
    "            q_invs_file.append((localization, qmeans_inv[i]))\n",
    "\n",
    "qmean_mean = np.mean(qmeans)\n",
    "qmean_std = np.std(qmeans)\n",
    "\n",
    "plt.scatter(list(map(lambda x:(x[0]-qmean_mean)/qmean_std,q_invs)), list(map(lambda x:x[1],q_invs)), label='qinvs')\n",
    "plt.scatter(list(map(lambda x:(x[0]-qmean_mean)/qmean_std,q_bas)), list(map(lambda x:x[1],q_bas)), label='qbas')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(list(map(lambda x:(x[0]-qmean_mean)/qmean_std,q_invs_file)), list(map(lambda x:x[1],q_invs)), label='qinvs')\n",
    "plt.scatter(list(map(lambda x:(x[0]-qmean_mean)/qmean_std,q_bas)), list(map(lambda x:x[1],q_bas)), label='qbas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5f7e8-5d78-4125-bd97-13fd32b3b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute z-score\n",
    "qmean_mean = np.mean(qmeans)\n",
    "qmean_std = np.std(qmeans)\n",
    "z_scores = ((qmeans - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "plt.scatter(z_scores, qmeans_inv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d87fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute qmeans_bas[2-10]\n",
    "def compute_qbas(measure, num_samples, reference:np.ndarray):\n",
    "    random_indices = np.random.randint(0, measure.shape[0], (measure.shape[0], num_samples))\n",
    "    random_qmeans = reference[random_indices]\n",
    "    mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "    # First way to deal with std==0; add some epsilon\n",
    "    #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "    # Second way to deal with std==0; ignore std (divide by 1)\n",
    "    std = np.std(random_qmeans, axis=1)\n",
    "    std[std==0] = 1\n",
    "\n",
    "    # Always ignore std\n",
    "    std=1\n",
    "    return (measure - mean) / std\n",
    "\n",
    "plt.scatter(z_scores, compute_qbas(qmeans, 1, qmeans))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
