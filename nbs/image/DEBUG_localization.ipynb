{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250e9af-c0e3-4fc9-88f4-11bd6e7a60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Measure performance\n",
    "# This notebook loads a file with precomputed measures (*qmeans*, *qbas* & *qinv*) for a set of rankings for a given instance of the dataset and measures the performance of the different alternative measures\n",
    "# \n",
    "# ## 1. Load libraries, model and data\n",
    "\n",
    "# %%\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DATASET = 'cmnist'\n",
    "MODEL_NAME = 'resnet18'\n",
    "REFERENCE_MODEL_NAME = MODEL_NAME#'resnet50w'\n",
    "GENERATION = '_random'\n",
    "TARGET_MEASURE = 'AttributionLocalisation'#'faithfulness_correlation'\n",
    "\n",
    "DATA_MEAN = [0.2675, 0.2565, 0.2761]\n",
    "DATA_STD = [0.5071, 0.4867, 0.4408]\n",
    "\n",
    "\n",
    "for FILENAME in os.listdir(os.path.join(PROJ_DIR,'results')):\n",
    "    if FILENAME.startswith(DATASET) and FILENAME.endswith(f'{MODEL_NAME}{GENERATION}_localization_s_area_measures.npz'):\n",
    "        print(FILENAME)\n",
    "\n",
    "        # Load data\n",
    "        data = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "        \n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(np.moveaxis(data['row'], 0, -1) * DATA_STD + DATA_MEAN, cmap='winter')\n",
    "        plt.title(f'{data[\"label\"]} ({data[\"label\"]})')\n",
    "        plt.show()\n",
    "        \n",
    "        qmeans = data[TARGET_MEASURE]\n",
    "        #qmeans_basX = [data['qmean_bas']] # We don't look at qmean_bas, it will be recomputed later with the appropriate reference\n",
    "        qmeans_basX = []\n",
    "        qmeans_inv = data[TARGET_MEASURE + '_inv']\n",
    "\n",
    "        # Compute qmeans_bas[2-10]\n",
    "        def compute_qbas(measure, num_samples, reference:np.ndarray):\n",
    "            random_indices = np.random.randint(0, measure.shape[0], (measure.shape[0], num_samples))\n",
    "            random_qmeans = reference[random_indices]\n",
    "            mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "            # First way to deal with std==0; add some epsilon\n",
    "            #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "            # Second way to deal with std==0; ignore std (divide by 1)\n",
    "            std = np.std(random_qmeans, axis=1)\n",
    "            std[std==0] = 1\n",
    "\n",
    "            # Always ignore std\n",
    "            std=1\n",
    "            return (measure - mean) / std\n",
    "        \n",
    "        data_reference = data\n",
    "        qmeans_reference = qmeans\n",
    "        if GENERATION in ['_genetic', '_captum']:\n",
    "            # If data is genetic, we'll load the random generated equivalent to compute qbas with\n",
    "            data_reference = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME.replace(GENERATION, '_random').replace(MODEL_NAME, REFERENCE_MODEL_NAME)))\n",
    "            qmeans_reference = data_reference[TARGET_MEASURE]\n",
    "\n",
    "        for i in range(1,11):\n",
    "            # If data is genetic, compute qbas with random data from other file\n",
    "            qmeans_basX.append(compute_qbas(qmeans, i, qmeans_reference if GENERATION in ['_genetic', '_captum'] else qmeans))\n",
    "\n",
    "        # Compute z-score\n",
    "        qmean_mean = np.mean(qmeans)\n",
    "        qmean_std = np.std(qmeans)\n",
    "        \n",
    "        if GENERATION in ['_genetic', '_captum']:\n",
    "            qmean_mean = np.mean(qmeans_reference)\n",
    "            qmean_std = np.std(qmeans_reference)\n",
    "\n",
    "        z_scores = ((qmeans - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "        print(f'Reference mean:{qmean_mean:.2f} std:{qmean_std:.2f}')\n",
    "        NUM_RANDOM_CURVES = 10\n",
    "        #TODO Imprimir resultados\n",
    "\n",
    "\n",
    "        #for i in range(selected_curves.shape[0]):\n",
    "        #    print(f'{np.unique(selected_rankings[i]).size}/{selected_rankings[i].size} unique values')\n",
    "        #    plt.scatter(selected_rankings[i].flatten(), np.arange(selected_rankings[i].size), s=0.2)\n",
    "        #    plt.show()\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(10, 2.5))\n",
    "        axs[0].scatter(z_scores, qmeans_inv)#, s=0.1, alpha=0.2)\n",
    "        axs[0].set_title('Zscore vs qmeans_inv')\n",
    "        axs[1].scatter(z_scores, qmeans_basX[0])#, s=0.1, alpha=0.2)\n",
    "        axs[1].set_title('Zscore vs qbas1')\n",
    "        axs[2].scatter(z_scores, qmeans_basX[1])#, s=0.1, alpha=0.2)\n",
    "        axs[2].set_title('Zscore vs qbas2')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Stratify z-index to be able to compare performance on different parts of the spectrum\n",
    "        indices = np.arange(z_scores.shape[0])\n",
    "        z_scores_numbered = np.vstack((z_scores, indices))\n",
    "        level_indices = []\n",
    "        boundaries = [0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "        for i in range(1,len(boundaries)+1):\n",
    "            bottom_limit = boundaries[i-1]\n",
    "            top_limit = float('inf')\n",
    "            if i < len(boundaries):\n",
    "                top_limit = boundaries[i]\n",
    "            level_indices.append((z_scores_numbered[:,np.logical_and(bottom_limit<=z_scores, z_scores<top_limit)][1,:].astype(int),(bottom_limit, top_limit)))\n",
    "        \n",
    "        # %% [markdown]\n",
    "        # ## 2. Measure performance\n",
    "        # ### 2.1 Order preservation\n",
    "        #  1. The issue with using qmean directly is that it doesn't have a fixed scale and you don't get an idea of how good your explanation is compared to other explanations\n",
    "        #  2. To address this, ideally you would determine the distribution of all qmeans and then compute the z-score. That's very costly, so you either:\n",
    "        #     1. Estimate the qmeans distribution with X samples $\\rightarrow$ qbasX\n",
    "        #     2. Calculate an alternative to the z-index directly $\\rightarrow$ qinv\n",
    "        #  3. The problem with both alternatives is that you adulterate the value of your original qmean measurement, so you may end up in a situation where $qmean_i<qmean_j$ but $qinv_i<qinv_j$, which is undesirable\n",
    "        #  4. Hence, we measure how many times that happens for each measure.\n",
    "        # \n",
    "        #  (This may be measuring the same as Pearson correlation, which is computed below)\n",
    "\n",
    "        # %%\n",
    "        def measure_correct_orderings(truths, estimators):\n",
    "            '''\n",
    "            Creates len(truth) x,y pairs and computes the fraction of them for which (truths[x]<truths[y] and estimators[x]<estimators[y]) or (truths[x]>truths[y] and estimators[x]>estimators[y])\n",
    "            Inputs:\n",
    "                - Truths & estimators contain num_elems floats\n",
    "            Output:\n",
    "                - Float representing the fraction of correctly ordered pairings\n",
    "            '''\n",
    "            xs = np.random.permutation(truths.size)\n",
    "            ys = np.random.permutation(truths.size)\n",
    "            truthX_lt_Y = truths[xs] < truths[ys]\n",
    "            estimatorX_lt_Y = estimators[xs] < estimators[ys]\n",
    "            hits = truthX_lt_Y==estimatorX_lt_Y\n",
    "            return hits.sum()/truths.size\n",
    "\n",
    "        print('\\tCorrect orderings:')\n",
    "        correct_pairings_basX = []\n",
    "        for i in range(len(qmeans_basX)):\n",
    "            correct_pairings_basX.append(measure_correct_orderings(qmeans, qmeans_basX[i]))\n",
    "            print(f'\\t\\tqmeans_bas{i+1}: {correct_pairings_basX[i]:.4f}')\n",
    "        correct_pairings_inv = measure_correct_orderings(qmeans, qmeans_inv)\n",
    "        print('\\t\\t'+'-'*20)\n",
    "        print(f'\\t\\tqmeans_inv: {correct_pairings_inv:.4f}')\n",
    "\n",
    "        # %% [markdown]\n",
    "        # ### 2.2. Spearman correlation\n",
    "        # Same thing, is the order of qmeans preserved in qbasX/qinv?\n",
    "\n",
    "        # %%\n",
    "        print('\\tSpearman correlation:')\n",
    "        from scipy.stats import spearmanr\n",
    "        spearman_basX = []\n",
    "        for i in range(len(qmeans_basX)):\n",
    "            spearman_basX.append(spearmanr(qmeans, qmeans_basX[i])[0])\n",
    "            print(f'\\t\\tqmeans_bas{i+1}: {spearman_basX[i]:.4f}')\n",
    "        spearman_inv = spearmanr(qmeans, qmeans_inv)[0]\n",
    "        print('\\t\\t'+'-'*20)\n",
    "        print(f'\\t\\tqmeans_inv: {spearman_inv:.4f}')\n",
    "        plt.plot(qmeans, qmeans_inv)\n",
    "        plt.title('Spearman')\n",
    "        plt.show()\n",
    "\n",
    "        # %% [markdown]\n",
    "        # ### 2.3. Ability to detect exceptionally good rankings\n",
    "        # As stated above, there are some ordering errors in the estimators. Are they in the relevant part of the distribution? i.e. Do they affect the ability to identify exceptionally good rankings?\n",
    "\n",
    "        # %%\n",
    "        from sklearn import metrics\n",
    "\n",
    "        def measure_detection(target_indices, estimator):\n",
    "            if (len(target_indices)==0) or (len(target_indices) == estimator.shape[0]):\n",
    "                return float('nan')\n",
    "            target = np.zeros_like(estimator, dtype=int)\n",
    "            target[target_indices] = 1\n",
    "            return metrics.roc_auc_score(target, estimator)\n",
    "\n",
    "        aucs_inv = []\n",
    "        aucs_basX = [[] for i in qmeans_basX]\n",
    "\n",
    "        for indices, (bottom_limit, upper_limit) in level_indices:\n",
    "            aucs_inv.append(measure_detection(indices, qmeans_inv))\n",
    "            for i in range(len(qmeans_basX)):\n",
    "                aucs_basX[i].append(measure_detection(indices, qmeans_basX[i]))\n",
    "\n",
    "        print('\\tExceptional detection:')\n",
    "        for i in range(len(qmeans_basX)):\n",
    "            print(f'\\t\\taucs_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_basX[i])))\n",
    "        print('\\t\\t'+'-'*20)\n",
    "        print('\\t\\taucs_inv ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_inv)))\n",
    "\n",
    "\n",
    "        # %% [markdown]\n",
    "        # ### 2.4 Ability to rank exceptionally good rankings\n",
    "        # How well is the order preserved for exceptionally good rankings?\n",
    "\n",
    "        # %%\n",
    "        spearman_exceptional_inv = []\n",
    "        spearman_exceptional_basX = [[] for i in qmeans_basX]\n",
    "\n",
    "        for indices, (bottom_limit, upper_limit) in level_indices:\n",
    "            spearman_exceptional_inv.append(spearmanr(qmeans[indices], qmeans_inv[indices])[0])\n",
    "            for i in range(len(qmeans_basX)):\n",
    "                spearman_exceptional_basX[i].append(spearmanr(qmeans[indices], qmeans_basX[i][indices])[0])\n",
    "\n",
    "        print('\\tSpearman correlation for exceptional rankings:')\n",
    "        for i in range(len(qmeans_basX)):\n",
    "            print(f'\\t\\tspearman_exceptional_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_basX[i])))\n",
    "        print('\\t\\t'+'-'*20)\n",
    "        print('\\t\\tspearman_exceptional_inv ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_inv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5f7e8-5d78-4125-bd97-13fd32b3b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
