{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure performance\n",
    "This notebook loads a file with precomputed measures (*qmeans*, *qbas* & *qinv*) for a set of rankings for a given instance of the dataset and measures the performance of the different alternative measures\n",
    "\n",
    "## 1. Load libraries, model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'avila_70_measures.npz'\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "qmeans = data['qmeans']\n",
    "qmeans_basX = [data['qmean_bas']]\n",
    "qmeans_inv = data['qmean_invs']\n",
    "\n",
    "# Compute qmeans_bas[2-10]\n",
    "def compute_qbas(measure, num_samples):\n",
    "    random_indices = np.random.randint(0,  measure.shape[0], (measure.shape[0], num_samples))\n",
    "    random_qmeans = measure[random_indices]\n",
    "    mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "    # First way to deal with std==0; add some epsilon\n",
    "    #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "    # Second way to deal with std==0; ignore std (divide by 1)\n",
    "    std = np.std(random_qmeans, axis=1)\n",
    "    std[std==0] = 1\n",
    "\n",
    "    # Always ignore std\n",
    "    std=1\n",
    "    return (measure - mean) / std\n",
    "for i in range(2,11):\n",
    "    qmeans_basX.append(compute_qbas(qmeans, i))\n",
    "\n",
    "# Compute z-score??\n",
    "qmean_mean = np.mean(qmeans)\n",
    "qmean_std = np.std(qmeans)\n",
    "z_scores = ((qmeans - qmean_mean) / qmean_std).flatten()\n",
    "\n",
    "# Stratify z-index to be able to compare performance on different parts of the spectrum\n",
    "indices = np.arange(z_scores.shape[0])\n",
    "z_scores_numbered = np.vstack((z_scores, indices))\n",
    "level_indices = []\n",
    "boundaries = [float('-inf'), 0, 0.5, 1, 1.5, 2, 2.5]\n",
    "for i in range(1,len(boundaries)+1):\n",
    "    bottom_limit = boundaries[i-1]\n",
    "    top_limit = float('inf')\n",
    "    if i < len(boundaries):\n",
    "        top_limit = boundaries[i]\n",
    "    level_indices.append((z_scores_numbered[:,np.logical_and(bottom_limit<=z_scores, z_scores<top_limit)][1,:].astype(int),(bottom_limit, top_limit)))\n",
    "exceptional_indices = level_indices[-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure performance\n",
    "### 2.1 Order preservation\n",
    " 1. The issue with using qmean directly is that it doesn't have a fixed scale and you don't get an idea of how good your explanation is compared to other explanations\n",
    " 2. To address this, ideally you would determine the distribution of all qmeans and then compute the z-score. That's very costly, so you either:\n",
    "    1. Estimate the qmeans distribution with X samples $\\rightarrow$ qbasX\n",
    "    2. Calculate an alternative to the z-index directly $\\rightarrow$ qinv\n",
    " 3. The problem with both alternatives is that you adulterate the value of your original qmean measurement, so you may end up in a situation where $qmean_i<qmean_j$ but $qinv_i<qinv_j$, which is undesirable\n",
    " 4. Hence, we measure how many times that happens for each measure.\n",
    "\n",
    " (This may be measuring the same as Pearson correlation, which is computed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qmeans_bas1: 0.7505\n",
      "qmeans_bas2: 0.7888\n",
      "qmeans_bas3: 0.8142\n",
      "qmeans_bas4: 0.8317\n",
      "qmeans_bas5: 0.8445\n",
      "qmeans_bas6: 0.8553\n",
      "qmeans_bas7: 0.8630\n",
      "qmeans_bas8: 0.8696\n",
      "qmeans_bas9: 0.8758\n",
      "qmeans_bas10: 0.8808\n",
      "qmeans_inv: 0.8341\n"
     ]
    }
   ],
   "source": [
    "def measure_correct_orderings(truths, estimators):\n",
    "    '''\n",
    "    Creates len(truth) x,y pairs and computes the fraction of them for which (truths[x]<truths[y] and estimators[x]<estimators[y]) or (truths[x]>truths[y] and estimators[x]>estimators[y])\n",
    "    Inputs:\n",
    "        - Truths & estimators contain num_elems floats\n",
    "    Output:\n",
    "        - Float representing the fraction of correctly ordered pairings\n",
    "    '''\n",
    "    xs = np.random.permutation(truths.size)\n",
    "    ys = np.random.permutation(truths.size)\n",
    "    truthX_lt_Y = truths[xs] < truths[ys]\n",
    "    estimatorX_lt_Y = estimators[xs] < estimators[ys]\n",
    "    hits = truthX_lt_Y==estimatorX_lt_Y\n",
    "    return hits.sum()/truths.size\n",
    "\n",
    "correct_pairings_basX = []\n",
    "for i in range(len(qmeans_basX)):\n",
    "    correct_pairings_basX.append(measure_correct_orderings(qmeans, qmeans_basX[i]))\n",
    "    print(f'qmeans_bas{i+1}: {correct_pairings_basX[i]:.4f}')\n",
    "correct_pairings_inv = measure_correct_orderings(qmeans, qmeans_inv)\n",
    "print(f'qmeans_inv: {correct_pairings_inv:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Spearman correlation\n",
    "Same thing, is the order of qmeans preserved in qbasX/qinv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qmeans_bas1: 0.6758\n",
      "qmeans_bas2: 0.7690\n",
      "qmeans_bas3: 0.8197\n",
      "qmeans_bas4: 0.8509\n",
      "qmeans_bas5: 0.8723\n",
      "qmeans_bas6: 0.8881\n",
      "qmeans_bas7: 0.8997\n",
      "qmeans_bas8: 0.9091\n",
      "qmeans_bas9: 0.9168\n",
      "qmeans_bas10: 0.9231\n",
      "qmeans_inv: 0.8474\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearman_basX = []\n",
    "for i in range(len(qmeans_basX)):\n",
    "    spearman_basX.append(spearmanr(qmeans, qmeans_basX[i])[0])\n",
    "    print(f'qmeans_bas{i+1}: {spearman_basX[i]:.4f}')\n",
    "spearman_inv = spearmanr(qmeans, qmeans_inv)[0]\n",
    "print(f'qmeans_inv: {spearman_inv:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Ability to detect exceptionally good rankings\n",
    "As stated above, there are some ordering errors in the estimators. Are they in the relevant part of the distribution? i.e. Do they affect the ability to identify exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ability to rank exceptionally good rankings\n",
    "How well is the order preserved for exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-quantus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
