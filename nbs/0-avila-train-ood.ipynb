{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass training\n",
    " This notebook loads the Glass identification dataset (https://archive.ics.uci.edu/dataset/42/glass+identification), preprocesses it and trains a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_data = np.load(os.path.join(PROJ_DIR, 'assets', 'data', 'avila.npz'))\n",
    "x_train = file_data['x_train']\n",
    "x_test = file_data['x_test']\n",
    "y_train = file_data['y_train']\n",
    "y_test = file_data['y_test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class RandomMasker(torch.nn.Module):\n",
    "    def __init__(self, masking_value:torch.tensor):\n",
    "        super().__init__()\n",
    "        self._masking_value = masking_value\n",
    "    def forward(self, x): # Assumes inputs are (batch_size, num_vars)\n",
    "        selection_levels = torch.rand((x.shape[0], 1)) # A different selection level for each element of the batch\n",
    "        selected_pixels = torch.le(torch.rand(x.shape), selection_levels) # A different selection level for each element of the batch\n",
    "        return x * selected_pixels + self._masking_value * ~selected_pixels\n",
    "\n",
    "# Zeros\n",
    "masking_value = np.zeros(x_train.shape[1])\n",
    "# Mean\n",
    "masking_value = np.mean(x_train, axis=0)\n",
    "masker = RandomMasker(torch.tensor(masking_value).float())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2000 - Loss: 20.00139808654785 - Train accuracy: 0.02837967313826084 - Test accuracy: 0.08063279092311859\n",
      "Epoch 1/2000 - Loss: 6.436717987060547 - Train accuracy: 0.052732501178979874 - Test accuracy: 0.32099711894989014\n",
      "Epoch 2/2000 - Loss: 6.159282207489014 - Train accuracy: 0.3332694172859192 - Test accuracy: 0.40575262904167175\n",
      "Epoch 3/2000 - Loss: 6.1150126457214355 - Train accuracy: 0.4039309620857239 - Test accuracy: 0.39530202746391296\n",
      "Epoch 4/2000 - Loss: 6.381319999694824 - Train accuracy: 0.4033557176589966 - Test accuracy: 0.3988494873046875\n",
      "Epoch 5/2000 - Loss: 5.686429023742676 - Train accuracy: 0.4053691327571869 - Test accuracy: 0.39923298358917236\n",
      "Epoch 6/2000 - Loss: 6.601292133331299 - Train accuracy: 0.4052732586860657 - Test accuracy: 0.3982742130756378\n",
      "Epoch 7/2000 - Loss: 6.0185441970825195 - Train accuracy: 0.40239691734313965 - Test accuracy: 0.3961648941040039\n",
      "Epoch 8/2000 - Loss: 5.713531494140625 - Train accuracy: 0.40172579884529114 - Test accuracy: 0.40757429599761963\n",
      "Epoch 9/2000 - Loss: 4.770207405090332 - Train accuracy: 0.40565675497055054 - Test accuracy: 0.4305848479270935\n",
      "Epoch 10/2000 - Loss: 5.468338966369629 - Train accuracy: 0.4164908826351166 - Test accuracy: 0.45541706681251526\n",
      "Epoch 11/2000 - Loss: 5.577227592468262 - Train accuracy: 0.4286673069000244 - Test accuracy: 0.46184083819389343\n",
      "Epoch 12/2000 - Loss: 6.2185773849487305 - Train accuracy: 0.4337488114833832 - Test accuracy: 0.4517737329006195\n",
      "Epoch 13/2000 - Loss: 4.652787208557129 - Train accuracy: 0.4279961585998535 - Test accuracy: 0.44343242049217224\n",
      "Epoch 14/2000 - Loss: 5.105297088623047 - Train accuracy: 0.4227229058742523 - Test accuracy: 0.43672099709510803\n",
      "Epoch 15/2000 - Loss: 5.853509902954102 - Train accuracy: 0.4199424684047699 - Test accuracy: 0.4339405596256256\n",
      "Epoch 16/2000 - Loss: 5.729153156280518 - Train accuracy: 0.4199424684047699 - Test accuracy: 0.4347075819969177\n",
      "Epoch 17/2000 - Loss: 5.88287878036499 - Train accuracy: 0.42023009061813354 - Test accuracy: 0.43892616033554077\n",
      "Epoch 18/2000 - Loss: 4.879213809967041 - Train accuracy: 0.4259827435016632 - Test accuracy: 0.441898375749588\n",
      "Epoch 19/2000 - Loss: 4.401845932006836 - Train accuracy: 0.42770853638648987 - Test accuracy: 0.44669222831726074\n",
      "Epoch 20/2000 - Loss: 4.6032843589782715 - Train accuracy: 0.43355703353881836 - Test accuracy: 0.45656758546829224\n",
      "Epoch 21/2000 - Loss: 4.520127773284912 - Train accuracy: 0.43537870049476624 - Test accuracy: 0.4644295275211334\n",
      "Epoch 22/2000 - Loss: 5.155195713043213 - Train accuracy: 0.4372003972530365 - Test accuracy: 0.4648130536079407\n",
      "Epoch 23/2000 - Loss: 4.681439399719238 - Train accuracy: 0.44343242049217224 - Test accuracy: 0.46184083819389343\n",
      "Epoch 24/2000 - Loss: 4.8790788650512695 - Train accuracy: 0.4386385381221771 - Test accuracy: 0.4548417925834656\n",
      "Epoch 25/2000 - Loss: 4.8281569480896 - Train accuracy: 0.43681687116622925 - Test accuracy: 0.4517737329006195\n",
      "Epoch 26/2000 - Loss: 4.87497091293335 - Train accuracy: 0.43422818183898926 - Test accuracy: 0.4511025846004486\n",
      "Epoch 27/2000 - Loss: 4.654726505279541 - Train accuracy: 0.4306807219982147 - Test accuracy: 0.4549376666545868\n",
      "Epoch 28/2000 - Loss: 4.420125961303711 - Train accuracy: 0.43413230776786804 - Test accuracy: 0.462799608707428\n",
      "Epoch 29/2000 - Loss: 3.791219711303711 - Train accuracy: 0.4379673898220062 - Test accuracy: 0.4701821804046631\n",
      "Epoch 30/2000 - Loss: 3.7378251552581787 - Train accuracy: 0.43624159693717957 - Test accuracy: 0.4763182997703552\n",
      "Epoch 31/2000 - Loss: 4.189302921295166 - Train accuracy: 0.43873441219329834 - Test accuracy: 0.48120805621147156\n",
      "Epoch 32/2000 - Loss: 5.408080577850342 - Train accuracy: 0.43959730863571167 - Test accuracy: 0.48763182759284973\n",
      "Epoch 33/2000 - Loss: 5.50892972946167 - Train accuracy: 0.44870564341545105 - Test accuracy: 0.4931927025318146\n",
      "Epoch 34/2000 - Loss: 4.3876190185546875 - Train accuracy: 0.4475551247596741 - Test accuracy: 0.4987536072731018\n",
      "Epoch 35/2000 - Loss: 4.469621181488037 - Train accuracy: 0.45215722918510437 - Test accuracy: 0.5009588003158569\n",
      "Epoch 36/2000 - Loss: 4.3996734619140625 - Train accuracy: 0.44937679171562195 - Test accuracy: 0.498561829328537\n",
      "Epoch 37/2000 - Loss: 4.011567115783691 - Train accuracy: 0.4515819847583771 - Test accuracy: 0.4939597249031067\n",
      "Epoch 38/2000 - Loss: 4.499089241027832 - Train accuracy: 0.45071908831596375 - Test accuracy: 0.4920421838760376\n",
      "Epoch 39/2000 - Loss: 5.0784478187561035 - Train accuracy: 0.459060400724411 - Test accuracy: 0.4912751615047455\n",
      "Epoch 40/2000 - Loss: 4.464393615722656 - Train accuracy: 0.4535953998565674 - Test accuracy: 0.4928092062473297\n",
      "Epoch 41/2000 - Loss: 4.063096523284912 - Train accuracy: 0.45397889614105225 - Test accuracy: 0.49511027336120605\n",
      "Epoch 42/2000 - Loss: 5.2752885818481445 - Train accuracy: 0.4490891695022583 - Test accuracy: 0.5017257928848267\n",
      "Epoch 43/2000 - Loss: 4.4784464836120605 - Train accuracy: 0.4548417925834656 - Test accuracy: 0.5093001127243042\n",
      "Epoch 44/2000 - Loss: 4.007237434387207 - Train accuracy: 0.45465004444122314 - Test accuracy: 0.5136145949363708\n",
      "Epoch 45/2000 - Loss: 4.373669624328613 - Train accuracy: 0.4608820676803589 - Test accuracy: 0.5144774913787842\n",
      "Epoch 46/2000 - Loss: 4.20548677444458 - Train accuracy: 0.4597315490245819 - Test accuracy: 0.5146692395210266\n",
      "Epoch 47/2000 - Loss: 4.4401373863220215 - Train accuracy: 0.46069031953811646 - Test accuracy: 0.5129434466362\n",
      "Epoch 48/2000 - Loss: 4.021129131317139 - Train accuracy: 0.45675933361053467 - Test accuracy: 0.5128475427627563\n",
      "Epoch 49/2000 - Loss: 5.086523056030273 - Train accuracy: 0.45925214886665344 - Test accuracy: 0.5113134980201721\n",
      "Epoch 50/2000 - Loss: 4.117007732391357 - Train accuracy: 0.4578140079975128 - Test accuracy: 0.5118888020515442\n",
      "Epoch 51/2000 - Loss: 3.9356160163879395 - Train accuracy: 0.456471711397171 - Test accuracy: 0.5126557946205139\n",
      "Epoch 52/2000 - Loss: 4.332669258117676 - Train accuracy: 0.46136146783828735 - Test accuracy: 0.5140939354896545\n",
      "Epoch 53/2000 - Loss: 4.689728736877441 - Train accuracy: 0.46145734190940857 - Test accuracy: 0.5158197283744812\n",
      "Epoch 54/2000 - Loss: 4.151158332824707 - Train accuracy: 0.46116968989372253 - Test accuracy: 0.5187919735908508\n",
      "Epoch 55/2000 - Loss: 4.479406833648682 - Train accuracy: 0.4596356749534607 - Test accuracy: 0.5201342105865479\n",
      "Epoch 56/2000 - Loss: 3.5361132621765137 - Train accuracy: 0.4595398008823395 - Test accuracy: 0.5201342105865479\n",
      "Epoch 57/2000 - Loss: 3.454190969467163 - Train accuracy: 0.4615532159805298 - Test accuracy: 0.5189837217330933\n",
      "Epoch 58/2000 - Loss: 4.105693340301514 - Train accuracy: 0.4591562747955322 - Test accuracy: 0.5163950324058533\n",
      "Epoch 59/2000 - Loss: 4.727734565734863 - Train accuracy: 0.4623202383518219 - Test accuracy: 0.5138063430786133\n",
      "Epoch 60/2000 - Loss: 3.645537853240967 - Train accuracy: 0.46452540159225464 - Test accuracy: 0.5146692395210266\n",
      "Epoch 61/2000 - Loss: 3.8592140674591064 - Train accuracy: 0.4617449641227722 - Test accuracy: 0.5178331732749939\n",
      "Epoch 62/2000 - Loss: 3.5833816528320312 - Train accuracy: 0.4676893651485443 - Test accuracy: 0.5209012627601624\n",
      "Epoch 63/2000 - Loss: 3.5999515056610107 - Train accuracy: 0.46596357226371765 - Test accuracy: 0.5205177664756775\n",
      "Epoch 64/2000 - Loss: 4.056082248687744 - Train accuracy: 0.46864813566207886 - Test accuracy: 0.5216682553291321\n",
      "Epoch 65/2000 - Loss: 4.475600242614746 - Train accuracy: 0.46673059463500977 - Test accuracy: 0.5231063961982727\n",
      "Epoch 66/2000 - Loss: 3.939558982849121 - Train accuracy: 0.4622243642807007 - Test accuracy: 0.5248321890830994\n",
      "Epoch 67/2000 - Loss: 3.415769338607788 - Train accuracy: 0.4662511944770813 - Test accuracy: 0.5251198410987854\n",
      "Epoch 68/2000 - Loss: 4.624496936798096 - Train accuracy: 0.47123682498931885 - Test accuracy: 0.5262703895568848\n",
      "Epoch 69/2000 - Loss: 4.304710388183594 - Train accuracy: 0.47392138838768005 - Test accuracy: 0.5277085304260254\n",
      "Epoch 70/2000 - Loss: 4.180429935455322 - Train accuracy: 0.47325024008750916 - Test accuracy: 0.5313518643379211\n",
      "Epoch 71/2000 - Loss: 3.4932961463928223 - Train accuracy: 0.4677852392196655 - Test accuracy: 0.5351869463920593\n",
      "Epoch 72/2000 - Loss: 3.3802528381347656 - Train accuracy: 0.47181206941604614 - Test accuracy: 0.5384467840194702\n",
      "Epoch 73/2000 - Loss: 3.697298526763916 - Train accuracy: 0.47334611415863037 - Test accuracy: 0.5404602289199829\n",
      "Epoch 74/2000 - Loss: 4.3031439781188965 - Train accuracy: 0.47392138838768005 - Test accuracy: 0.5405560731887817\n",
      "Epoch 75/2000 - Loss: 4.016073226928711 - Train accuracy: 0.47651007771492004 - Test accuracy: 0.5429530143737793\n",
      "Epoch 76/2000 - Loss: 3.682827949523926 - Train accuracy: 0.4787152409553528 - Test accuracy: 0.5428571701049805\n",
      "Epoch 77/2000 - Loss: 3.9729206562042236 - Train accuracy: 0.4782358705997467 - Test accuracy: 0.5432406663894653\n",
      "Epoch 78/2000 - Loss: 3.6846537590026855 - Train accuracy: 0.4780440926551819 - Test accuracy: 0.5441994071006775\n",
      "Epoch 79/2000 - Loss: 4.650415897369385 - Train accuracy: 0.47986575961112976 - Test accuracy: 0.5460211038589478\n",
      "Epoch 80/2000 - Loss: 4.13031530380249 - Train accuracy: 0.48187920451164246 - Test accuracy: 0.548897385597229\n",
      "Epoch 81/2000 - Loss: 4.015552520751953 - Train accuracy: 0.48120805621147156 - Test accuracy: 0.5524448752403259\n",
      "Epoch 82/2000 - Loss: 3.3929126262664795 - Train accuracy: 0.48763182759284973 - Test accuracy: 0.5552253127098083\n",
      "Epoch 83/2000 - Loss: 4.414124965667725 - Train accuracy: 0.47976988554000854 - Test accuracy: 0.5555129647254944\n",
      "Epoch 84/2000 - Loss: 3.4791903495788574 - Train accuracy: 0.4835090935230255 - Test accuracy: 0.5576222538948059\n",
      "Epoch 85/2000 - Loss: 3.9973504543304443 - Train accuracy: 0.4879194498062134 - Test accuracy: 0.5563758611679077\n",
      "Epoch 86/2000 - Loss: 4.2098774909973145 - Train accuracy: 0.48648130893707275 - Test accuracy: 0.5555129647254944\n",
      "Epoch 87/2000 - Loss: 3.5305004119873047 - Train accuracy: 0.4867689311504364 - Test accuracy: 0.5555129647254944\n",
      "Epoch 88/2000 - Loss: 3.6927249431610107 - Train accuracy: 0.48581016063690186 - Test accuracy: 0.5580057501792908\n",
      "Epoch 89/2000 - Loss: 4.446955680847168 - Train accuracy: 0.48715245723724365 - Test accuracy: 0.5585809946060181\n",
      "Epoch 90/2000 - Loss: 4.134105205535889 - Train accuracy: 0.4893576204776764 - Test accuracy: 0.559252142906189\n",
      "Epoch 91/2000 - Loss: 3.956852674484253 - Train accuracy: 0.48849472403526306 - Test accuracy: 0.5602109432220459\n",
      "Epoch 92/2000 - Loss: 3.4840338230133057 - Train accuracy: 0.48983702063560486 - Test accuracy: 0.5591562986373901\n",
      "Epoch 93/2000 - Loss: 3.6824305057525635 - Train accuracy: 0.4887823462486267 - Test accuracy: 0.5620325803756714\n",
      "Epoch 94/2000 - Loss: 3.9273605346679688 - Train accuracy: 0.4881112277507782 - Test accuracy: 0.5620325803756714\n",
      "Epoch 95/2000 - Loss: 4.431332588195801 - Train accuracy: 0.4892617464065552 - Test accuracy: 0.5612655878067017\n",
      "Epoch 96/2000 - Loss: 4.859111309051514 - Train accuracy: 0.48772770166397095 - Test accuracy: 0.5602109432220459\n",
      "Epoch 97/2000 - Loss: 3.879509925842285 - Train accuracy: 0.48590603470802307 - Test accuracy: 0.5614573359489441\n",
      "Epoch 98/2000 - Loss: 4.642908573150635 - Train accuracy: 0.48724833130836487 - Test accuracy: 0.5641418695449829\n",
      "Epoch 99/2000 - Loss: 4.89354133605957 - Train accuracy: 0.49491849541664124 - Test accuracy: 0.5669223666191101\n",
      "Epoch 100/2000 - Loss: 3.6993753910064697 - Train accuracy: 0.49175456166267395 - Test accuracy: 0.568935751914978\n",
      "Epoch 101/2000 - Loss: 3.383486270904541 - Train accuracy: 0.49252158403396606 - Test accuracy: 0.5692234039306641\n",
      "Epoch 102/2000 - Loss: 3.7457385063171387 - Train accuracy: 0.49453499913215637 - Test accuracy: 0.5716203451156616\n",
      "Epoch 103/2000 - Loss: 3.366093397140503 - Train accuracy: 0.48974111676216125 - Test accuracy: 0.5727708339691162\n",
      "Epoch 104/2000 - Loss: 4.815800666809082 - Train accuracy: 0.49712368845939636 - Test accuracy: 0.5725790858268738\n",
      "Epoch 105/2000 - Loss: 3.333753824234009 - Train accuracy: 0.48849472403526306 - Test accuracy: 0.5728667378425598\n",
      "Epoch 106/2000 - Loss: 3.436404228210449 - Train accuracy: 0.4908916652202606 - Test accuracy: 0.5736337304115295\n",
      "Epoch 107/2000 - Loss: 3.3829164505004883 - Train accuracy: 0.4979865849018097 - Test accuracy: 0.5726749897003174\n",
      "Epoch 108/2000 - Loss: 3.8380789756774902 - Train accuracy: 0.4978907108306885 - Test accuracy: 0.5731543898582458\n",
      "Epoch 109/2000 - Loss: 4.020100116729736 - Train accuracy: 0.4953978955745697 - Test accuracy: 0.5748801827430725\n",
      "Epoch 110/2000 - Loss: 3.776963949203491 - Train accuracy: 0.4942473769187927 - Test accuracy: 0.5755512714385986\n",
      "Epoch 111/2000 - Loss: 4.062901496887207 - Train accuracy: 0.5018216967582703 - Test accuracy: 0.5753595232963562\n",
      "Epoch 112/2000 - Loss: 3.3850765228271484 - Train accuracy: 0.49578139185905457 - Test accuracy: 0.5755512714385986\n",
      "Epoch 113/2000 - Loss: 3.246577262878418 - Train accuracy: 0.5013422966003418 - Test accuracy: 0.576989471912384\n",
      "Epoch 114/2000 - Loss: 3.7962288856506348 - Train accuracy: 0.4999041259288788 - Test accuracy: 0.5780441164970398\n",
      "Epoch 115/2000 - Loss: 3.5253944396972656 - Train accuracy: 0.49453499913215637 - Test accuracy: 0.5773729681968689\n",
      "Epoch 116/2000 - Loss: 4.2256178855896 - Train accuracy: 0.49252158403396606 - Test accuracy: 0.5796740055084229\n",
      "Epoch 117/2000 - Loss: 3.27711820602417 - Train accuracy: 0.49779483675956726 - Test accuracy: 0.5816874504089355\n",
      "Epoch 118/2000 - Loss: 3.8109331130981445 - Train accuracy: 0.5021092891693115 - Test accuracy: 0.5842761397361755\n",
      "Epoch 119/2000 - Loss: 3.779317617416382 - Train accuracy: 0.5055608749389648 - Test accuracy: 0.5865771770477295\n",
      "Epoch 120/2000 - Loss: 4.205026149749756 - Train accuracy: 0.4994247257709503 - Test accuracy: 0.5884947180747986\n",
      "Epoch 121/2000 - Loss: 3.886794328689575 - Train accuracy: 0.50258868932724 - Test accuracy: 0.5904122591018677\n",
      "Epoch 122/2000 - Loss: 3.462815999984741 - Train accuracy: 0.5015340447425842 - Test accuracy: 0.5897411108016968\n",
      "Epoch 123/2000 - Loss: 3.641279697418213 - Train accuracy: 0.5062320232391357 - Test accuracy: 0.5901246666908264\n",
      "Epoch 124/2000 - Loss: 3.1869418621063232 - Train accuracy: 0.5016298890113831 - Test accuracy: 0.5902205109596252\n",
      "Epoch 125/2000 - Loss: 3.7117538452148438 - Train accuracy: 0.5058485269546509 - Test accuracy: 0.5920422077178955\n",
      "Epoch 126/2000 - Loss: 3.835414171218872 - Train accuracy: 0.5074784159660339 - Test accuracy: 0.593863844871521\n",
      "Epoch 127/2000 - Loss: 3.3226146697998047 - Train accuracy: 0.5078619122505188 - Test accuracy: 0.5943432450294495\n",
      "Epoch 128/2000 - Loss: 3.298525094985962 - Train accuracy: 0.5049856305122375 - Test accuracy: 0.5940555930137634\n",
      "Epoch 129/2000 - Loss: 3.6957154273986816 - Train accuracy: 0.5049856305122375 - Test accuracy: 0.5951102375984192\n",
      "Epoch 130/2000 - Loss: 3.6760191917419434 - Train accuracy: 0.5039309859275818 - Test accuracy: 0.5953019857406616\n",
      "Epoch 131/2000 - Loss: 3.2399022579193115 - Train accuracy: 0.504218578338623 - Test accuracy: 0.5962607860565186\n",
      "Epoch 132/2000 - Loss: 3.699570655822754 - Train accuracy: 0.5044103264808655 - Test accuracy: 0.5979865789413452\n",
      "Epoch 133/2000 - Loss: 3.4364423751831055 - Train accuracy: 0.5053691267967224 - Test accuracy: 0.599041223526001\n",
      "Epoch 134/2000 - Loss: 3.40879487991333 - Train accuracy: 0.505465030670166 - Test accuracy: 0.5994247198104858\n",
      "Epoch 135/2000 - Loss: 3.270132303237915 - Train accuracy: 0.5023969411849976 - Test accuracy: 0.6010546684265137\n",
      "Epoch 136/2000 - Loss: 3.5944342613220215 - Train accuracy: 0.5065196752548218 - Test accuracy: 0.6027804613113403\n",
      "Epoch 137/2000 - Loss: 3.913363456726074 - Train accuracy: 0.5089166164398193 - Test accuracy: 0.6036433577537537\n",
      "Epoch 138/2000 - Loss: 3.2387588024139404 - Train accuracy: 0.5041227340698242 - Test accuracy: 0.6022051572799683\n",
      "Epoch 139/2000 - Loss: 3.794084310531616 - Train accuracy: 0.5084372162818909 - Test accuracy: 0.6000958681106567\n",
      "Epoch 140/2000 - Loss: 3.414118528366089 - Train accuracy: 0.5035474300384521 - Test accuracy: 0.5994247198104858\n",
      "Epoch 141/2000 - Loss: 4.158128261566162 - Train accuracy: 0.5128475427627563 - Test accuracy: 0.6003835201263428\n",
      "Epoch 142/2000 - Loss: 3.460620403289795 - Train accuracy: 0.5118888020515442 - Test accuracy: 0.601629912853241\n",
      "Epoch 143/2000 - Loss: 3.2280242443084717 - Train accuracy: 0.5121763944625854 - Test accuracy: 0.6022051572799683\n",
      "Epoch 144/2000 - Loss: 3.6596601009368896 - Train accuracy: 0.5162991285324097 - Test accuracy: 0.604218602180481\n",
      "Epoch 145/2000 - Loss: 3.5065910816192627 - Train accuracy: 0.5078619122505188 - Test accuracy: 0.6037392020225525\n",
      "Epoch 146/2000 - Loss: 3.3991763591766357 - Train accuracy: 0.5082454681396484 - Test accuracy: 0.6052732467651367\n",
      "Epoch 147/2000 - Loss: 4.082612991333008 - Train accuracy: 0.5129434466362 - Test accuracy: 0.6051774024963379\n",
      "Epoch 148/2000 - Loss: 3.3056087493896484 - Train accuracy: 0.5111217498779297 - Test accuracy: 0.6056567430496216\n",
      "Epoch 149/2000 - Loss: 3.2096750736236572 - Train accuracy: 0.5093001127243042 - Test accuracy: 0.6051774024963379\n",
      "Epoch 150/2000 - Loss: 3.700838327407837 - Train accuracy: 0.5094918608665466 - Test accuracy: 0.605848491191864\n",
      "Epoch 151/2000 - Loss: 3.2598323822021484 - Train accuracy: 0.5111217498779297 - Test accuracy: 0.6053691506385803\n",
      "Epoch 152/2000 - Loss: 3.5627546310424805 - Train accuracy: 0.5058485269546509 - Test accuracy: 0.6075742840766907\n",
      "Epoch 153/2000 - Loss: 3.605478525161743 - Train accuracy: 0.5044103264808655 - Test accuracy: 0.6091083288192749\n",
      "Epoch 154/2000 - Loss: 3.624892234802246 - Train accuracy: 0.5177372694015503 - Test accuracy: 0.6105465292930603\n",
      "Epoch 155/2000 - Loss: 3.39863920211792 - Train accuracy: 0.5150527358055115 - Test accuracy: 0.6095877289772034\n",
      "Epoch 156/2000 - Loss: 3.54618239402771 - Train accuracy: 0.5113134980201721 - Test accuracy: 0.6101629734039307\n",
      "Epoch 157/2000 - Loss: 3.659247636795044 - Train accuracy: 0.5132310390472412 - Test accuracy: 0.6086289286613464\n",
      "Epoch 158/2000 - Loss: 3.1349728107452393 - Train accuracy: 0.5116011500358582 - Test accuracy: 0.6107382774353027\n",
      "Epoch 159/2000 - Loss: 3.5127880573272705 - Train accuracy: 0.5144774913787842 - Test accuracy: 0.611025869846344\n",
      "Epoch 160/2000 - Loss: 3.9240503311157227 - Train accuracy: 0.5116011500358582 - Test accuracy: 0.6116011738777161\n",
      "Epoch 161/2000 - Loss: 3.379784345626831 - Train accuracy: 0.5071908235549927 - Test accuracy: 0.6109300255775452\n",
      "Epoch 162/2000 - Loss: 3.537931442260742 - Train accuracy: 0.5163950324058533 - Test accuracy: 0.6103547215461731\n",
      "Epoch 163/2000 - Loss: 3.5500123500823975 - Train accuracy: 0.5141898393630981 - Test accuracy: 0.6117929220199585\n",
      "Epoch 164/2000 - Loss: 3.151890993118286 - Train accuracy: 0.5132310390472412 - Test accuracy: 0.6125599145889282\n",
      "Epoch 165/2000 - Loss: 3.195068836212158 - Train accuracy: 0.5047938823699951 - Test accuracy: 0.6150527596473694\n",
      "Epoch 166/2000 - Loss: 3.1371259689331055 - Train accuracy: 0.5126557946205139 - Test accuracy: 0.6158197522163391\n",
      "Epoch 167/2000 - Loss: 3.182443380355835 - Train accuracy: 0.5075743198394775 - Test accuracy: 0.6175455451011658\n",
      "Epoch 168/2000 - Loss: 3.05246639251709 - Train accuracy: 0.5126557946205139 - Test accuracy: 0.6173537969589233\n",
      "Epoch 169/2000 - Loss: 3.6367275714874268 - Train accuracy: 0.5128475427627563 - Test accuracy: 0.6186001896858215\n",
      "Epoch 170/2000 - Loss: 3.207324981689453 - Train accuracy: 0.5133269429206848 - Test accuracy: 0.6202300786972046\n",
      "Epoch 171/2000 - Loss: 3.24532151222229 - Train accuracy: 0.5158197283744812 - Test accuracy: 0.6209971308708191\n",
      "Epoch 172/2000 - Loss: 3.6205191612243652 - Train accuracy: 0.5153403878211975 - Test accuracy: 0.6240652203559875\n",
      "Epoch 173/2000 - Loss: 3.24448299407959 - Train accuracy: 0.5079578161239624 - Test accuracy: 0.6259827613830566\n",
      "Epoch 174/2000 - Loss: 3.487131357192993 - Train accuracy: 0.5205177664756775 - Test accuracy: 0.6263662576675415\n",
      "Epoch 175/2000 - Loss: 3.1193318367004395 - Train accuracy: 0.5162991285324097 - Test accuracy: 0.6269415020942688\n",
      "Epoch 176/2000 - Loss: 3.226652145385742 - Train accuracy: 0.519463062286377 - Test accuracy: 0.6274209022521973\n",
      "Epoch 177/2000 - Loss: 3.421804428100586 - Train accuracy: 0.5117928981781006 - Test accuracy: 0.6262703537940979\n",
      "Epoch 178/2000 - Loss: 3.0895283222198486 - Train accuracy: 0.5140939354896545 - Test accuracy: 0.6267497539520264\n",
      "Epoch 179/2000 - Loss: 3.2291882038116455 - Train accuracy: 0.5183125734329224 - Test accuracy: 0.6283797025680542\n",
      "Epoch 180/2000 - Loss: 3.462879180908203 - Train accuracy: 0.5186960697174072 - Test accuracy: 0.6291466951370239\n",
      "Epoch 181/2000 - Loss: 3.446071147918701 - Train accuracy: 0.5219559073448181 - Test accuracy: 0.6302972435951233\n",
      "Epoch 182/2000 - Loss: 3.9846949577331543 - Train accuracy: 0.5198466181755066 - Test accuracy: 0.631351888179779\n",
      "Epoch 183/2000 - Loss: 3.1961123943328857 - Train accuracy: 0.5230105519294739 - Test accuracy: 0.6318312287330627\n",
      "Epoch 184/2000 - Loss: 3.447211503982544 - Train accuracy: 0.5179290771484375 - Test accuracy: 0.6328859329223633\n",
      "Epoch 185/2000 - Loss: 3.11775279045105 - Train accuracy: 0.5216682553291321 - Test accuracy: 0.633940577507019\n",
      "Epoch 186/2000 - Loss: 3.3779332637786865 - Train accuracy: 0.5161073803901672 - Test accuracy: 0.6356663703918457\n",
      "Epoch 187/2000 - Loss: 3.235680341720581 - Train accuracy: 0.5205177664756775 - Test accuracy: 0.636241614818573\n",
      "Epoch 188/2000 - Loss: 3.1095004081726074 - Train accuracy: 0.5244486927986145 - Test accuracy: 0.6346117258071899\n",
      "Epoch 189/2000 - Loss: 3.0308749675750732 - Train accuracy: 0.5162991285324097 - Test accuracy: 0.6348034739494324\n",
      "Epoch 190/2000 - Loss: 3.3702409267425537 - Train accuracy: 0.5208053588867188 - Test accuracy: 0.6343240737915039\n",
      "Epoch 191/2000 - Loss: 3.3462839126586914 - Train accuracy: 0.5204218626022339 - Test accuracy: 0.635953962802887\n",
      "Epoch 192/2000 - Loss: 3.1345455646514893 - Train accuracy: 0.5196548700332642 - Test accuracy: 0.6374880075454712\n",
      "Epoch 193/2000 - Loss: 3.1950669288635254 - Train accuracy: 0.5214765071868896 - Test accuracy: 0.6380632519721985\n",
      "Epoch 194/2000 - Loss: 3.350126028060913 - Train accuracy: 0.5158197283744812 - Test accuracy: 0.6393097043037415\n",
      "Epoch 195/2000 - Loss: 3.3904671669006348 - Train accuracy: 0.5271332859992981 - Test accuracy: 0.6406519412994385\n",
      "Epoch 196/2000 - Loss: 3.2650556564331055 - Train accuracy: 0.5267497897148132 - Test accuracy: 0.641418993473053\n",
      "Epoch 197/2000 - Loss: 3.1126959323883057 - Train accuracy: 0.5288590788841248 - Test accuracy: 0.639117956161499\n",
      "Epoch 198/2000 - Loss: 3.5713155269622803 - Train accuracy: 0.5236817002296448 - Test accuracy: 0.6411313414573669\n",
      "Epoch 199/2000 - Loss: 3.5688998699188232 - Train accuracy: 0.5209012627601624 - Test accuracy: 0.6415148377418518\n",
      "Epoch 200/2000 - Loss: 3.341813325881958 - Train accuracy: 0.5225311517715454 - Test accuracy: 0.6411313414573669\n",
      "Epoch 201/2000 - Loss: 3.0867769718170166 - Train accuracy: 0.5286673307418823 - Test accuracy: 0.6401726007461548\n",
      "Epoch 202/2000 - Loss: 3.3194899559020996 - Train accuracy: 0.5270373821258545 - Test accuracy: 0.6392138004302979\n",
      "Epoch 203/2000 - Loss: 3.339719295501709 - Train accuracy: 0.522627055644989 - Test accuracy: 0.6382550597190857\n",
      "Epoch 204/2000 - Loss: 3.157294273376465 - Train accuracy: 0.5254074931144714 - Test accuracy: 0.6374880075454712\n",
      "Epoch 205/2000 - Loss: 3.1013567447662354 - Train accuracy: 0.5228188037872314 - Test accuracy: 0.6375839114189148\n",
      "Epoch 206/2000 - Loss: 3.3904917240142822 - Train accuracy: 0.5209012627601624 - Test accuracy: 0.6393097043037415\n",
      "Epoch 207/2000 - Loss: 3.5639710426330566 - Train accuracy: 0.524928092956543 - Test accuracy: 0.6421859860420227\n",
      "Epoch 208/2000 - Loss: 3.1665451526641846 - Train accuracy: 0.5254074931144714 - Test accuracy: 0.6435282826423645\n",
      "Epoch 209/2000 - Loss: 3.2929847240448 - Train accuracy: 0.5224353075027466 - Test accuracy: 0.6452540755271912\n",
      "Epoch 210/2000 - Loss: 3.3147096633911133 - Train accuracy: 0.5230105519294739 - Test accuracy: 0.6471716165542603\n",
      "Epoch 211/2000 - Loss: 2.988508939743042 - Train accuracy: 0.5229146480560303 - Test accuracy: 0.6471716165542603\n",
      "Epoch 212/2000 - Loss: 2.9600350856781006 - Train accuracy: 0.5251198410987854 - Test accuracy: 0.6464046239852905\n",
      "Epoch 213/2000 - Loss: 3.1314709186553955 - Train accuracy: 0.5295302271842957 - Test accuracy: 0.6480345129966736\n",
      "Epoch 214/2000 - Loss: 3.0379319190979004 - Train accuracy: 0.5257909893989563 - Test accuracy: 0.6484180092811584\n",
      "Epoch 215/2000 - Loss: 3.316821575164795 - Train accuracy: 0.5287631750106812 - Test accuracy: 0.6504314541816711\n",
      "Epoch 216/2000 - Loss: 3.151674747467041 - Train accuracy: 0.5214765071868896 - Test accuracy: 0.65052729845047\n",
      "Epoch 217/2000 - Loss: 3.088176727294922 - Train accuracy: 0.5253115892410278 - Test accuracy: 0.6510066986083984\n",
      "Epoch 218/2000 - Loss: 3.5774474143981934 - Train accuracy: 0.527516782283783 - Test accuracy: 0.6516778469085693\n",
      "Epoch 219/2000 - Loss: 3.2301719188690186 - Train accuracy: 0.5334611535072327 - Test accuracy: 0.6503355503082275\n",
      "Epoch 220/2000 - Loss: 3.0799622535705566 - Train accuracy: 0.5280920267105103 - Test accuracy: 0.6489933133125305\n",
      "Epoch 221/2000 - Loss: 3.053962469100952 - Train accuracy: 0.5262703895568848 - Test accuracy: 0.6484180092811584\n",
      "Epoch 222/2000 - Loss: 3.1361565589904785 - Train accuracy: 0.5270373821258545 - Test accuracy: 0.64793860912323\n",
      "Epoch 223/2000 - Loss: 3.2874608039855957 - Train accuracy: 0.524928092956543 - Test accuracy: 0.6506232023239136\n",
      "Epoch 224/2000 - Loss: 3.448936939239502 - Train accuracy: 0.5331735610961914 - Test accuracy: 0.6493768095970154\n",
      "Epoch 225/2000 - Loss: 3.1454086303710938 - Train accuracy: 0.525215744972229 - Test accuracy: 0.6489933133125305\n",
      "Epoch 226/2000 - Loss: 2.9691638946533203 - Train accuracy: 0.5332694053649902 - Test accuracy: 0.6476510167121887\n",
      "Epoch 227/2000 - Loss: 3.1307930946350098 - Train accuracy: 0.5322147607803345 - Test accuracy: 0.6483221650123596\n",
      "Epoch 228/2000 - Loss: 3.2316620349884033 - Train accuracy: 0.527804434299469 - Test accuracy: 0.6492809057235718\n",
      "Epoch 229/2000 - Loss: 3.222647190093994 - Train accuracy: 0.5262703895568848 - Test accuracy: 0.6526366472244263\n",
      "Epoch 230/2000 - Loss: 3.0469889640808105 - Train accuracy: 0.5345157980918884 - Test accuracy: 0.6540747880935669\n",
      "Epoch 231/2000 - Loss: 3.326997756958008 - Train accuracy: 0.5254074931144714 - Test accuracy: 0.6558964252471924\n",
      "Epoch 232/2000 - Loss: 3.111867904663086 - Train accuracy: 0.5244486927986145 - Test accuracy: 0.6566634774208069\n",
      "Epoch 233/2000 - Loss: 3.0033118724823 - Train accuracy: 0.5263662338256836 - Test accuracy: 0.6575263738632202\n",
      "Epoch 234/2000 - Loss: 3.236927032470703 - Train accuracy: 0.5306807160377502 - Test accuracy: 0.6564717292785645\n",
      "Epoch 235/2000 - Loss: 3.2537622451782227 - Train accuracy: 0.5325982570648193 - Test accuracy: 0.6567593216896057\n",
      "Epoch 236/2000 - Loss: 3.178070545196533 - Train accuracy: 0.5310642123222351 - Test accuracy: 0.6573346257209778\n",
      "Epoch 237/2000 - Loss: 3.2751681804656982 - Train accuracy: 0.5290508270263672 - Test accuracy: 0.6582933664321899\n",
      "Epoch 238/2000 - Loss: 3.2702860832214355 - Train accuracy: 0.5377756357192993 - Test accuracy: 0.6582933664321899\n",
      "Epoch 239/2000 - Loss: 3.0830485820770264 - Train accuracy: 0.5382550358772278 - Test accuracy: 0.6591562628746033\n",
      "Epoch 240/2000 - Loss: 2.961484432220459 - Train accuracy: 0.5292425751686096 - Test accuracy: 0.6583892703056335\n",
      "Epoch 241/2000 - Loss: 3.223696231842041 - Train accuracy: 0.5331735610961914 - Test accuracy: 0.6580057740211487\n",
      "Epoch 242/2000 - Loss: 2.991478443145752 - Train accuracy: 0.5290508270263672 - Test accuracy: 0.658581018447876\n",
      "Epoch 243/2000 - Loss: 3.003648281097412 - Train accuracy: 0.527804434299469 - Test accuracy: 0.6589645147323608\n",
      "Epoch 244/2000 - Loss: 2.9837687015533447 - Train accuracy: 0.5338446497917175 - Test accuracy: 0.6589645147323608\n",
      "Epoch 245/2000 - Loss: 2.9236228466033936 - Train accuracy: 0.5274208784103394 - Test accuracy: 0.6573346257209778\n",
      "Epoch 246/2000 - Loss: 3.201784610748291 - Train accuracy: 0.5348034501075745 - Test accuracy: 0.6567593216896057\n",
      "Epoch 247/2000 - Loss: 2.943228006362915 - Train accuracy: 0.537200391292572 - Test accuracy: 0.6571428775787354\n",
      "Epoch 248/2000 - Loss: 3.2833328247070312 - Train accuracy: 0.5310642123222351 - Test accuracy: 0.6569511294364929\n",
      "Epoch 249/2000 - Loss: 2.9686405658721924 - Train accuracy: 0.532023012638092 - Test accuracy: 0.6566634774208069\n",
      "Epoch 250/2000 - Loss: 2.867035150527954 - Train accuracy: 0.5382550358772278 - Test accuracy: 0.6580057740211487\n",
      "Epoch 251/2000 - Loss: 3.3781967163085938 - Train accuracy: 0.5415148735046387 - Test accuracy: 0.6581016182899475\n",
      "Epoch 252/2000 - Loss: 3.1944613456726074 - Train accuracy: 0.5385426878929138 - Test accuracy: 0.6600191593170166\n",
      "Epoch 253/2000 - Loss: 3.270118474960327 - Train accuracy: 0.5308724641799927 - Test accuracy: 0.6603068113327026\n",
      "Epoch 254/2000 - Loss: 3.1245369911193848 - Train accuracy: 0.531735360622406 - Test accuracy: 0.6609779596328735\n",
      "Epoch 255/2000 - Loss: 3.1493427753448486 - Train accuracy: 0.537200391292572 - Test accuracy: 0.6615532040596008\n",
      "Epoch 256/2000 - Loss: 2.9974546432495117 - Train accuracy: 0.5402684807777405 - Test accuracy: 0.6613614559173584\n",
      "Epoch 257/2000 - Loss: 3.0436854362487793 - Train accuracy: 0.5342282056808472 - Test accuracy: 0.6612655520439148\n",
      "Epoch 258/2000 - Loss: 3.165588617324829 - Train accuracy: 0.5378715395927429 - Test accuracy: 0.6615532040596008\n",
      "Epoch 259/2000 - Loss: 3.1270992755889893 - Train accuracy: 0.5355704426765442 - Test accuracy: 0.6625120043754578\n",
      "Epoch 260/2000 - Loss: 2.931366443634033 - Train accuracy: 0.5393096804618835 - Test accuracy: 0.6628955006599426\n",
      "Epoch 261/2000 - Loss: 3.1215574741363525 - Train accuracy: 0.5337488055229187 - Test accuracy: 0.6628955006599426\n",
      "Epoch 262/2000 - Loss: 2.9137792587280273 - Train accuracy: 0.5315436124801636 - Test accuracy: 0.6629913449287415\n",
      "Epoch 263/2000 - Loss: 3.026726722717285 - Train accuracy: 0.5356663465499878 - Test accuracy: 0.6634707450866699\n",
      "Epoch 264/2000 - Loss: 3.1449508666992188 - Train accuracy: 0.5312560200691223 - Test accuracy: 0.6623202562332153\n",
      "Epoch 265/2000 - Loss: 3.293879508972168 - Train accuracy: 0.5353786945343018 - Test accuracy: 0.6624161005020142\n",
      "Epoch 266/2000 - Loss: 3.073509454727173 - Train accuracy: 0.5337488055229187 - Test accuracy: 0.6631831526756287\n",
      "Epoch 267/2000 - Loss: 2.9563393592834473 - Train accuracy: 0.5337488055229187 - Test accuracy: 0.6619367003440857\n",
      "Epoch 268/2000 - Loss: 2.853823184967041 - Train accuracy: 0.5356663465499878 - Test accuracy: 0.6621284484863281\n",
      "Epoch 269/2000 - Loss: 2.8978989124298096 - Train accuracy: 0.5354745984077454 - Test accuracy: 0.6622243523597717\n",
      "Epoch 270/2000 - Loss: 3.167282819747925 - Train accuracy: 0.5389261841773987 - Test accuracy: 0.6623202562332153\n",
      "Epoch 271/2000 - Loss: 3.2879185676574707 - Train accuracy: 0.5352828502655029 - Test accuracy: 0.6621284484863281\n",
      "Epoch 272/2000 - Loss: 3.158841609954834 - Train accuracy: 0.5348993539810181 - Test accuracy: 0.6626078486442566\n",
      "Epoch 273/2000 - Loss: 2.9917914867401123 - Train accuracy: 0.5395973324775696 - Test accuracy: 0.6639501452445984\n",
      "Epoch 274/2000 - Loss: 2.9815545082092285 - Train accuracy: 0.5327900052070618 - Test accuracy: 0.6639501452445984\n",
      "Epoch 275/2000 - Loss: 3.197814702987671 - Train accuracy: 0.5334611535072327 - Test accuracy: 0.664046049118042\n",
      "Epoch 276/2000 - Loss: 3.0513858795166016 - Train accuracy: 0.5379673838615417 - Test accuracy: 0.6652924418449402\n",
      "Epoch 277/2000 - Loss: 3.021599292755127 - Train accuracy: 0.5313518643379211 - Test accuracy: 0.6651006937026978\n",
      "Epoch 278/2000 - Loss: 3.1868858337402344 - Train accuracy: 0.5361457467079163 - Test accuracy: 0.6645253896713257\n",
      "Epoch 279/2000 - Loss: 3.0148441791534424 - Train accuracy: 0.5323106646537781 - Test accuracy: 0.6644295454025269\n",
      "Epoch 280/2000 - Loss: 3.1883952617645264 - Train accuracy: 0.5355704426765442 - Test accuracy: 0.6642377972602844\n",
      "Epoch 281/2000 - Loss: 3.3439455032348633 - Train accuracy: 0.5386385321617126 - Test accuracy: 0.6647171378135681\n",
      "Epoch 282/2000 - Loss: 2.9349400997161865 - Train accuracy: 0.5356663465499878 - Test accuracy: 0.6643336415290833\n",
      "Epoch 283/2000 - Loss: 2.8461556434631348 - Train accuracy: 0.5344199538230896 - Test accuracy: 0.6647171378135681\n",
      "Epoch 284/2000 - Loss: 3.0508198738098145 - Train accuracy: 0.5352828502655029 - Test accuracy: 0.665675938129425\n",
      "Epoch 285/2000 - Loss: 2.9149813652038574 - Train accuracy: 0.5383509397506714 - Test accuracy: 0.6659635901451111\n",
      "Epoch 286/2000 - Loss: 3.0625388622283936 - Train accuracy: 0.5416107177734375 - Test accuracy: 0.6669223308563232\n",
      "Epoch 287/2000 - Loss: 3.192096710205078 - Train accuracy: 0.5404602289199829 - Test accuracy: 0.6671140789985657\n",
      "Epoch 288/2000 - Loss: 2.880847930908203 - Train accuracy: 0.539501428604126 - Test accuracy: 0.6674975752830505\n",
      "Epoch 289/2000 - Loss: 3.102062940597534 - Train accuracy: 0.5444870591163635 - Test accuracy: 0.6692233681678772\n",
      "Epoch 290/2000 - Loss: 3.170705556869507 - Train accuracy: 0.5431447625160217 - Test accuracy: 0.6675934791564941\n",
      "Epoch 291/2000 - Loss: 3.017162322998047 - Train accuracy: 0.5378715395927429 - Test accuracy: 0.6676893830299377\n",
      "Epoch 292/2000 - Loss: 2.9108715057373047 - Train accuracy: 0.5315436124801636 - Test accuracy: 0.6674017310142517\n",
      "Epoch 293/2000 - Loss: 3.098386764526367 - Train accuracy: 0.5312560200691223 - Test accuracy: 0.6684563755989075\n",
      "Epoch 294/2000 - Loss: 2.800675868988037 - Train accuracy: 0.5413231253623962 - Test accuracy: 0.6678811311721802\n",
      "Epoch 295/2000 - Loss: 2.8696820735931396 - Train accuracy: 0.5394055843353271 - Test accuracy: 0.6678811311721802\n",
      "Epoch 296/2000 - Loss: 2.980393648147583 - Train accuracy: 0.5418024659156799 - Test accuracy: 0.6672099828720093\n",
      "Epoch 297/2000 - Loss: 2.9192874431610107 - Train accuracy: 0.5345157980918884 - Test accuracy: 0.6677852272987366\n",
      "Epoch 298/2000 - Loss: 3.1987125873565674 - Train accuracy: 0.5407478213310242 - Test accuracy: 0.668264627456665\n",
      "Epoch 299/2000 - Loss: 3.0274856090545654 - Train accuracy: 0.5396931767463684 - Test accuracy: 0.6681687235832214\n",
      "Epoch 300/2000 - Loss: 3.081268310546875 - Train accuracy: 0.5380632877349854 - Test accuracy: 0.6693192720413208\n",
      "Epoch 301/2000 - Loss: 3.1647422313690186 - Train accuracy: 0.5374880433082581 - Test accuracy: 0.6700862646102905\n",
      "Epoch 302/2000 - Loss: 2.9020283222198486 - Train accuracy: 0.5386385321617126 - Test accuracy: 0.6700862646102905\n",
      "Epoch 303/2000 - Loss: 2.9651918411254883 - Train accuracy: 0.5323106646537781 - Test accuracy: 0.6721956133842468\n",
      "Epoch 304/2000 - Loss: 2.956678628921509 - Train accuracy: 0.5399808287620544 - Test accuracy: 0.6739214062690735\n",
      "Epoch 305/2000 - Loss: 3.0660510063171387 - Train accuracy: 0.5450623035430908 - Test accuracy: 0.6735378503799438\n",
      "Epoch 306/2000 - Loss: 3.2405834197998047 - Train accuracy: 0.5414189696311951 - Test accuracy: 0.6753595471382141\n",
      "Epoch 307/2000 - Loss: 2.92264461517334 - Train accuracy: 0.5405560731887817 - Test accuracy: 0.6750718951225281\n",
      "Epoch 308/2000 - Loss: 3.060940980911255 - Train accuracy: 0.5409395694732666 - Test accuracy: 0.6747843027114868\n",
      "Epoch 309/2000 - Loss: 3.0899219512939453 - Train accuracy: 0.5406519770622253 - Test accuracy: 0.6742089986801147\n",
      "Epoch 310/2000 - Loss: 2.9426584243774414 - Train accuracy: 0.5484180450439453 - Test accuracy: 0.6744007468223572\n",
      "Epoch 311/2000 - Loss: 2.89400577545166 - Train accuracy: 0.539501428604126 - Test accuracy: 0.6735378503799438\n",
      "Epoch 312/2000 - Loss: 2.8433713912963867 - Train accuracy: 0.5511025786399841 - Test accuracy: 0.6738255023956299\n",
      "Epoch 313/2000 - Loss: 2.939577341079712 - Train accuracy: 0.5403643250465393 - Test accuracy: 0.6743049025535583\n",
      "Epoch 314/2000 - Loss: 2.892256498336792 - Train accuracy: 0.5432406663894653 - Test accuracy: 0.6722914576530457\n",
      "Epoch 315/2000 - Loss: 3.0597240924835205 - Train accuracy: 0.5481303930282593 - Test accuracy: 0.6720038056373596\n",
      "Epoch 316/2000 - Loss: 3.241503953933716 - Train accuracy: 0.5413231253623962 - Test accuracy: 0.6738255023956299\n",
      "Epoch 317/2000 - Loss: 2.8900198936462402 - Train accuracy: 0.5389261841773987 - Test accuracy: 0.6749760508537292\n",
      "Epoch 318/2000 - Loss: 3.015289545059204 - Train accuracy: 0.544678807258606 - Test accuracy: 0.6754553914070129\n",
      "Epoch 319/2000 - Loss: 2.9484803676605225 - Train accuracy: 0.5378715395927429 - Test accuracy: 0.6756471991539001\n",
      "Epoch 320/2000 - Loss: 2.956841230392456 - Train accuracy: 0.5419942736625671 - Test accuracy: 0.6723873615264893\n",
      "Epoch 321/2000 - Loss: 2.996692657470703 - Train accuracy: 0.5394055843353271 - Test accuracy: 0.673154354095459\n",
      "Epoch 322/2000 - Loss: 2.988684892654419 - Train accuracy: 0.5373921394348145 - Test accuracy: 0.6740172505378723\n",
      "Epoch 323/2000 - Loss: 2.9974687099456787 - Train accuracy: 0.5408437252044678 - Test accuracy: 0.6756471991539001\n",
      "Epoch 324/2000 - Loss: 3.1657276153564453 - Train accuracy: 0.547267496585846 - Test accuracy: 0.6752636432647705\n",
      "Epoch 325/2000 - Loss: 2.9479334354400635 - Train accuracy: 0.5489932894706726 - Test accuracy: 0.6749760508537292\n",
      "Epoch 326/2000 - Loss: 2.9543230533599854 - Train accuracy: 0.536912739276886 - Test accuracy: 0.6759347915649414\n",
      "Epoch 327/2000 - Loss: 2.8647890090942383 - Train accuracy: 0.5393096804618835 - Test accuracy: 0.6775647401809692\n",
      "Epoch 328/2000 - Loss: 2.7836384773254395 - Train accuracy: 0.537200391292572 - Test accuracy: 0.6773729920387268\n",
      "Epoch 329/2000 - Loss: 2.771845817565918 - Train accuracy: 0.5441035628318787 - Test accuracy: 0.6775647401809692\n",
      "Epoch 330/2000 - Loss: 3.0189526081085205 - Train accuracy: 0.5468840003013611 - Test accuracy: 0.6782358288764954\n",
      "Epoch 331/2000 - Loss: 2.8809564113616943 - Train accuracy: 0.5461169481277466 - Test accuracy: 0.678619384765625\n",
      "Epoch 332/2000 - Loss: 2.8484394550323486 - Train accuracy: 0.5477468967437744 - Test accuracy: 0.6790028810501099\n",
      "Epoch 333/2000 - Loss: 2.8669679164886475 - Train accuracy: 0.5473634004592896 - Test accuracy: 0.679961621761322\n",
      "Epoch 334/2000 - Loss: 2.845698118209839 - Train accuracy: 0.5443911552429199 - Test accuracy: 0.6791946291923523\n",
      "Epoch 335/2000 - Loss: 2.9267876148223877 - Train accuracy: 0.5509108304977417 - Test accuracy: 0.6791946291923523\n",
      "Epoch 336/2000 - Loss: 2.880446672439575 - Train accuracy: 0.5439118146896362 - Test accuracy: 0.6790028810501099\n",
      "Epoch 337/2000 - Loss: 2.805703639984131 - Train accuracy: 0.5433365106582642 - Test accuracy: 0.6781399846076965\n",
      "Epoch 338/2000 - Loss: 3.0549581050872803 - Train accuracy: 0.5415148735046387 - Test accuracy: 0.6771811842918396\n",
      "Epoch 339/2000 - Loss: 3.0780248641967773 - Train accuracy: 0.5422818660736084 - Test accuracy: 0.678331732749939\n",
      "Epoch 340/2000 - Loss: 2.9940567016601562 - Train accuracy: 0.5484180450439453 - Test accuracy: 0.6792905330657959\n",
      "Epoch 341/2000 - Loss: 3.1827504634857178 - Train accuracy: 0.5411313772201538 - Test accuracy: 0.678331732749939\n",
      "Epoch 342/2000 - Loss: 2.955761671066284 - Train accuracy: 0.5406519770622253 - Test accuracy: 0.6797698736190796\n",
      "Epoch 343/2000 - Loss: 2.9091217517852783 - Train accuracy: 0.5554170608520508 - Test accuracy: 0.6792905330657959\n",
      "Epoch 344/2000 - Loss: 2.8295576572418213 - Train accuracy: 0.5493767857551575 - Test accuracy: 0.6785234808921814\n",
      "Epoch 345/2000 - Loss: 2.9533143043518066 - Train accuracy: 0.5418024659156799 - Test accuracy: 0.6780440807342529\n",
      "Epoch 346/2000 - Loss: 3.1055941581726074 - Train accuracy: 0.5399808287620544 - Test accuracy: 0.6768935918807983\n",
      "Epoch 347/2000 - Loss: 2.7848808765411377 - Train accuracy: 0.5413231253623962 - Test accuracy: 0.6771811842918396\n",
      "Epoch 348/2000 - Loss: 2.988941192626953 - Train accuracy: 0.546308696269989 - Test accuracy: 0.678331732749939\n",
      "Epoch 349/2000 - Loss: 2.742236614227295 - Train accuracy: 0.5421860218048096 - Test accuracy: 0.678331732749939\n",
      "Epoch 350/2000 - Loss: 3.0102379322052 - Train accuracy: 0.5355704426765442 - Test accuracy: 0.6788111329078674\n",
      "Epoch 351/2000 - Loss: 3.088780641555786 - Train accuracy: 0.5440076589584351 - Test accuracy: 0.6777564883232117\n",
      "Epoch 352/2000 - Loss: 3.0157113075256348 - Train accuracy: 0.5418983697891235 - Test accuracy: 0.6773729920387268\n",
      "Epoch 353/2000 - Loss: 2.9831016063690186 - Train accuracy: 0.5376797914505005 - Test accuracy: 0.6785234808921814\n",
      "Epoch 354/2000 - Loss: 3.0133163928985596 - Train accuracy: 0.5454457998275757 - Test accuracy: 0.6781399846076965\n",
      "Epoch 355/2000 - Loss: 2.847963571548462 - Train accuracy: 0.5508149862289429 - Test accuracy: 0.6791946291923523\n",
      "Epoch 356/2000 - Loss: 2.8584277629852295 - Train accuracy: 0.5390220284461975 - Test accuracy: 0.6801534295082092\n",
      "Epoch 357/2000 - Loss: 3.0460846424102783 - Train accuracy: 0.5465005040168762 - Test accuracy: 0.6813039183616638\n",
      "Epoch 358/2000 - Loss: 2.851806879043579 - Train accuracy: 0.5440076589584351 - Test accuracy: 0.680920422077179\n",
      "Epoch 359/2000 - Loss: 3.3161962032318115 - Train accuracy: 0.5481303930282593 - Test accuracy: 0.6810163259506226\n",
      "Epoch 360/2000 - Loss: 2.8264801502227783 - Train accuracy: 0.5421860218048096 - Test accuracy: 0.6797698736190796\n",
      "Epoch 361/2000 - Loss: 2.9540560245513916 - Train accuracy: 0.542377769947052 - Test accuracy: 0.6803451776504517\n",
      "Epoch 362/2000 - Loss: 2.899733304977417 - Train accuracy: 0.5451582074165344 - Test accuracy: 0.6801534295082092\n",
      "Epoch 363/2000 - Loss: 2.814452886581421 - Train accuracy: 0.5478427410125732 - Test accuracy: 0.682837963104248\n",
      "Epoch 364/2000 - Loss: 2.859121799468994 - Train accuracy: 0.5441035628318787 - Test accuracy: 0.6802492737770081\n",
      "Epoch 365/2000 - Loss: 2.8800177574157715 - Train accuracy: 0.5413231253623962 - Test accuracy: 0.6792905330657959\n",
      "Epoch 366/2000 - Loss: 2.975961685180664 - Train accuracy: 0.5436241626739502 - Test accuracy: 0.6805369257926941\n",
      "Epoch 367/2000 - Loss: 2.8925061225891113 - Train accuracy: 0.5457334518432617 - Test accuracy: 0.679961621761322\n",
      "Epoch 368/2000 - Loss: 2.8433170318603516 - Train accuracy: 0.5537871718406677 - Test accuracy: 0.680920422077179\n",
      "Epoch 369/2000 - Loss: 2.811908721923828 - Train accuracy: 0.5453499555587769 - Test accuracy: 0.6794822812080383\n",
      "Epoch 370/2000 - Loss: 2.9219813346862793 - Train accuracy: 0.5478427410125732 - Test accuracy: 0.6800575256347656\n",
      "Epoch 371/2000 - Loss: 2.766309976577759 - Train accuracy: 0.5524448752403259 - Test accuracy: 0.6802492737770081\n",
      "Epoch 372/2000 - Loss: 2.8503191471099854 - Train accuracy: 0.5430489182472229 - Test accuracy: 0.6801534295082092\n",
      "Epoch 373/2000 - Loss: 2.993652105331421 - Train accuracy: 0.5454457998275757 - Test accuracy: 0.6808245182037354\n",
      "Epoch 374/2000 - Loss: 2.7709665298461914 - Train accuracy: 0.5467880964279175 - Test accuracy: 0.6815915703773499\n",
      "Epoch 375/2000 - Loss: 2.8357768058776855 - Train accuracy: 0.5442953109741211 - Test accuracy: 0.6824544668197632\n",
      "Epoch 376/2000 - Loss: 3.167057752609253 - Train accuracy: 0.5395973324775696 - Test accuracy: 0.682837963104248\n",
      "Epoch 377/2000 - Loss: 2.957043409347534 - Train accuracy: 0.5486097931861877 - Test accuracy: 0.6824544668197632\n",
      "Epoch 378/2000 - Loss: 2.722973585128784 - Train accuracy: 0.5414189696311951 - Test accuracy: 0.683796763420105\n",
      "Epoch 379/2000 - Loss: 3.003457546234131 - Train accuracy: 0.5504314303398132 - Test accuracy: 0.6845637559890747\n",
      "Epoch 380/2000 - Loss: 2.889099359512329 - Train accuracy: 0.5503355860710144 - Test accuracy: 0.685139000415802\n",
      "Epoch 381/2000 - Loss: 2.9876253604888916 - Train accuracy: 0.5441035628318787 - Test accuracy: 0.6860018968582153\n",
      "Epoch 382/2000 - Loss: 2.759929656982422 - Train accuracy: 0.5466922521591187 - Test accuracy: 0.6858101487159729\n",
      "Epoch 383/2000 - Loss: 3.03869891166687 - Train accuracy: 0.5464046001434326 - Test accuracy: 0.6849472522735596\n",
      "Epoch 384/2000 - Loss: 2.9217545986175537 - Train accuracy: 0.5464046001434326 - Test accuracy: 0.6855225563049316\n",
      "Epoch 385/2000 - Loss: 2.873479127883911 - Train accuracy: 0.5513902306556702 - Test accuracy: 0.6848514080047607\n",
      "Epoch 386/2000 - Loss: 2.930238962173462 - Train accuracy: 0.5442953109741211 - Test accuracy: 0.6857143044471741\n",
      "Epoch 387/2000 - Loss: 2.963334321975708 - Train accuracy: 0.5476509928703308 - Test accuracy: 0.6860018968582153\n",
      "Epoch 388/2000 - Loss: 2.728105068206787 - Train accuracy: 0.546308696269989 - Test accuracy: 0.6849472522735596\n",
      "Epoch 389/2000 - Loss: 2.842381000518799 - Train accuracy: 0.5479386448860168 - Test accuracy: 0.6847555041313171\n",
      "Epoch 390/2000 - Loss: 2.676650285720825 - Train accuracy: 0.551773726940155 - Test accuracy: 0.6857143044471741\n",
      "Epoch 391/2000 - Loss: 2.7590723037719727 - Train accuracy: 0.547267496585846 - Test accuracy: 0.6861936450004578\n",
      "Epoch 392/2000 - Loss: 2.8191330432891846 - Train accuracy: 0.5484180450439453 - Test accuracy: 0.686385452747345\n",
      "Epoch 393/2000 - Loss: 2.733865976333618 - Train accuracy: 0.5485138893127441 - Test accuracy: 0.6860018968582153\n",
      "Epoch 394/2000 - Loss: 2.9213616847991943 - Train accuracy: 0.5508149862289429 - Test accuracy: 0.6860018968582153\n",
      "Epoch 395/2000 - Loss: 3.1006240844726562 - Train accuracy: 0.5504314303398132 - Test accuracy: 0.6840843558311462\n",
      "Epoch 396/2000 - Loss: 2.8978772163391113 - Train accuracy: 0.5490891933441162 - Test accuracy: 0.6837008595466614\n",
      "Epoch 397/2000 - Loss: 2.70218825340271 - Train accuracy: 0.5539789199829102 - Test accuracy: 0.6838926076889038\n",
      "Epoch 398/2000 - Loss: 2.6332058906555176 - Train accuracy: 0.5500479340553284 - Test accuracy: 0.6860018968582153\n",
      "Epoch 399/2000 - Loss: 2.9035565853118896 - Train accuracy: 0.549185037612915 - Test accuracy: 0.6870565414428711\n",
      "Epoch 400/2000 - Loss: 2.767894744873047 - Train accuracy: 0.5479386448860168 - Test accuracy: 0.6876318454742432\n",
      "Epoch 401/2000 - Loss: 2.9798097610473633 - Train accuracy: 0.5548418164253235 - Test accuracy: 0.6883029937744141\n",
      "Epoch 402/2000 - Loss: 3.06390118598938 - Train accuracy: 0.5497602820396423 - Test accuracy: 0.6882070899009705\n",
      "Epoch 403/2000 - Loss: 2.9550039768218994 - Train accuracy: 0.5438159108161926 - Test accuracy: 0.6886864900588989\n",
      "Epoch 404/2000 - Loss: 2.86807918548584 - Train accuracy: 0.5516778230667114 - Test accuracy: 0.6886864900588989\n",
      "Epoch 405/2000 - Loss: 2.9247822761535645 - Train accuracy: 0.5459251999855042 - Test accuracy: 0.6888782382011414\n",
      "Epoch 406/2000 - Loss: 2.813401937484741 - Train accuracy: 0.559539794921875 - Test accuracy: 0.6881112456321716\n",
      "Epoch 407/2000 - Loss: 2.8766088485717773 - Train accuracy: 0.5535954236984253 - Test accuracy: 0.6881112456321716\n",
      "Epoch 408/2000 - Loss: 2.7083852291107178 - Train accuracy: 0.5525407195091248 - Test accuracy: 0.6890699863433838\n",
      "Epoch 409/2000 - Loss: 2.817645311355591 - Train accuracy: 0.5526366233825684 - Test accuracy: 0.6899328827857971\n",
      "Epoch 410/2000 - Loss: 2.9583699703216553 - Train accuracy: 0.5476509928703308 - Test accuracy: 0.6915627717971802\n",
      "Epoch 411/2000 - Loss: 2.7328152656555176 - Train accuracy: 0.5492809414863586 - Test accuracy: 0.6914669275283813\n",
      "Epoch 412/2000 - Loss: 3.0770583152770996 - Train accuracy: 0.5511984825134277 - Test accuracy: 0.6924256682395935\n",
      "Epoch 413/2000 - Loss: 3.0083441734313965 - Train accuracy: 0.551773726940155 - Test accuracy: 0.6917545795440674\n",
      "Epoch 414/2000 - Loss: 2.842257261276245 - Train accuracy: 0.5541706681251526 - Test accuracy: 0.6924256682395935\n",
      "Epoch 415/2000 - Loss: 2.8852314949035645 - Train accuracy: 0.5439118146896362 - Test accuracy: 0.690604031085968\n",
      "Epoch 416/2000 - Loss: 2.771954298019409 - Train accuracy: 0.5466922521591187 - Test accuracy: 0.6878235936164856\n",
      "Epoch 417/2000 - Loss: 2.9535465240478516 - Train accuracy: 0.554074764251709 - Test accuracy: 0.6887823343276978\n",
      "Epoch 418/2000 - Loss: 2.725092887878418 - Train accuracy: 0.5571428537368774 - Test accuracy: 0.6870565414428711\n",
      "Epoch 419/2000 - Loss: 2.993560791015625 - Train accuracy: 0.5490891933441162 - Test accuracy: 0.6882070899009705\n",
      "Epoch 420/2000 - Loss: 2.968815326690674 - Train accuracy: 0.5590603947639465 - Test accuracy: 0.690316379070282\n",
      "Epoch 421/2000 - Loss: 2.7212026119232178 - Train accuracy: 0.5500479340553284 - Test accuracy: 0.6913710236549377\n",
      "Epoch 422/2000 - Loss: 2.853933811187744 - Train accuracy: 0.554074764251709 - Test accuracy: 0.6925215721130371\n",
      "Epoch 423/2000 - Loss: 2.9883980751037598 - Train accuracy: 0.552732527256012 - Test accuracy: 0.693480372428894\n",
      "Epoch 424/2000 - Loss: 2.8284668922424316 - Train accuracy: 0.544966459274292 - Test accuracy: 0.6923298239707947\n",
      "Epoch 425/2000 - Loss: 2.9415931701660156 - Train accuracy: 0.551773726940155 - Test accuracy: 0.6899328827857971\n",
      "Epoch 426/2000 - Loss: 2.8528025150299072 - Train accuracy: 0.5414189696311951 - Test accuracy: 0.6896452307701111\n",
      "Epoch 427/2000 - Loss: 2.6767280101776123 - Train accuracy: 0.5518696308135986 - Test accuracy: 0.6906998753547668\n",
      "Epoch 428/2000 - Loss: 2.9553749561309814 - Train accuracy: 0.5545541644096375 - Test accuracy: 0.6923298239707947\n",
      "Epoch 429/2000 - Loss: 2.726544141769409 - Train accuracy: 0.5493767857551575 - Test accuracy: 0.6955896615982056\n",
      "Epoch 430/2000 - Loss: 2.8434174060821533 - Train accuracy: 0.5525407195091248 - Test accuracy: 0.695493757724762\n",
      "Epoch 431/2000 - Loss: 2.8966357707977295 - Train accuracy: 0.551773726940155 - Test accuracy: 0.6953020095825195\n",
      "Epoch 432/2000 - Loss: 2.8266286849975586 - Train accuracy: 0.5571428537368774 - Test accuracy: 0.6944391131401062\n",
      "Epoch 433/2000 - Loss: 2.7308504581451416 - Train accuracy: 0.5539789199829102 - Test accuracy: 0.6941514611244202\n",
      "Epoch 434/2000 - Loss: 2.891275644302368 - Train accuracy: 0.551486074924469 - Test accuracy: 0.6922339200973511\n",
      "Epoch 435/2000 - Loss: 2.7907464504241943 - Train accuracy: 0.5467880964279175 - Test accuracy: 0.6919463276863098\n",
      "Epoch 436/2000 - Loss: 2.9711122512817383 - Train accuracy: 0.5511984825134277 - Test accuracy: 0.6918504238128662\n",
      "Epoch 437/2000 - Loss: 2.858858108520508 - Train accuracy: 0.5521572232246399 - Test accuracy: 0.692905068397522\n",
      "Epoch 438/2000 - Loss: 2.929896116256714 - Train accuracy: 0.5551294088363647 - Test accuracy: 0.6940556168556213\n",
      "Epoch 439/2000 - Loss: 2.941065549850464 - Train accuracy: 0.5547459125518799 - Test accuracy: 0.6945350170135498\n",
      "Epoch 440/2000 - Loss: 3.0873706340789795 - Train accuracy: 0.5474592447280884 - Test accuracy: 0.6947267651557922\n",
      "Epoch 441/2000 - Loss: 2.8283445835113525 - Train accuracy: 0.5535954236984253 - Test accuracy: 0.6945350170135498\n",
      "Epoch 442/2000 - Loss: 2.950608253479004 - Train accuracy: 0.5493767857551575 - Test accuracy: 0.6946308612823486\n",
      "Epoch 443/2000 - Loss: 2.7811174392700195 - Train accuracy: 0.5505273342132568 - Test accuracy: 0.6953979134559631\n",
      "Epoch 444/2000 - Loss: 2.7603092193603516 - Train accuracy: 0.5591562986373901 - Test accuracy: 0.6951102614402771\n",
      "Epoch 445/2000 - Loss: 2.680776596069336 - Train accuracy: 0.559252142906189 - Test accuracy: 0.6950143575668335\n",
      "Epoch 446/2000 - Loss: 2.838043689727783 - Train accuracy: 0.554362416267395 - Test accuracy: 0.6976989507675171\n",
      "Epoch 447/2000 - Loss: 2.7761788368225098 - Train accuracy: 0.5613614320755005 - Test accuracy: 0.6963566541671753\n",
      "Epoch 448/2000 - Loss: 2.707688808441162 - Train accuracy: 0.5556088089942932 - Test accuracy: 0.6975072026252747\n",
      "Epoch 449/2000 - Loss: 2.6608798503875732 - Train accuracy: 0.5665388107299805 - Test accuracy: 0.6979866027832031\n",
      "Epoch 450/2000 - Loss: 2.7845282554626465 - Train accuracy: 0.5532118678092957 - Test accuracy: 0.6988494992256165\n",
      "Epoch 451/2000 - Loss: 2.8378868103027344 - Train accuracy: 0.5542665123939514 - Test accuracy: 0.6991370916366577\n",
      "Epoch 452/2000 - Loss: 2.980534315109253 - Train accuracy: 0.5558005571365356 - Test accuracy: 0.6996164917945862\n",
      "Epoch 453/2000 - Loss: 2.865126371383667 - Train accuracy: 0.5536912679672241 - Test accuracy: 0.6999041438102722\n",
      "Epoch 454/2000 - Loss: 2.6683876514434814 - Train accuracy: 0.5535954236984253 - Test accuracy: 0.6989453434944153\n",
      "Epoch 455/2000 - Loss: 2.7668333053588867 - Train accuracy: 0.5584851503372192 - Test accuracy: 0.6987535953521729\n",
      "Epoch 456/2000 - Loss: 2.823535680770874 - Train accuracy: 0.5558964610099792 - Test accuracy: 0.6992329955101013\n",
      "Epoch 457/2000 - Loss: 2.905235767364502 - Train accuracy: 0.5539789199829102 - Test accuracy: 0.6976989507675171\n",
      "Epoch 458/2000 - Loss: 2.9136693477630615 - Train accuracy: 0.5533077716827393 - Test accuracy: 0.7000958919525146\n",
      "Epoch 459/2000 - Loss: 2.6618149280548096 - Train accuracy: 0.5506231784820557 - Test accuracy: 0.7016299366950989\n",
      "Epoch 460/2000 - Loss: 2.849323272705078 - Train accuracy: 0.5615532398223877 - Test accuracy: 0.7024928331375122\n",
      "Epoch 461/2000 - Loss: 3.0015268325805664 - Train accuracy: 0.5544583201408386 - Test accuracy: 0.7041227221488953\n",
      "Epoch 462/2000 - Loss: 2.826261281967163 - Train accuracy: 0.5554170608520508 - Test accuracy: 0.7037392258644104\n",
      "Epoch 463/2000 - Loss: 2.8296337127685547 - Train accuracy: 0.5564717054367065 - Test accuracy: 0.7031639218330383\n",
      "Epoch 464/2000 - Loss: 2.773085832595825 - Train accuracy: 0.559539794921875 - Test accuracy: 0.7034515738487244\n",
      "Epoch 465/2000 - Loss: 2.728731870651245 - Train accuracy: 0.5552253127098083 - Test accuracy: 0.702301025390625\n",
      "Epoch 466/2000 - Loss: 2.650407314300537 - Train accuracy: 0.5570470094680786 - Test accuracy: 0.7019175291061401\n",
      "Epoch 467/2000 - Loss: 2.763969659805298 - Train accuracy: 0.559252142906189 - Test accuracy: 0.7022051811218262\n",
      "Epoch 468/2000 - Loss: 2.8797221183776855 - Train accuracy: 0.5539789199829102 - Test accuracy: 0.6990412473678589\n",
      "Epoch 469/2000 - Loss: 2.9583146572113037 - Train accuracy: 0.5565676093101501 - Test accuracy: 0.6984659433364868\n",
      "Epoch 470/2000 - Loss: 2.799278497695923 - Train accuracy: 0.5537871718406677 - Test accuracy: 0.697411298751831\n",
      "Epoch 471/2000 - Loss: 2.700042486190796 - Train accuracy: 0.5585809946060181 - Test accuracy: 0.6979866027832031\n",
      "Epoch 472/2000 - Loss: 2.7840678691864014 - Train accuracy: 0.5504314303398132 - Test accuracy: 0.7008628845214844\n",
      "Epoch 473/2000 - Loss: 3.107081890106201 - Train accuracy: 0.5551294088363647 - Test accuracy: 0.7015340328216553\n",
      "Epoch 474/2000 - Loss: 2.7231950759887695 - Train accuracy: 0.5604026913642883 - Test accuracy: 0.7020134329795837\n",
      "Epoch 475/2000 - Loss: 2.7033393383026123 - Train accuracy: 0.5607861876487732 - Test accuracy: 0.7014381885528564\n",
      "Epoch 476/2000 - Loss: 2.9792449474334717 - Train accuracy: 0.5628954768180847 - Test accuracy: 0.700958788394928\n",
      "Epoch 477/2000 - Loss: 2.7133524417877197 - Train accuracy: 0.5604026913642883 - Test accuracy: 0.7041227221488953\n",
      "Epoch 478/2000 - Loss: 2.773970365524292 - Train accuracy: 0.5525407195091248 - Test accuracy: 0.703547477722168\n",
      "Epoch 479/2000 - Loss: 2.8527374267578125 - Train accuracy: 0.5555129647254944 - Test accuracy: 0.7021092772483826\n",
      "Epoch 480/2000 - Loss: 2.8041646480560303 - Train accuracy: 0.5537871718406677 - Test accuracy: 0.7034515738487244\n",
      "Epoch 481/2000 - Loss: 2.793574571609497 - Train accuracy: 0.5536912679672241 - Test accuracy: 0.7037392258644104\n",
      "Epoch 482/2000 - Loss: 2.6108486652374268 - Train accuracy: 0.5599232912063599 - Test accuracy: 0.7024928331375122\n",
      "Epoch 483/2000 - Loss: 2.8289265632629395 - Train accuracy: 0.5652924180030823 - Test accuracy: 0.703547477722168\n",
      "Epoch 484/2000 - Loss: 2.7982380390167236 - Train accuracy: 0.5556088089942932 - Test accuracy: 0.7027804255485535\n",
      "Epoch 485/2000 - Loss: 2.7479474544525146 - Train accuracy: 0.5610738396644592 - Test accuracy: 0.7031639218330383\n",
      "Epoch 486/2000 - Loss: 2.7069077491760254 - Train accuracy: 0.556663453578949 - Test accuracy: 0.7037392258644104\n",
      "Epoch 487/2000 - Loss: 2.8562874794006348 - Train accuracy: 0.5576222538948059 - Test accuracy: 0.7028763294219971\n",
      "Epoch 488/2000 - Loss: 2.9378268718719482 - Train accuracy: 0.5534036159515381 - Test accuracy: 0.7029721736907959\n",
      "Epoch 489/2000 - Loss: 2.7605326175689697 - Train accuracy: 0.5522531270980835 - Test accuracy: 0.7013422846794128\n",
      "Epoch 490/2000 - Loss: 2.6925857067108154 - Train accuracy: 0.5518696308135986 - Test accuracy: 0.7012463808059692\n",
      "Epoch 491/2000 - Loss: 2.7428383827209473 - Train accuracy: 0.5519654750823975 - Test accuracy: 0.7026845812797546\n",
      "Epoch 492/2000 - Loss: 2.8786303997039795 - Train accuracy: 0.5604985356330872 - Test accuracy: 0.7018216848373413\n",
      "Epoch 493/2000 - Loss: 2.667426109313965 - Train accuracy: 0.5607861876487732 - Test accuracy: 0.7016299366950989\n",
      "Epoch 494/2000 - Loss: 2.878225088119507 - Train accuracy: 0.5518696308135986 - Test accuracy: 0.7005752921104431\n",
      "Epoch 495/2000 - Loss: 2.9403889179229736 - Train accuracy: 0.5629913806915283 - Test accuracy: 0.7012463808059692\n",
      "Epoch 496/2000 - Loss: 2.6666512489318848 - Train accuracy: 0.5581016540527344 - Test accuracy: 0.7027804255485535\n",
      "Epoch 497/2000 - Loss: 2.8976528644561768 - Train accuracy: 0.5561841130256653 - Test accuracy: 0.7036433219909668\n",
      "Epoch 498/2000 - Loss: 2.643524169921875 - Train accuracy: 0.5611696839332581 - Test accuracy: 0.7053691148757935\n",
      "Epoch 499/2000 - Loss: 2.834604501724243 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.7060402631759644\n",
      "Epoch 500/2000 - Loss: 2.6466736793518066 - Train accuracy: 0.552732527256012 - Test accuracy: 0.7057526111602783\n",
      "Epoch 501/2000 - Loss: 2.7162179946899414 - Train accuracy: 0.564429521560669 - Test accuracy: 0.7057526111602783\n",
      "Epoch 502/2000 - Loss: 2.959059715270996 - Train accuracy: 0.5582934021949768 - Test accuracy: 0.7052732706069946\n",
      "Epoch 503/2000 - Loss: 2.7809321880340576 - Train accuracy: 0.5563758611679077 - Test accuracy: 0.7056567668914795\n",
      "Epoch 504/2000 - Loss: 2.5838160514831543 - Train accuracy: 0.5620325803756714 - Test accuracy: 0.7059444189071655\n",
      "Epoch 505/2000 - Loss: 2.6964685916900635 - Train accuracy: 0.5557047128677368 - Test accuracy: 0.7064237594604492\n",
      "Epoch 506/2000 - Loss: 2.668560028076172 - Train accuracy: 0.5604026913642883 - Test accuracy: 0.7063279151916504\n",
      "Epoch 507/2000 - Loss: 2.564626455307007 - Train accuracy: 0.5567593574523926 - Test accuracy: 0.7063279151916504\n",
      "Epoch 508/2000 - Loss: 2.7356534004211426 - Train accuracy: 0.559539794921875 - Test accuracy: 0.7064237594604492\n",
      "Epoch 509/2000 - Loss: 2.6518146991729736 - Train accuracy: 0.5535954236984253 - Test accuracy: 0.7056567668914795\n",
      "Epoch 510/2000 - Loss: 2.5994176864624023 - Train accuracy: 0.559539794921875 - Test accuracy: 0.7046021223068237\n",
      "Epoch 511/2000 - Loss: 2.4836442470550537 - Train accuracy: 0.5600191950798035 - Test accuracy: 0.7046979665756226\n",
      "Epoch 512/2000 - Loss: 2.9882774353027344 - Train accuracy: 0.5541706681251526 - Test accuracy: 0.7062320113182068\n",
      "Epoch 513/2000 - Loss: 2.6341590881347656 - Train accuracy: 0.554650068283081 - Test accuracy: 0.7069031596183777\n",
      "Epoch 514/2000 - Loss: 2.5495824813842773 - Train accuracy: 0.5545541644096375 - Test accuracy: 0.7055608630180359\n",
      "Epoch 515/2000 - Loss: 2.861417531967163 - Train accuracy: 0.5584851503372192 - Test accuracy: 0.7065196633338928\n",
      "Epoch 516/2000 - Loss: 2.728783130645752 - Train accuracy: 0.5611696839332581 - Test accuracy: 0.7071908116340637\n",
      "Epoch 517/2000 - Loss: 2.6797029972076416 - Train accuracy: 0.5656759142875671 - Test accuracy: 0.7086289525032043\n",
      "Epoch 518/2000 - Loss: 2.958470344543457 - Train accuracy: 0.5627037286758423 - Test accuracy: 0.7085330486297607\n",
      "Epoch 519/2000 - Loss: 2.843205690383911 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.7079578042030334\n",
      "Epoch 520/2000 - Loss: 2.822354555130005 - Train accuracy: 0.5555129647254944 - Test accuracy: 0.7076702117919922\n",
      "Epoch 521/2000 - Loss: 2.7578511238098145 - Train accuracy: 0.5642377734184265 - Test accuracy: 0.7062320113182068\n",
      "Epoch 522/2000 - Loss: 2.746321678161621 - Train accuracy: 0.5594438910484314 - Test accuracy: 0.7073825597763062\n",
      "Epoch 523/2000 - Loss: 2.815096139907837 - Train accuracy: 0.5571428537368774 - Test accuracy: 0.7059444189071655\n",
      "Epoch 524/2000 - Loss: 2.8223154544830322 - Train accuracy: 0.562416136264801 - Test accuracy: 0.7059444189071655\n",
      "Epoch 525/2000 - Loss: 2.7946059703826904 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.7057526111602783\n",
      "Epoch 526/2000 - Loss: 2.6675312519073486 - Train accuracy: 0.554650068283081 - Test accuracy: 0.7055608630180359\n",
      "Epoch 527/2000 - Loss: 2.805434226989746 - Train accuracy: 0.5563758611679077 - Test accuracy: 0.7046021223068237\n",
      "Epoch 528/2000 - Loss: 2.6425740718841553 - Train accuracy: 0.5573346018791199 - Test accuracy: 0.7049856185913086\n",
      "Epoch 529/2000 - Loss: 2.567652940750122 - Train accuracy: 0.5589645504951477 - Test accuracy: 0.7070949077606201\n",
      "Epoch 530/2000 - Loss: 2.6346371173858643 - Train accuracy: 0.5667305588722229 - Test accuracy: 0.7070949077606201\n",
      "Epoch 531/2000 - Loss: 2.5827136039733887 - Train accuracy: 0.556951105594635 - Test accuracy: 0.7069990634918213\n",
      "Epoch 532/2000 - Loss: 2.6790459156036377 - Train accuracy: 0.5605944395065308 - Test accuracy: 0.7059444189071655\n",
      "Epoch 533/2000 - Loss: 2.662109613418579 - Train accuracy: 0.5616490840911865 - Test accuracy: 0.7060402631759644\n",
      "Epoch 534/2000 - Loss: 2.660250425338745 - Train accuracy: 0.562128484249115 - Test accuracy: 0.7058485150337219\n",
      "Epoch 535/2000 - Loss: 2.81596040725708 - Train accuracy: 0.5537871718406677 - Test accuracy: 0.7070949077606201\n",
      "Epoch 536/2000 - Loss: 2.5640997886657715 - Train accuracy: 0.5607861876487732 - Test accuracy: 0.7084372043609619\n",
      "Epoch 537/2000 - Loss: 2.7148005962371826 - Train accuracy: 0.5599232912063599 - Test accuracy: 0.708724856376648\n",
      "Epoch 538/2000 - Loss: 2.7953405380249023 - Train accuracy: 0.5534036159515381 - Test accuracy: 0.7093001008033752\n",
      "Epoch 539/2000 - Loss: 2.6900947093963623 - Train accuracy: 0.5556088089942932 - Test accuracy: 0.7093959450721741\n",
      "Epoch 540/2000 - Loss: 2.7135586738586426 - Train accuracy: 0.5619367361068726 - Test accuracy: 0.7084372043609619\n",
      "Epoch 541/2000 - Loss: 2.7091143131256104 - Train accuracy: 0.5627037286758423 - Test accuracy: 0.7090124487876892\n",
      "Epoch 542/2000 - Loss: 2.584702968597412 - Train accuracy: 0.5599232912063599 - Test accuracy: 0.7075743079185486\n",
      "Epoch 543/2000 - Loss: 2.7681353092193604 - Train accuracy: 0.5666347146034241 - Test accuracy: 0.7069031596183777\n",
      "Epoch 544/2000 - Loss: 2.7332019805908203 - Train accuracy: 0.5521572232246399 - Test accuracy: 0.7071908116340637\n",
      "Epoch 545/2000 - Loss: 2.7724087238311768 - Train accuracy: 0.5469798445701599 - Test accuracy: 0.7089166045188904\n",
      "Epoch 546/2000 - Loss: 2.6799795627593994 - Train accuracy: 0.554650068283081 - Test accuracy: 0.7090124487876892\n",
      "Epoch 547/2000 - Loss: 2.768220901489258 - Train accuracy: 0.5587727427482605 - Test accuracy: 0.708724856376648\n",
      "Epoch 548/2000 - Loss: 2.6345741748809814 - Train accuracy: 0.562416136264801 - Test accuracy: 0.7076702117919922\n",
      "Epoch 549/2000 - Loss: 2.7378828525543213 - Train accuracy: 0.5640460252761841 - Test accuracy: 0.7059444189071655\n",
      "Epoch 550/2000 - Loss: 2.6672863960266113 - Train accuracy: 0.5571428537368774 - Test accuracy: 0.7066155076026917\n",
      "Epoch 551/2000 - Loss: 2.5412325859069824 - Train accuracy: 0.5605944395065308 - Test accuracy: 0.7062320113182068\n",
      "Epoch 552/2000 - Loss: 2.740051746368408 - Train accuracy: 0.5633748769760132 - Test accuracy: 0.7069031596183777\n",
      "Epoch 553/2000 - Loss: 2.6964104175567627 - Train accuracy: 0.557238757610321 - Test accuracy: 0.7084372043609619\n",
      "Epoch 554/2000 - Loss: 2.9292385578155518 - Train accuracy: 0.5593480467796326 - Test accuracy: 0.710642397403717\n",
      "Epoch 555/2000 - Loss: 2.542017698287964 - Train accuracy: 0.556951105594635 - Test accuracy: 0.7108341455459595\n",
      "Epoch 556/2000 - Loss: 2.7753474712371826 - Train accuracy: 0.5593480467796326 - Test accuracy: 0.7108341455459595\n",
      "Epoch 557/2000 - Loss: 3.039674758911133 - Train accuracy: 0.5613614320755005 - Test accuracy: 0.7123681902885437\n",
      "Epoch 558/2000 - Loss: 2.57871413230896 - Train accuracy: 0.5600191950798035 - Test accuracy: 0.7119846343994141\n",
      "Epoch 559/2000 - Loss: 2.962026834487915 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.7127516865730286\n",
      "Epoch 560/2000 - Loss: 2.5956878662109375 - Train accuracy: 0.5567593574523926 - Test accuracy: 0.7122722864151001\n",
      "Epoch 561/2000 - Loss: 2.7007505893707275 - Train accuracy: 0.5581016540527344 - Test accuracy: 0.7127516865730286\n",
      "Epoch 562/2000 - Loss: 2.6994640827178955 - Train accuracy: 0.554650068283081 - Test accuracy: 0.7133269309997559\n",
      "Epoch 563/2000 - Loss: 2.8259406089782715 - Train accuracy: 0.5617449879646301 - Test accuracy: 0.7117928862571716\n",
      "Epoch 564/2000 - Loss: 2.6561005115509033 - Train accuracy: 0.5614573359489441 - Test accuracy: 0.710354745388031\n",
      "Epoch 565/2000 - Loss: 2.6656908988952637 - Train accuracy: 0.5613614320755005 - Test accuracy: 0.7112176418304443\n",
      "Epoch 566/2000 - Loss: 2.646681785583496 - Train accuracy: 0.5667305588722229 - Test accuracy: 0.7121764421463013\n",
      "Epoch 567/2000 - Loss: 2.8414676189422607 - Train accuracy: 0.5590603947639465 - Test accuracy: 0.7138063311576843\n",
      "Epoch 568/2000 - Loss: 2.804669141769409 - Train accuracy: 0.559827446937561 - Test accuracy: 0.712943434715271\n",
      "Epoch 569/2000 - Loss: 2.9456331729888916 - Train accuracy: 0.561840832233429 - Test accuracy: 0.7137104272842407\n",
      "Epoch 570/2000 - Loss: 2.9516243934631348 - Train accuracy: 0.5576222538948059 - Test accuracy: 0.7128475308418274\n",
      "Epoch 571/2000 - Loss: 2.5743002891540527 - Train accuracy: 0.5628954768180847 - Test accuracy: 0.7141898274421692\n",
      "Epoch 572/2000 - Loss: 2.542172908782959 - Train accuracy: 0.5638542771339417 - Test accuracy: 0.7151486277580261\n",
      "Epoch 573/2000 - Loss: 2.7365572452545166 - Train accuracy: 0.5608820915222168 - Test accuracy: 0.714573323726654\n",
      "Epoch 574/2000 - Loss: 2.5750808715820312 - Train accuracy: 0.5687440037727356 - Test accuracy: 0.7147650718688965\n",
      "Epoch 575/2000 - Loss: 2.616140842437744 - Train accuracy: 0.5634707808494568 - Test accuracy: 0.7143815755844116\n",
      "Epoch 576/2000 - Loss: 2.6601696014404297 - Train accuracy: 0.5593480467796326 - Test accuracy: 0.7160115242004395\n",
      "Epoch 577/2000 - Loss: 2.6514875888824463 - Train accuracy: 0.5658676624298096 - Test accuracy: 0.715244472026825\n",
      "Epoch 578/2000 - Loss: 2.6687171459198 - Train accuracy: 0.5602109432220459 - Test accuracy: 0.7127516865730286\n",
      "Epoch 579/2000 - Loss: 2.7342562675476074 - Train accuracy: 0.5633748769760132 - Test accuracy: 0.7125599384307861\n",
      "Epoch 580/2000 - Loss: 2.6643285751342773 - Train accuracy: 0.561840832233429 - Test accuracy: 0.7121764421463013\n",
      "Epoch 581/2000 - Loss: 2.7834744453430176 - Train accuracy: 0.5705657005310059 - Test accuracy: 0.7104506492614746\n",
      "Epoch 582/2000 - Loss: 2.741072654724121 - Train accuracy: 0.5590603947639465 - Test accuracy: 0.710642397403717\n",
      "Epoch 583/2000 - Loss: 2.8056302070617676 - Train accuracy: 0.5585809946060181 - Test accuracy: 0.7124640345573425\n",
      "Epoch 584/2000 - Loss: 3.0048227310180664 - Train accuracy: 0.5559923052787781 - Test accuracy: 0.7125599384307861\n",
      "Epoch 585/2000 - Loss: 2.6324195861816406 - Train accuracy: 0.5638542771339417 - Test accuracy: 0.7137104272842407\n",
      "Epoch 586/2000 - Loss: 2.7542662620544434 - Train accuracy: 0.5658676624298096 - Test accuracy: 0.7127516865730286\n",
      "Epoch 587/2000 - Loss: 2.8726136684417725 - Train accuracy: 0.5597315430641174 - Test accuracy: 0.7112176418304443\n",
      "Epoch 588/2000 - Loss: 2.7569468021392822 - Train accuracy: 0.5610738396644592 - Test accuracy: 0.7109299898147583\n",
      "Epoch 589/2000 - Loss: 2.7892074584960938 - Train accuracy: 0.555321216583252 - Test accuracy: 0.7116970419883728\n",
      "Epoch 590/2000 - Loss: 2.681337356567383 - Train accuracy: 0.5664429664611816 - Test accuracy: 0.7114093899726868\n",
      "Epoch 591/2000 - Loss: 2.593581199645996 - Train accuracy: 0.5614573359489441 - Test accuracy: 0.7125599384307861\n",
      "Epoch 592/2000 - Loss: 2.7758753299713135 - Train accuracy: 0.5604985356330872 - Test accuracy: 0.712655782699585\n",
      "Epoch 593/2000 - Loss: 2.715566396713257 - Train accuracy: 0.5616490840911865 - Test accuracy: 0.7117928862571716\n",
      "Epoch 594/2000 - Loss: 2.5967202186584473 - Train accuracy: 0.5627996325492859 - Test accuracy: 0.7097795009613037\n",
      "Epoch 595/2000 - Loss: 2.5431571006774902 - Train accuracy: 0.5620325803756714 - Test accuracy: 0.7104506492614746\n",
      "Epoch 596/2000 - Loss: 2.6981096267700195 - Train accuracy: 0.5599232912063599 - Test accuracy: 0.710354745388031\n",
      "Epoch 597/2000 - Loss: 2.6141531467437744 - Train accuracy: 0.5539789199829102 - Test accuracy: 0.710067093372345\n",
      "Epoch 598/2000 - Loss: 2.7992217540740967 - Train accuracy: 0.5576222538948059 - Test accuracy: 0.7091083526611328\n",
      "Epoch 599/2000 - Loss: 2.8166728019714355 - Train accuracy: 0.5641418695449829 - Test accuracy: 0.7098753452301025\n",
      "Epoch 600/2000 - Loss: 2.6062052249908447 - Train accuracy: 0.5542665123939514 - Test accuracy: 0.7107382416725159\n",
      "Epoch 601/2000 - Loss: 3.0456597805023193 - Train accuracy: 0.5556088089942932 - Test accuracy: 0.710354745388031\n",
      "Epoch 602/2000 - Loss: 2.7664246559143066 - Train accuracy: 0.5612655878067017 - Test accuracy: 0.7112176418304443\n",
      "Epoch 603/2000 - Loss: 2.5652525424957275 - Train accuracy: 0.5671141147613525 - Test accuracy: 0.7113135457038879\n",
      "Epoch 604/2000 - Loss: 2.684776782989502 - Train accuracy: 0.559252142906189 - Test accuracy: 0.7138063311576843\n",
      "Epoch 605/2000 - Loss: 2.6362524032592773 - Train accuracy: 0.5561841130256653 - Test accuracy: 0.7148609757423401\n",
      "Epoch 606/2000 - Loss: 2.7435193061828613 - Train accuracy: 0.5612655878067017 - Test accuracy: 0.7164908647537231\n",
      "Epoch 607/2000 - Loss: 2.8534934520721436 - Train accuracy: 0.5507190823554993 - Test accuracy: 0.7162032723426819\n",
      "Epoch 608/2000 - Loss: 2.7327051162719727 - Train accuracy: 0.5617449879646301 - Test accuracy: 0.7150527238845825\n",
      "Epoch 609/2000 - Loss: 2.7256970405578613 - Train accuracy: 0.5552253127098083 - Test accuracy: 0.7161073684692383\n",
      "Epoch 610/2000 - Loss: 2.4934651851654053 - Train accuracy: 0.5631831288337708 - Test accuracy: 0.7175455689430237\n",
      "Epoch 611/2000 - Loss: 2.7029027938842773 - Train accuracy: 0.5634707808494568 - Test accuracy: 0.7169702649116516\n",
      "Epoch 612/2000 - Loss: 2.8140246868133545 - Train accuracy: 0.5581016540527344 - Test accuracy: 0.7176414132118225\n",
      "Epoch 613/2000 - Loss: 2.686041831970215 - Train accuracy: 0.5605944395065308 - Test accuracy: 0.7200383543968201\n",
      "Epoch 614/2000 - Loss: 2.7190890312194824 - Train accuracy: 0.5631831288337708 - Test accuracy: 0.7191754579544067\n",
      "Epoch 615/2000 - Loss: 2.783304452896118 - Train accuracy: 0.5622243285179138 - Test accuracy: 0.7180249094963074\n",
      "Epoch 616/2000 - Loss: 2.6330156326293945 - Train accuracy: 0.5601150393486023 - Test accuracy: 0.7180249094963074\n",
      "Epoch 617/2000 - Loss: 2.6518170833587646 - Train accuracy: 0.562128484249115 - Test accuracy: 0.7160115242004395\n",
      "Epoch 618/2000 - Loss: 2.679800510406494 - Train accuracy: 0.5593480467796326 - Test accuracy: 0.7154362201690674\n",
      "Epoch 619/2000 - Loss: 2.684236526489258 - Train accuracy: 0.5594438910484314 - Test accuracy: 0.7156279683113098\n",
      "Epoch 620/2000 - Loss: 2.7580976486206055 - Train accuracy: 0.5588686466217041 - Test accuracy: 0.7153403759002686\n",
      "Epoch 621/2000 - Loss: 2.584261655807495 - Train accuracy: 0.556951105594635 - Test accuracy: 0.7141898274421692\n",
      "Epoch 622/2000 - Loss: 2.5605781078338623 - Train accuracy: 0.5596356391906738 - Test accuracy: 0.7137104272842407\n",
      "Epoch 623/2000 - Loss: 2.6513471603393555 - Train accuracy: 0.5590603947639465 - Test accuracy: 0.7142857313156128\n",
      "Epoch 624/2000 - Loss: 2.7601420879364014 - Train accuracy: 0.561840832233429 - Test accuracy: 0.7150527238845825\n",
      "Epoch 625/2000 - Loss: 2.520461320877075 - Train accuracy: 0.5645254254341125 - Test accuracy: 0.7153403759002686\n",
      "Epoch 626/2000 - Loss: 2.5810437202453613 - Train accuracy: 0.5604985356330872 - Test accuracy: 0.715244472026825\n",
      "Epoch 627/2000 - Loss: 2.441337823867798 - Train accuracy: 0.5619367361068726 - Test accuracy: 0.7160115242004395\n",
      "Epoch 628/2000 - Loss: 2.595257043838501 - Train accuracy: 0.5638542771339417 - Test accuracy: 0.7183125615119934\n",
      "Epoch 629/2000 - Loss: 2.5142581462860107 - Train accuracy: 0.5679770112037659 - Test accuracy: 0.7185043096542358\n",
      "Epoch 630/2000 - Loss: 2.4424479007720947 - Train accuracy: 0.5616490840911865 - Test accuracy: 0.718120813369751\n",
      "Epoch 631/2000 - Loss: 2.660010576248169 - Train accuracy: 0.5628954768180847 - Test accuracy: 0.7168744206428528\n",
      "Epoch 632/2000 - Loss: 2.652317762374878 - Train accuracy: 0.5602109432220459 - Test accuracy: 0.717162013053894\n",
      "Epoch 633/2000 - Loss: 2.894758701324463 - Train accuracy: 0.556951105594635 - Test accuracy: 0.7150527238845825\n",
      "Epoch 634/2000 - Loss: 2.4021661281585693 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.715532124042511\n",
      "Epoch 635/2000 - Loss: 2.528911828994751 - Train accuracy: 0.5625119805335999 - Test accuracy: 0.7176414132118225\n",
      "Epoch 636/2000 - Loss: 2.6500444412231445 - Train accuracy: 0.5626078844070435 - Test accuracy: 0.7209970951080322\n",
      "Epoch 637/2000 - Loss: 2.5131306648254395 - Train accuracy: 0.567305862903595 - Test accuracy: 0.7209970951080322\n",
      "Epoch 638/2000 - Loss: 2.621300220489502 - Train accuracy: 0.5656759142875671 - Test accuracy: 0.7204218506813049\n",
      "Epoch 639/2000 - Loss: 2.527710437774658 - Train accuracy: 0.5628954768180847 - Test accuracy: 0.719750702381134\n",
      "Epoch 640/2000 - Loss: 2.6313884258270264 - Train accuracy: 0.5623202323913574 - Test accuracy: 0.7179290652275085\n",
      "Epoch 641/2000 - Loss: 2.625370979309082 - Train accuracy: 0.5693192481994629 - Test accuracy: 0.7164908647537231\n",
      "Epoch 642/2000 - Loss: 2.473501682281494 - Train accuracy: 0.5641418695449829 - Test accuracy: 0.7159156203269958\n",
      "Epoch 643/2000 - Loss: 2.9676194190979004 - Train accuracy: 0.5576222538948059 - Test accuracy: 0.715819776058197\n",
      "Epoch 644/2000 - Loss: 2.6869802474975586 - Train accuracy: 0.5653883218765259 - Test accuracy: 0.7169702649116516\n",
      "Epoch 645/2000 - Loss: 2.483599901199341 - Train accuracy: 0.5628954768180847 - Test accuracy: 0.7180249094963074\n",
      "Epoch 646/2000 - Loss: 2.558452606201172 - Train accuracy: 0.5669223666191101 - Test accuracy: 0.7186002135276794\n",
      "Epoch 647/2000 - Loss: 2.7004270553588867 - Train accuracy: 0.5590603947639465 - Test accuracy: 0.7199424505233765\n",
      "Epoch 648/2000 - Loss: 2.7001545429229736 - Train accuracy: 0.5604026913642883 - Test accuracy: 0.7173537611961365\n",
      "Epoch 649/2000 - Loss: 2.614126443862915 - Train accuracy: 0.5627996325492859 - Test accuracy: 0.7173537611961365\n",
      "Epoch 650/2000 - Loss: 2.509107828140259 - Train accuracy: 0.5582934021949768 - Test accuracy: 0.7154362201690674\n",
      "Epoch 651/2000 - Loss: 2.638105630874634 - Train accuracy: 0.5604985356330872 - Test accuracy: 0.7160115242004395\n",
      "Epoch 652/2000 - Loss: 2.7503082752227783 - Train accuracy: 0.5653883218765259 - Test accuracy: 0.7161073684692383\n",
      "Epoch 653/2000 - Loss: 2.8187270164489746 - Train accuracy: 0.562128484249115 - Test accuracy: 0.7162991166114807\n",
      "Epoch 654/2000 - Loss: 2.9261634349823 - Train accuracy: 0.562416136264801 - Test accuracy: 0.7180249094963074\n",
      "Epoch 655/2000 - Loss: 2.9039804935455322 - Train accuracy: 0.5627996325492859 - Test accuracy: 0.7188878059387207\n",
      "Epoch 656/2000 - Loss: 2.465625524520874 - Train accuracy: 0.5638542771339417 - Test accuracy: 0.7192713618278503\n",
      "Epoch 657/2000 - Loss: 2.665156841278076 - Train accuracy: 0.5627996325492859 - Test accuracy: 0.7209970951080322\n",
      "Epoch 658/2000 - Loss: 2.6699211597442627 - Train accuracy: 0.5670182108879089 - Test accuracy: 0.7206135988235474\n",
      "Epoch 659/2000 - Loss: 2.7413170337677 - Train accuracy: 0.5561841130256653 - Test accuracy: 0.720709502696991\n",
      "Epoch 660/2000 - Loss: 2.567549467086792 - Train accuracy: 0.5656759142875671 - Test accuracy: 0.7209012508392334\n",
      "Epoch 661/2000 - Loss: 2.5836551189422607 - Train accuracy: 0.5583892464637756 - Test accuracy: 0.7200383543968201\n",
      "Epoch 662/2000 - Loss: 2.5399057865142822 - Train accuracy: 0.5593480467796326 - Test accuracy: 0.7168744206428528\n",
      "Epoch 663/2000 - Loss: 2.744495153427124 - Train accuracy: 0.5683605074882507 - Test accuracy: 0.7172579169273376\n",
      "Epoch 664/2000 - Loss: 2.6592726707458496 - Train accuracy: 0.5645254254341125 - Test accuracy: 0.7167785167694092\n",
      "Epoch 665/2000 - Loss: 2.580113649368286 - Train accuracy: 0.5658676624298096 - Test accuracy: 0.7169702649116516\n",
      "Epoch 666/2000 - Loss: 2.662494421005249 - Train accuracy: 0.5612655878067017 - Test accuracy: 0.7165867686271667\n",
      "Epoch 667/2000 - Loss: 2.5887887477874756 - Train accuracy: 0.5541706681251526 - Test accuracy: 0.7175455689430237\n",
      "Epoch 668/2000 - Loss: 2.418804883956909 - Train accuracy: 0.5648130178451538 - Test accuracy: 0.7192713618278503\n",
      "Epoch 669/2000 - Loss: 2.6168572902679443 - Train accuracy: 0.559252142906189 - Test accuracy: 0.7189837098121643\n",
      "Epoch 670/2000 - Loss: 2.567215919494629 - Train accuracy: 0.564429521560669 - Test accuracy: 0.7195589542388916\n",
      "Epoch 671/2000 - Loss: 2.6737351417541504 - Train accuracy: 0.5636625289916992 - Test accuracy: 0.7205177545547485\n",
      "Epoch 672/2000 - Loss: 2.5828499794006348 - Train accuracy: 0.5690316557884216 - Test accuracy: 0.7200383543968201\n",
      "Epoch 673/2000 - Loss: 2.8604605197906494 - Train accuracy: 0.5608820915222168 - Test accuracy: 0.7199424505233765\n",
      "Epoch 674/2000 - Loss: 2.579501152038574 - Train accuracy: 0.5620325803756714 - Test accuracy: 0.7210929989814758\n",
      "Epoch 675/2000 - Loss: 2.819267988204956 - Train accuracy: 0.5589645504951477 - Test accuracy: 0.7219558954238892\n",
      "Epoch 676/2000 - Loss: 2.5333025455474854 - Train accuracy: 0.5668264627456665 - Test accuracy: 0.7220517992973328\n",
      "Epoch 677/2000 - Loss: 2.6524229049682617 - Train accuracy: 0.5596356391906738 - Test accuracy: 0.722339391708374\n",
      "Epoch 678/2000 - Loss: 2.775686264038086 - Train accuracy: 0.5613614320755005 - Test accuracy: 0.7240651845932007\n",
      "Epoch 679/2000 - Loss: 2.90584659576416 - Train accuracy: 0.5645254254341125 - Test accuracy: 0.7231064438819885\n",
      "Epoch 680/2000 - Loss: 2.6058738231658936 - Train accuracy: 0.5620325803756714 - Test accuracy: 0.7235857844352722\n",
      "Epoch 681/2000 - Loss: 2.634019136428833 - Train accuracy: 0.5626078844070435 - Test accuracy: 0.725886881351471\n",
      "Epoch 682/2000 - Loss: 2.640763998031616 - Train accuracy: 0.5639501214027405 - Test accuracy: 0.7248322367668152\n",
      "Epoch 683/2000 - Loss: 2.559577465057373 - Train accuracy: 0.5662512183189392 - Test accuracy: 0.7235857844352722\n",
      "Epoch 684/2000 - Loss: 2.5244739055633545 - Train accuracy: 0.5635666251182556 - Test accuracy: 0.7246404886245728\n",
      "Epoch 685/2000 - Loss: 2.6011459827423096 - Train accuracy: 0.5672099590301514 - Test accuracy: 0.7241610884666443\n",
      "Epoch 686/2000 - Loss: 2.5609495639801025 - Train accuracy: 0.5675934553146362 - Test accuracy: 0.7232022881507874\n",
      "Epoch 687/2000 - Loss: 2.6189818382263184 - Train accuracy: 0.5682646036148071 - Test accuracy: 0.7212847471237183\n",
      "Epoch 688/2000 - Loss: 2.5932087898254395 - Train accuracy: 0.5677852630615234 - Test accuracy: 0.7208053469657898\n",
      "Epoch 689/2000 - Loss: 2.7654221057891846 - Train accuracy: 0.5655800700187683 - Test accuracy: 0.7232022881507874\n",
      "Epoch 690/2000 - Loss: 2.7105767726898193 - Train accuracy: 0.5693192481994629 - Test accuracy: 0.7237775921821594\n",
      "Epoch 691/2000 - Loss: 2.845533609390259 - Train accuracy: 0.5653883218765259 - Test accuracy: 0.7245445847511292\n",
      "Epoch 692/2000 - Loss: 2.6741604804992676 - Train accuracy: 0.5674017071723938 - Test accuracy: 0.7254074811935425\n",
      "Epoch 693/2000 - Loss: 2.7618918418884277 - Train accuracy: 0.5631831288337708 - Test accuracy: 0.7269415259361267\n",
      "Epoch 694/2000 - Loss: 2.745422601699829 - Train accuracy: 0.5665388107299805 - Test accuracy: 0.7267497777938843\n",
      "Epoch 695/2000 - Loss: 2.8302690982818604 - Train accuracy: 0.562416136264801 - Test accuracy: 0.7259827256202698\n",
      "Epoch 696/2000 - Loss: 2.514152765274048 - Train accuracy: 0.5690316557884216 - Test accuracy: 0.7244486808776855\n",
      "Epoch 697/2000 - Loss: 2.558481216430664 - Train accuracy: 0.5697986483573914 - Test accuracy: 0.7234899401664734\n",
      "Epoch 698/2000 - Loss: 2.600320816040039 - Train accuracy: 0.5667305588722229 - Test accuracy: 0.7231064438819885\n",
      "Epoch 699/2000 - Loss: 2.6489412784576416 - Train accuracy: 0.5676893591880798 - Test accuracy: 0.7228187918663025\n",
      "Epoch 700/2000 - Loss: 2.9122023582458496 - Train accuracy: 0.5662512183189392 - Test accuracy: 0.7228187918663025\n",
      "Epoch 701/2000 - Loss: 2.6442718505859375 - Train accuracy: 0.559827446937561 - Test accuracy: 0.7236816883087158\n",
      "Epoch 702/2000 - Loss: 2.509347438812256 - Train accuracy: 0.5720996856689453 - Test accuracy: 0.7244486808776855\n",
      "Epoch 703/2000 - Loss: 2.4887683391571045 - Train accuracy: 0.5678811073303223 - Test accuracy: 0.7251198291778564\n",
      "Epoch 704/2000 - Loss: 2.6945135593414307 - Train accuracy: 0.5710450410842896 - Test accuracy: 0.7259827256202698\n",
      "Epoch 705/2000 - Loss: 2.5603160858154297 - Train accuracy: 0.5649089217185974 - Test accuracy: 0.7257909774780273\n",
      "Epoch 706/2000 - Loss: 2.585466146469116 - Train accuracy: 0.564429521560669 - Test accuracy: 0.7257909774780273\n",
      "Epoch 707/2000 - Loss: 2.757072687149048 - Train accuracy: 0.5706615447998047 - Test accuracy: 0.7266538739204407\n",
      "Epoch 708/2000 - Loss: 2.5749521255493164 - Train accuracy: 0.568935751914978 - Test accuracy: 0.7270373702049255\n",
      "Epoch 709/2000 - Loss: 2.6539053916931152 - Train accuracy: 0.5661553144454956 - Test accuracy: 0.7274209260940552\n",
      "Epoch 710/2000 - Loss: 2.5067203044891357 - Train accuracy: 0.5701821446418762 - Test accuracy: 0.7269415259361267\n",
      "Epoch 711/2000 - Loss: 2.5299458503723145 - Train accuracy: 0.5636625289916992 - Test accuracy: 0.727229118347168\n",
      "Epoch 712/2000 - Loss: 2.7135238647460938 - Train accuracy: 0.5701821446418762 - Test accuracy: 0.7255992293357849\n",
      "Epoch 713/2000 - Loss: 2.7781105041503906 - Train accuracy: 0.5697028040885925 - Test accuracy: 0.7235857844352722\n",
      "Epoch 714/2000 - Loss: 2.473316192626953 - Train accuracy: 0.5645254254341125 - Test accuracy: 0.7222435474395752\n",
      "Epoch 715/2000 - Loss: 2.662912607192993 - Train accuracy: 0.5601150393486023 - Test accuracy: 0.7246404886245728\n",
      "Epoch 716/2000 - Loss: 2.476557970046997 - Train accuracy: 0.5688399076461792 - Test accuracy: 0.7234899401664734\n",
      "Epoch 717/2000 - Loss: 2.7435576915740967 - Train accuracy: 0.5671141147613525 - Test accuracy: 0.7252157330513\n",
      "Epoch 718/2000 - Loss: 2.5279133319854736 - Train accuracy: 0.5676893591880798 - Test accuracy: 0.7276126742362976\n",
      "Epoch 719/2000 - Loss: 2.72452974319458 - Train accuracy: 0.5665388107299805 - Test accuracy: 0.7269415259361267\n",
      "Epoch 720/2000 - Loss: 2.5157253742218018 - Train accuracy: 0.564717173576355 - Test accuracy: 0.7267497777938843\n",
      "Epoch 721/2000 - Loss: 2.47594952583313 - Train accuracy: 0.5616490840911865 - Test accuracy: 0.7252157330513\n",
      "Epoch 722/2000 - Loss: 2.7234044075012207 - Train accuracy: 0.5650047659873962 - Test accuracy: 0.7251198291778564\n",
      "Epoch 723/2000 - Loss: 2.588805675506592 - Train accuracy: 0.5646212697029114 - Test accuracy: 0.7236816883087158\n",
      "Epoch 724/2000 - Loss: 2.7080814838409424 - Train accuracy: 0.5683605074882507 - Test accuracy: 0.7226270437240601\n",
      "Epoch 725/2000 - Loss: 2.7288966178894043 - Train accuracy: 0.5612655878067017 - Test accuracy: 0.7239693403244019\n",
      "Epoch 726/2000 - Loss: 2.6231529712677 - Train accuracy: 0.5643336772918701 - Test accuracy: 0.727229118347168\n",
      "Epoch 727/2000 - Loss: 2.6199347972869873 - Train accuracy: 0.5686481595039368 - Test accuracy: 0.7280920147895813\n",
      "Epoch 728/2000 - Loss: 2.520275115966797 - Train accuracy: 0.5710450410842896 - Test accuracy: 0.7277085185050964\n",
      "Epoch 729/2000 - Loss: 2.4667580127716064 - Train accuracy: 0.5608820915222168 - Test accuracy: 0.7280920147895813\n",
      "Epoch 730/2000 - Loss: 2.5929324626922607 - Train accuracy: 0.5677852630615234 - Test accuracy: 0.7297219634056091\n",
      "Epoch 731/2000 - Loss: 2.909792423248291 - Train accuracy: 0.5669223666191101 - Test accuracy: 0.7276126742362976\n",
      "Epoch 732/2000 - Loss: 2.5848262310028076 - Train accuracy: 0.5682646036148071 - Test accuracy: 0.7261744737625122\n",
      "Epoch 733/2000 - Loss: 2.5433907508850098 - Train accuracy: 0.5660594701766968 - Test accuracy: 0.7256951332092285\n",
      "Epoch 734/2000 - Loss: 2.6055314540863037 - Train accuracy: 0.5634707808494568 - Test accuracy: 0.724928081035614\n",
      "Epoch 735/2000 - Loss: 2.783172130584717 - Train accuracy: 0.5661553144454956 - Test accuracy: 0.727516770362854\n",
      "Epoch 736/2000 - Loss: 2.7177836894989014 - Train accuracy: 0.5682646036148071 - Test accuracy: 0.7264621257781982\n",
      "Epoch 737/2000 - Loss: 2.744150400161743 - Train accuracy: 0.562416136264801 - Test accuracy: 0.727229118347168\n",
      "Epoch 738/2000 - Loss: 2.909507989883423 - Train accuracy: 0.5612655878067017 - Test accuracy: 0.7306807041168213\n",
      "Epoch 739/2000 - Loss: 2.6996009349823 - Train accuracy: 0.5660594701766968 - Test accuracy: 0.730105459690094\n",
      "Epoch 740/2000 - Loss: 2.707113742828369 - Train accuracy: 0.5597315430641174 - Test accuracy: 0.7310642600059509\n",
      "Epoch 741/2000 - Loss: 2.8020498752593994 - Train accuracy: 0.5627037286758423 - Test accuracy: 0.7306807041168213\n",
      "Epoch 742/2000 - Loss: 2.526907444000244 - Train accuracy: 0.5697986483573914 - Test accuracy: 0.7304889559745789\n",
      "Epoch 743/2000 - Loss: 2.5654568672180176 - Train accuracy: 0.569894552230835 - Test accuracy: 0.7295302152633667\n",
      "Epoch 744/2000 - Loss: 2.613898992538452 - Train accuracy: 0.5680728554725647 - Test accuracy: 0.7300096154212952\n",
      "Epoch 745/2000 - Loss: 2.7220230102539062 - Train accuracy: 0.5697028040885925 - Test accuracy: 0.7325982451438904\n",
      "Epoch 746/2000 - Loss: 2.5318188667297363 - Train accuracy: 0.5651965737342834 - Test accuracy: 0.7315436005592346\n",
      "Epoch 747/2000 - Loss: 2.3976292610168457 - Train accuracy: 0.5680728554725647 - Test accuracy: 0.7312560081481934\n",
      "Epoch 748/2000 - Loss: 2.60614013671875 - Train accuracy: 0.5714285969734192 - Test accuracy: 0.7306807041168213\n",
      "Epoch 749/2000 - Loss: 2.4515116214752197 - Train accuracy: 0.5694151520729065 - Test accuracy: 0.7307766079902649\n",
      "Epoch 750/2000 - Loss: 2.8804800510406494 - Train accuracy: 0.5652924180030823 - Test accuracy: 0.7309683561325073\n",
      "Epoch 751/2000 - Loss: 2.8522181510925293 - Train accuracy: 0.5626078844070435 - Test accuracy: 0.7293384671211243\n",
      "Epoch 752/2000 - Loss: 2.4719114303588867 - Train accuracy: 0.5596356391906738 - Test accuracy: 0.7302013635635376\n",
      "Epoch 753/2000 - Loss: 2.584225654602051 - Train accuracy: 0.571524441242218 - Test accuracy: 0.7304889559745789\n",
      "Epoch 754/2000 - Loss: 2.7014644145965576 - Train accuracy: 0.5676893591880798 - Test accuracy: 0.7302013635635376\n",
      "Epoch 755/2000 - Loss: 2.4150569438934326 - Train accuracy: 0.5703738927841187 - Test accuracy: 0.7297219634056091\n",
      "Epoch 756/2000 - Loss: 2.6754794120788574 - Train accuracy: 0.5640460252761841 - Test accuracy: 0.729817807674408\n",
      "Epoch 757/2000 - Loss: 2.5530219078063965 - Train accuracy: 0.5727708339691162 - Test accuracy: 0.7312560081481934\n",
      "Epoch 758/2000 - Loss: 2.5430896282196045 - Train accuracy: 0.568935751914978 - Test accuracy: 0.7292425632476807\n",
      "Epoch 759/2000 - Loss: 2.5046842098236084 - Train accuracy: 0.5751677751541138 - Test accuracy: 0.729817807674408\n",
      "Epoch 760/2000 - Loss: 2.660034656524658 - Train accuracy: 0.5752636790275574 - Test accuracy: 0.7314477562904358\n",
      "Epoch 761/2000 - Loss: 2.616044044494629 - Train accuracy: 0.5627996325492859 - Test accuracy: 0.7325982451438904\n",
      "Epoch 762/2000 - Loss: 2.7558724880218506 - Train accuracy: 0.5755512714385986 - Test accuracy: 0.7356663346290588\n",
      "Epoch 763/2000 - Loss: 2.4040181636810303 - Train accuracy: 0.5675934553146362 - Test accuracy: 0.7321189045906067\n",
      "Epoch 764/2000 - Loss: 2.455899953842163 - Train accuracy: 0.5667305588722229 - Test accuracy: 0.7325982451438904\n",
      "Epoch 765/2000 - Loss: 2.7231290340423584 - Train accuracy: 0.5697028040885925 - Test accuracy: 0.7336529493331909\n",
      "Epoch 766/2000 - Loss: 2.5435543060302734 - Train accuracy: 0.5713326930999756 - Test accuracy: 0.7339405417442322\n",
      "Epoch 767/2000 - Loss: 2.666975259780884 - Train accuracy: 0.5720038414001465 - Test accuracy: 0.7354745864868164\n",
      "Epoch 768/2000 - Loss: 2.6909849643707275 - Train accuracy: 0.5684563517570496 - Test accuracy: 0.7370086312294006\n",
      "Epoch 769/2000 - Loss: 2.4931302070617676 - Train accuracy: 0.5697986483573914 - Test accuracy: 0.7360498309135437\n",
      "Epoch 770/2000 - Loss: 2.5642919540405273 - Train accuracy: 0.5722914934158325 - Test accuracy: 0.736912727355957\n",
      "Epoch 771/2000 - Loss: 2.6297216415405273 - Train accuracy: 0.567305862903595 - Test accuracy: 0.7388302683830261\n",
      "Epoch 772/2000 - Loss: 2.440211057662964 - Train accuracy: 0.5678811073303223 - Test accuracy: 0.7392138242721558\n",
      "Epoch 773/2000 - Loss: 2.451683521270752 - Train accuracy: 0.5739213824272156 - Test accuracy: 0.736912727355957\n",
      "Epoch 774/2000 - Loss: 2.553605794906616 - Train accuracy: 0.5677852630615234 - Test accuracy: 0.7349951863288879\n",
      "Epoch 775/2000 - Loss: 2.5517826080322266 - Train accuracy: 0.5743048787117004 - Test accuracy: 0.7345158457756042\n",
      "Epoch 776/2000 - Loss: 2.425118923187256 - Train accuracy: 0.574400782585144 - Test accuracy: 0.7338446974754333\n",
      "Epoch 777/2000 - Loss: 2.5634472370147705 - Train accuracy: 0.5636625289916992 - Test accuracy: 0.7344199419021606\n",
      "Epoch 778/2000 - Loss: 2.52762508392334 - Train accuracy: 0.5664429664611816 - Test accuracy: 0.7368168830871582\n",
      "Epoch 779/2000 - Loss: 2.629150152206421 - Train accuracy: 0.5654841661453247 - Test accuracy: 0.737871527671814\n",
      "Epoch 780/2000 - Loss: 2.5085086822509766 - Train accuracy: 0.5697028040885925 - Test accuracy: 0.7371045351028442\n",
      "Epoch 781/2000 - Loss: 2.711343765258789 - Train accuracy: 0.5721955895423889 - Test accuracy: 0.736912727355957\n",
      "Epoch 782/2000 - Loss: 2.4348769187927246 - Train accuracy: 0.5625119805335999 - Test accuracy: 0.7381591796875\n",
      "Epoch 783/2000 - Loss: 2.4953315258026123 - Train accuracy: 0.5731543898582458 - Test accuracy: 0.7387344241142273\n",
      "Epoch 784/2000 - Loss: 2.5684568881988525 - Train accuracy: 0.5757430195808411 - Test accuracy: 0.7376797795295715\n",
      "Epoch 785/2000 - Loss: 2.728485584259033 - Train accuracy: 0.5731543898582458 - Test accuracy: 0.7356663346290588\n",
      "Epoch 786/2000 - Loss: 2.63950252532959 - Train accuracy: 0.5739213824272156 - Test accuracy: 0.7366251349449158\n",
      "Epoch 787/2000 - Loss: 2.5420589447021484 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7388302683830261\n",
      "Epoch 788/2000 - Loss: 2.6231350898742676 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7386385202407837\n",
      "Epoch 789/2000 - Loss: 2.5550320148468018 - Train accuracy: 0.5651006698608398 - Test accuracy: 0.737871527671814\n",
      "Epoch 790/2000 - Loss: 2.6906609535217285 - Train accuracy: 0.5686481595039368 - Test accuracy: 0.7372962832450867\n",
      "Epoch 791/2000 - Loss: 2.5106289386749268 - Train accuracy: 0.5720996856689453 - Test accuracy: 0.7361457347869873\n",
      "Epoch 792/2000 - Loss: 2.6303701400756836 - Train accuracy: 0.5720996856689453 - Test accuracy: 0.7368168830871582\n",
      "Epoch 793/2000 - Loss: 2.4686450958251953 - Train accuracy: 0.5720996856689453 - Test accuracy: 0.7372962832450867\n",
      "Epoch 794/2000 - Loss: 2.449521541595459 - Train accuracy: 0.5693192481994629 - Test accuracy: 0.736912727355957\n",
      "Epoch 795/2000 - Loss: 2.5240981578826904 - Train accuracy: 0.5678811073303223 - Test accuracy: 0.7370086312294006\n",
      "Epoch 796/2000 - Loss: 2.5791211128234863 - Train accuracy: 0.5653883218765259 - Test accuracy: 0.7376797795295715\n",
      "Epoch 797/2000 - Loss: 2.542581558227539 - Train accuracy: 0.5706615447998047 - Test accuracy: 0.7390220761299133\n",
      "Epoch 798/2000 - Loss: 2.3938043117523193 - Train accuracy: 0.5713326930999756 - Test accuracy: 0.7402684688568115\n",
      "Epoch 799/2000 - Loss: 2.6714396476745605 - Train accuracy: 0.574113130569458 - Test accuracy: 0.7415148615837097\n",
      "Epoch 800/2000 - Loss: 2.46988582611084 - Train accuracy: 0.5694151520729065 - Test accuracy: 0.7408437132835388\n",
      "Epoch 801/2000 - Loss: 2.4831840991973877 - Train accuracy: 0.5695109963417053 - Test accuracy: 0.7416107654571533\n",
      "Epoch 802/2000 - Loss: 2.6127243041992188 - Train accuracy: 0.5677852630615234 - Test accuracy: 0.7413231134414673\n",
      "Epoch 803/2000 - Loss: 2.6661183834075928 - Train accuracy: 0.5702780485153198 - Test accuracy: 0.7405560612678528\n",
      "Epoch 804/2000 - Loss: 2.652662992477417 - Train accuracy: 0.5679770112037659 - Test accuracy: 0.7398849725723267\n",
      "Epoch 805/2000 - Loss: 2.5761470794677734 - Train accuracy: 0.5723873376846313 - Test accuracy: 0.7429530024528503\n",
      "Epoch 806/2000 - Loss: 2.459994316101074 - Train accuracy: 0.5727708339691162 - Test accuracy: 0.7452540993690491\n",
      "Epoch 807/2000 - Loss: 2.540379047393799 - Train accuracy: 0.5687440037727356 - Test accuracy: 0.7442952990531921\n",
      "Epoch 808/2000 - Loss: 2.6459062099456787 - Train accuracy: 0.5742090344429016 - Test accuracy: 0.7435283064842224\n",
      "Epoch 809/2000 - Loss: 2.7402822971343994 - Train accuracy: 0.5668264627456665 - Test accuracy: 0.7414189577102661\n",
      "Epoch 810/2000 - Loss: 2.615281343460083 - Train accuracy: 0.5666347146034241 - Test accuracy: 0.7384467720985413\n",
      "Epoch 811/2000 - Loss: 2.4700539112091064 - Train accuracy: 0.5723873376846313 - Test accuracy: 0.736912727355957\n",
      "Epoch 812/2000 - Loss: 2.5063204765319824 - Train accuracy: 0.5745925307273865 - Test accuracy: 0.7375838756561279\n",
      "Epoch 813/2000 - Loss: 2.5438387393951416 - Train accuracy: 0.576701819896698 - Test accuracy: 0.7390220761299133\n",
      "Epoch 814/2000 - Loss: 2.5334270000457764 - Train accuracy: 0.5691275000572205 - Test accuracy: 0.7408437132835388\n",
      "Epoch 815/2000 - Loss: 2.6981682777404785 - Train accuracy: 0.5727708339691162 - Test accuracy: 0.7418025135993958\n",
      "Epoch 816/2000 - Loss: 2.546879768371582 - Train accuracy: 0.5777564644813538 - Test accuracy: 0.74333655834198\n",
      "Epoch 817/2000 - Loss: 2.5398175716400146 - Train accuracy: 0.5651006698608398 - Test accuracy: 0.74333655834198\n",
      "Epoch 818/2000 - Loss: 2.533667802810669 - Train accuracy: 0.569894552230835 - Test accuracy: 0.7431447505950928\n",
      "Epoch 819/2000 - Loss: 2.40022611618042 - Train accuracy: 0.5746883749961853 - Test accuracy: 0.7455416917800903\n",
      "Epoch 820/2000 - Loss: 2.4715824127197266 - Train accuracy: 0.571524441242218 - Test accuracy: 0.7469798922538757\n",
      "Epoch 821/2000 - Loss: 2.3844070434570312 - Train accuracy: 0.571812093257904 - Test accuracy: 0.7488974332809448\n",
      "Epoch 822/2000 - Loss: 2.5804624557495117 - Train accuracy: 0.5733461380004883 - Test accuracy: 0.7499520778656006\n",
      "Epoch 823/2000 - Loss: 2.8006577491760254 - Train accuracy: 0.5727708339691162 - Test accuracy: 0.7489932775497437\n",
      "Epoch 824/2000 - Loss: 2.7574899196624756 - Train accuracy: 0.5670182108879089 - Test accuracy: 0.7452540993690491\n",
      "Epoch 825/2000 - Loss: 2.415632486343384 - Train accuracy: 0.571524441242218 - Test accuracy: 0.7469798922538757\n",
      "Epoch 826/2000 - Loss: 2.389465808868408 - Train accuracy: 0.5739213824272156 - Test accuracy: 0.7478427886962891\n",
      "Epoch 827/2000 - Loss: 2.538074493408203 - Train accuracy: 0.5708532929420471 - Test accuracy: 0.7454458475112915\n",
      "Epoch 828/2000 - Loss: 2.5761725902557373 - Train accuracy: 0.5745925307273865 - Test accuracy: 0.7453499436378479\n",
      "Epoch 829/2000 - Loss: 2.5057480335235596 - Train accuracy: 0.5701821446418762 - Test accuracy: 0.7460210919380188\n",
      "Epoch 830/2000 - Loss: 2.64689302444458 - Train accuracy: 0.5700863003730774 - Test accuracy: 0.7452540993690491\n",
      "Epoch 831/2000 - Loss: 2.691591262817383 - Train accuracy: 0.5701821446418762 - Test accuracy: 0.744966447353363\n",
      "Epoch 832/2000 - Loss: 2.548086404800415 - Train accuracy: 0.5696069002151489 - Test accuracy: 0.7443912029266357\n",
      "Epoch 833/2000 - Loss: 2.4790353775024414 - Train accuracy: 0.5674976110458374 - Test accuracy: 0.7452540993690491\n",
      "Epoch 834/2000 - Loss: 2.3294472694396973 - Train accuracy: 0.5766059160232544 - Test accuracy: 0.7439118027687073\n",
      "Epoch 835/2000 - Loss: 2.439908981323242 - Train accuracy: 0.5744966268539429 - Test accuracy: 0.7427612543106079\n",
      "Epoch 836/2000 - Loss: 2.490844249725342 - Train accuracy: 0.5705657005310059 - Test accuracy: 0.7427612543106079\n",
      "Epoch 837/2000 - Loss: 2.5390307903289795 - Train accuracy: 0.5729625821113586 - Test accuracy: 0.7422818541526794\n",
      "Epoch 838/2000 - Loss: 2.6649582386016846 - Train accuracy: 0.5734419822692871 - Test accuracy: 0.742377758026123\n",
      "Epoch 839/2000 - Loss: 2.4996445178985596 - Train accuracy: 0.5667305588722229 - Test accuracy: 0.7421860098838806\n",
      "Epoch 840/2000 - Loss: 2.276151418685913 - Train accuracy: 0.5775647163391113 - Test accuracy: 0.7427612543106079\n",
      "Epoch 841/2000 - Loss: 2.7232131958007812 - Train accuracy: 0.5755512714385986 - Test accuracy: 0.7432406544685364\n",
      "Epoch 842/2000 - Loss: 2.663919448852539 - Train accuracy: 0.5723873376846313 - Test accuracy: 0.7435283064842224\n",
      "Epoch 843/2000 - Loss: 2.5957720279693604 - Train accuracy: 0.5736337304115295 - Test accuracy: 0.7440076470375061\n",
      "Epoch 844/2000 - Loss: 2.6108198165893555 - Train accuracy: 0.576989471912384 - Test accuracy: 0.74333655834198\n",
      "Epoch 845/2000 - Loss: 2.4954493045806885 - Train accuracy: 0.5749760270118713 - Test accuracy: 0.7439118027687073\n",
      "Epoch 846/2000 - Loss: 2.5272905826568604 - Train accuracy: 0.5766059160232544 - Test accuracy: 0.7467880845069885\n",
      "Epoch 847/2000 - Loss: 2.4619882106781006 - Train accuracy: 0.5749760270118713 - Test accuracy: 0.7480345368385315\n",
      "Epoch 848/2000 - Loss: 2.399378538131714 - Train accuracy: 0.576701819896698 - Test accuracy: 0.7497603297233582\n",
      "Epoch 849/2000 - Loss: 2.5462687015533447 - Train accuracy: 0.5705657005310059 - Test accuracy: 0.7507190704345703\n",
      "Epoch 850/2000 - Loss: 2.4343061447143555 - Train accuracy: 0.5802493095397949 - Test accuracy: 0.7464045882225037\n",
      "Epoch 851/2000 - Loss: 2.5358593463897705 - Train accuracy: 0.572483241558075 - Test accuracy: 0.7473633885383606\n",
      "Epoch 852/2000 - Loss: 2.4177961349487305 - Train accuracy: 0.5755512714385986 - Test accuracy: 0.7479386329650879\n",
      "Epoch 853/2000 - Loss: 2.5659823417663574 - Train accuracy: 0.5755512714385986 - Test accuracy: 0.7479386329650879\n",
      "Epoch 854/2000 - Loss: 2.5461909770965576 - Train accuracy: 0.5699903964996338 - Test accuracy: 0.7477468848228455\n",
      "Epoch 855/2000 - Loss: 2.4406049251556396 - Train accuracy: 0.5806328058242798 - Test accuracy: 0.7470757365226746\n",
      "Epoch 856/2000 - Loss: 2.4295597076416016 - Train accuracy: 0.5767977237701416 - Test accuracy: 0.7462128400802612\n",
      "Epoch 857/2000 - Loss: 2.637469530105591 - Train accuracy: 0.576701819896698 - Test accuracy: 0.7441993951797485\n",
      "Epoch 858/2000 - Loss: 2.3489415645599365 - Train accuracy: 0.576701819896698 - Test accuracy: 0.7450622916221619\n",
      "Epoch 859/2000 - Loss: 2.4794394969940186 - Train accuracy: 0.5757430195808411 - Test accuracy: 0.7465004920959473\n",
      "Epoch 860/2000 - Loss: 2.5665459632873535 - Train accuracy: 0.5760306715965271 - Test accuracy: 0.7469798922538757\n",
      "Epoch 861/2000 - Loss: 2.3806917667388916 - Train accuracy: 0.5739213824272156 - Test accuracy: 0.7415148615837097\n",
      "Epoch 862/2000 - Loss: 2.5768046379089355 - Train accuracy: 0.5688399076461792 - Test accuracy: 0.7440076470375061\n",
      "Epoch 863/2000 - Loss: 2.6765923500061035 - Train accuracy: 0.5773729681968689 - Test accuracy: 0.7471716403961182\n",
      "Epoch 864/2000 - Loss: 2.790627956390381 - Train accuracy: 0.5705657005310059 - Test accuracy: 0.7488974332809448\n",
      "Epoch 865/2000 - Loss: 2.6302874088287354 - Train accuracy: 0.5687440037727356 - Test accuracy: 0.7493767738342285\n",
      "Epoch 866/2000 - Loss: 2.49764347076416 - Train accuracy: 0.5782358646392822 - Test accuracy: 0.750143826007843\n",
      "Epoch 867/2000 - Loss: 2.65822696685791 - Train accuracy: 0.5773729681968689 - Test accuracy: 0.7542665600776672\n",
      "Epoch 868/2000 - Loss: 2.531980514526367 - Train accuracy: 0.576414167881012 - Test accuracy: 0.7505273222923279\n",
      "Epoch 869/2000 - Loss: 2.5728063583374023 - Train accuracy: 0.573825478553772 - Test accuracy: 0.7488974332809448\n",
      "Epoch 870/2000 - Loss: 2.48990797996521 - Train accuracy: 0.576989471912384 - Test accuracy: 0.7513902187347412\n",
      "Epoch 871/2000 - Loss: 2.5421981811523438 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7513902187347412\n",
      "Epoch 872/2000 - Loss: 2.417766571044922 - Train accuracy: 0.5771812200546265 - Test accuracy: 0.7504314184188843\n",
      "Epoch 873/2000 - Loss: 2.4513988494873047 - Train accuracy: 0.572483241558075 - Test accuracy: 0.7490891814231873\n",
      "Epoch 874/2000 - Loss: 2.2819550037384033 - Train accuracy: 0.5780441164970398 - Test accuracy: 0.7480345368385315\n",
      "Epoch 875/2000 - Loss: 2.583692789077759 - Train accuracy: 0.5805369019508362 - Test accuracy: 0.7469798922538757\n",
      "Epoch 876/2000 - Loss: 2.59798264503479 - Train accuracy: 0.5745925307273865 - Test accuracy: 0.7487056851387024\n",
      "Epoch 877/2000 - Loss: 2.426164150238037 - Train accuracy: 0.582166850566864 - Test accuracy: 0.7489932775497437\n",
      "Epoch 878/2000 - Loss: 2.5945301055908203 - Train accuracy: 0.5714285969734192 - Test accuracy: 0.7504314184188843\n",
      "Epoch 879/2000 - Loss: 2.460340738296509 - Train accuracy: 0.571236789226532 - Test accuracy: 0.7520613670349121\n",
      "Epoch 880/2000 - Loss: 2.62099027633667 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7528283596038818\n",
      "Epoch 881/2000 - Loss: 2.3632078170776367 - Train accuracy: 0.5735378861427307 - Test accuracy: 0.7534036636352539\n",
      "Epoch 882/2000 - Loss: 2.377882480621338 - Train accuracy: 0.5773729681968689 - Test accuracy: 0.7511025667190552\n",
      "Epoch 883/2000 - Loss: 2.6880087852478027 - Train accuracy: 0.5711409449577332 - Test accuracy: 0.7520613670349121\n",
      "Epoch 884/2000 - Loss: 2.4115049839019775 - Train accuracy: 0.5767977237701416 - Test accuracy: 0.7533077597618103\n",
      "Epoch 885/2000 - Loss: 2.6445224285125732 - Train accuracy: 0.5747842788696289 - Test accuracy: 0.7512943148612976\n",
      "Epoch 886/2000 - Loss: 2.3903462886810303 - Train accuracy: 0.5705657005310059 - Test accuracy: 0.7505273222923279\n",
      "Epoch 887/2000 - Loss: 2.4077682495117188 - Train accuracy: 0.5658676624298096 - Test accuracy: 0.7503355741500854\n",
      "Epoch 888/2000 - Loss: 2.4451661109924316 - Train accuracy: 0.576989471912384 - Test accuracy: 0.7511984705924988\n",
      "Epoch 889/2000 - Loss: 2.2689292430877686 - Train accuracy: 0.5757430195808411 - Test accuracy: 0.7505273222923279\n",
      "Epoch 890/2000 - Loss: 2.480679512023926 - Train accuracy: 0.5744966268539429 - Test accuracy: 0.7522531151771545\n",
      "Epoch 891/2000 - Loss: 2.5409305095672607 - Train accuracy: 0.5778523683547974 - Test accuracy: 0.7537871599197388\n",
      "Epoch 892/2000 - Loss: 2.620544195175171 - Train accuracy: 0.5825503468513489 - Test accuracy: 0.7518696188926697\n",
      "Epoch 893/2000 - Loss: 2.513115882873535 - Train accuracy: 0.571812093257904 - Test accuracy: 0.7496644258499146\n",
      "Epoch 894/2000 - Loss: 2.586378335952759 - Train accuracy: 0.583509087562561 - Test accuracy: 0.7522531151771545\n",
      "Epoch 895/2000 - Loss: 2.5075623989105225 - Train accuracy: 0.5804410576820374 - Test accuracy: 0.7473633885383606\n",
      "Epoch 896/2000 - Loss: 2.3207218647003174 - Train accuracy: 0.574400782585144 - Test accuracy: 0.744678795337677\n",
      "Epoch 897/2000 - Loss: 2.725283145904541 - Train accuracy: 0.5737296342849731 - Test accuracy: 0.7487056851387024\n",
      "Epoch 898/2000 - Loss: 2.408691167831421 - Train accuracy: 0.5787152647972107 - Test accuracy: 0.7513902187347412\n",
      "Epoch 899/2000 - Loss: 2.361652135848999 - Train accuracy: 0.5734419822692871 - Test accuracy: 0.750143826007843\n",
      "Epoch 900/2000 - Loss: 2.344496726989746 - Train accuracy: 0.571524441242218 - Test accuracy: 0.7499520778656006\n",
      "Epoch 901/2000 - Loss: 2.330420970916748 - Train accuracy: 0.5729625821113586 - Test accuracy: 0.7538830041885376\n",
      "Epoch 902/2000 - Loss: 2.50079607963562 - Train accuracy: 0.574113130569458 - Test accuracy: 0.7558964490890503\n",
      "Epoch 903/2000 - Loss: 2.451341152191162 - Train accuracy: 0.5720996856689453 - Test accuracy: 0.7546500563621521\n",
      "Epoch 904/2000 - Loss: 2.6680047512054443 - Train accuracy: 0.5807286500930786 - Test accuracy: 0.7533077597618103\n",
      "Epoch 905/2000 - Loss: 2.586543560028076 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7543624043464661\n",
      "Epoch 906/2000 - Loss: 2.4498627185821533 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7540748119354248\n",
      "Epoch 907/2000 - Loss: 2.562042474746704 - Train accuracy: 0.5772770643234253 - Test accuracy: 0.7525407671928406\n",
      "Epoch 908/2000 - Loss: 2.509441614151001 - Train accuracy: 0.5729625821113586 - Test accuracy: 0.7551294565200806\n",
      "Epoch 909/2000 - Loss: 2.433588743209839 - Train accuracy: 0.5771812200546265 - Test accuracy: 0.7507190704345703\n",
      "Epoch 910/2000 - Loss: 2.55387806892395 - Train accuracy: 0.584467887878418 - Test accuracy: 0.7489932775497437\n",
      "Epoch 911/2000 - Loss: 2.4805922508239746 - Train accuracy: 0.5763183236122131 - Test accuracy: 0.7497603297233582\n",
      "Epoch 912/2000 - Loss: 2.758754253387451 - Train accuracy: 0.5736337304115295 - Test accuracy: 0.7560881972312927\n",
      "Epoch 913/2000 - Loss: 2.3758761882781982 - Train accuracy: 0.5793864130973816 - Test accuracy: 0.756951093673706\n",
      "Epoch 914/2000 - Loss: 2.5713462829589844 - Train accuracy: 0.5775647163391113 - Test accuracy: 0.7571428418159485\n",
      "Epoch 915/2000 - Loss: 2.34725022315979 - Train accuracy: 0.5771812200546265 - Test accuracy: 0.7535954117774963\n",
      "Epoch 916/2000 - Loss: 2.323319673538208 - Train accuracy: 0.5803451538085938 - Test accuracy: 0.7567593455314636\n",
      "Epoch 917/2000 - Loss: 2.4505836963653564 - Train accuracy: 0.5806328058242798 - Test accuracy: 0.7538830041885376\n",
      "Epoch 918/2000 - Loss: 2.3876655101776123 - Train accuracy: 0.5803451538085938 - Test accuracy: 0.7534995079040527\n",
      "Epoch 919/2000 - Loss: 2.4713680744171143 - Train accuracy: 0.5816874504089355 - Test accuracy: 0.7529242634773254\n",
      "Epoch 920/2000 - Loss: 2.362823009490967 - Train accuracy: 0.5812080502510071 - Test accuracy: 0.7530201077461243\n",
      "Epoch 921/2000 - Loss: 2.4364466667175293 - Train accuracy: 0.5834132432937622 - Test accuracy: 0.7554170489311218\n",
      "Epoch 922/2000 - Loss: 2.4777889251708984 - Train accuracy: 0.5823585987091064 - Test accuracy: 0.7539789080619812\n",
      "Epoch 923/2000 - Loss: 2.3953864574432373 - Train accuracy: 0.576414167881012 - Test accuracy: 0.7549377083778381\n",
      "Epoch 924/2000 - Loss: 2.4010629653930664 - Train accuracy: 0.5767977237701416 - Test accuracy: 0.7554170489311218\n",
      "Epoch 925/2000 - Loss: 2.4301137924194336 - Train accuracy: 0.5825503468513489 - Test accuracy: 0.7534995079040527\n",
      "Epoch 926/2000 - Loss: 2.3791298866271973 - Train accuracy: 0.5771812200546265 - Test accuracy: 0.7548418045043945\n",
      "Epoch 927/2000 - Loss: 2.570915699005127 - Train accuracy: 0.579578161239624 - Test accuracy: 0.7557047009468079\n",
      "Epoch 928/2000 - Loss: 2.2735445499420166 - Train accuracy: 0.579290509223938 - Test accuracy: 0.7581016421318054\n",
      "Epoch 929/2000 - Loss: 2.4047248363494873 - Train accuracy: 0.576989471912384 - Test accuracy: 0.7582933902740479\n",
      "Epoch 930/2000 - Loss: 2.471057653427124 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7599232792854309\n",
      "Epoch 931/2000 - Loss: 2.5199599266052246 - Train accuracy: 0.5832214951515198 - Test accuracy: 0.7570469975471497\n",
      "Epoch 932/2000 - Loss: 2.596473455429077 - Train accuracy: 0.5836049914360046 - Test accuracy: 0.7583892345428467\n",
      "Epoch 933/2000 - Loss: 2.3775527477264404 - Train accuracy: 0.5822626948356628 - Test accuracy: 0.7577181458473206\n",
      "Epoch 934/2000 - Loss: 2.5135321617126465 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7543624043464661\n",
      "Epoch 935/2000 - Loss: 2.4980249404907227 - Train accuracy: 0.571236789226532 - Test accuracy: 0.7571428418159485\n",
      "Epoch 936/2000 - Loss: 2.472217082977295 - Train accuracy: 0.5772770643234253 - Test accuracy: 0.755321204662323\n",
      "Epoch 937/2000 - Loss: 2.407468795776367 - Train accuracy: 0.5736337304115295 - Test accuracy: 0.7549377083778381\n",
      "Epoch 938/2000 - Loss: 2.6010851860046387 - Train accuracy: 0.5760306715965271 - Test accuracy: 0.7558964490890503\n",
      "Epoch 939/2000 - Loss: 2.294743299484253 - Train accuracy: 0.5813039541244507 - Test accuracy: 0.756951093673706\n",
      "Epoch 940/2000 - Loss: 2.586047649383545 - Train accuracy: 0.5815915465354919 - Test accuracy: 0.7574304938316345\n",
      "Epoch 941/2000 - Loss: 2.499255657196045 - Train accuracy: 0.5726749897003174 - Test accuracy: 0.7598274350166321\n",
      "Epoch 942/2000 - Loss: 2.59537935256958 - Train accuracy: 0.5807286500930786 - Test accuracy: 0.759539783000946\n",
      "Epoch 943/2000 - Loss: 2.4666905403137207 - Train accuracy: 0.5806328058242798 - Test accuracy: 0.7599232792854309\n",
      "Epoch 944/2000 - Loss: 2.3650097846984863 - Train accuracy: 0.5854266285896301 - Test accuracy: 0.7617449760437012\n",
      "Epoch 945/2000 - Loss: 2.7373273372650146 - Train accuracy: 0.5779482126235962 - Test accuracy: 0.7609779238700867\n",
      "Epoch 946/2000 - Loss: 2.50185489654541 - Train accuracy: 0.580920398235321 - Test accuracy: 0.7622243762016296\n",
      "Epoch 947/2000 - Loss: 2.659562826156616 - Train accuracy: 0.576989471912384 - Test accuracy: 0.7639501690864563\n",
      "Epoch 948/2000 - Loss: 2.473649263381958 - Train accuracy: 0.5869606733322144 - Test accuracy: 0.7629913687705994\n",
      "Epoch 949/2000 - Loss: 2.468019485473633 - Train accuracy: 0.5706615447998047 - Test accuracy: 0.7610738277435303\n",
      "Epoch 950/2000 - Loss: 2.6358330249786377 - Train accuracy: 0.578331708908081 - Test accuracy: 0.759539783000946\n",
      "Epoch 951/2000 - Loss: 2.486478090286255 - Train accuracy: 0.5816874504089355 - Test accuracy: 0.7575263381004333\n",
      "Epoch 952/2000 - Loss: 2.4655954837799072 - Train accuracy: 0.5814957022666931 - Test accuracy: 0.7564716935157776\n",
      "Epoch 953/2000 - Loss: 2.4039292335510254 - Train accuracy: 0.5758389234542847 - Test accuracy: 0.7564716935157776\n",
      "Epoch 954/2000 - Loss: 2.3895483016967773 - Train accuracy: 0.5791946053504944 - Test accuracy: 0.75925213098526\n",
      "Epoch 955/2000 - Loss: 2.4011800289154053 - Train accuracy: 0.5781399607658386 - Test accuracy: 0.7607861757278442\n",
      "Epoch 956/2000 - Loss: 2.444277763366699 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7599232792854309\n",
      "Epoch 957/2000 - Loss: 2.4107491970062256 - Train accuracy: 0.576989471912384 - Test accuracy: 0.7597315311431885\n",
      "Epoch 958/2000 - Loss: 2.393813133239746 - Train accuracy: 0.5761265754699707 - Test accuracy: 0.7603068351745605\n",
      "Epoch 959/2000 - Loss: 2.471309185028076 - Train accuracy: 0.5784276127815247 - Test accuracy: 0.7582933902740479\n",
      "Epoch 960/2000 - Loss: 2.67659854888916 - Train accuracy: 0.5770853161811829 - Test accuracy: 0.756951093673706\n",
      "Epoch 961/2000 - Loss: 2.3392550945281982 - Train accuracy: 0.5766059160232544 - Test accuracy: 0.7581974864006042\n",
      "Epoch 962/2000 - Loss: 2.2914345264434814 - Train accuracy: 0.5801534056663513 - Test accuracy: 0.7607861757278442\n",
      "Epoch 963/2000 - Loss: 2.391641139984131 - Train accuracy: 0.5813039541244507 - Test accuracy: 0.7614573240280151\n",
      "Epoch 964/2000 - Loss: 2.5015764236450195 - Train accuracy: 0.5868648290634155 - Test accuracy: 0.7642377614974976\n",
      "Epoch 965/2000 - Loss: 2.6228833198547363 - Train accuracy: 0.5865771770477295 - Test accuracy: 0.7637583613395691\n",
      "Epoch 966/2000 - Loss: 2.521699905395508 - Train accuracy: 0.5814957022666931 - Test accuracy: 0.7629913687705994\n",
      "Epoch 967/2000 - Loss: 2.490145444869995 - Train accuracy: 0.5765100717544556 - Test accuracy: 0.7629913687705994\n",
      "Epoch 968/2000 - Loss: 2.293107271194458 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7628954648971558\n",
      "Epoch 969/2000 - Loss: 2.5235469341278076 - Train accuracy: 0.5770853161811829 - Test accuracy: 0.7633748650550842\n",
      "Epoch 970/2000 - Loss: 2.1970162391662598 - Train accuracy: 0.5808245539665222 - Test accuracy: 0.7634707689285278\n",
      "Epoch 971/2000 - Loss: 2.3666701316833496 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7651965618133545\n",
      "Epoch 972/2000 - Loss: 2.361187219619751 - Train accuracy: 0.5814957022666931 - Test accuracy: 0.7650048136711121\n",
      "Epoch 973/2000 - Loss: 2.336383581161499 - Train accuracy: 0.5867689251899719 - Test accuracy: 0.7646212577819824\n",
      "Epoch 974/2000 - Loss: 2.5641682147979736 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7661553025245667\n",
      "Epoch 975/2000 - Loss: 2.1867804527282715 - Train accuracy: 0.5830297470092773 - Test accuracy: 0.7645254135131836\n",
      "Epoch 976/2000 - Loss: 2.42604923248291 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7641419172286987\n",
      "Epoch 977/2000 - Loss: 2.357264757156372 - Train accuracy: 0.5773729681968689 - Test accuracy: 0.7625119686126709\n",
      "Epoch 978/2000 - Loss: 2.243428945541382 - Train accuracy: 0.5866730809211731 - Test accuracy: 0.7639501690864563\n",
      "Epoch 979/2000 - Loss: 2.359349012374878 - Train accuracy: 0.5791946053504944 - Test accuracy: 0.7633748650550842\n",
      "Epoch 980/2000 - Loss: 2.440044641494751 - Train accuracy: 0.5790987610816956 - Test accuracy: 0.7649089097976685\n",
      "Epoch 981/2000 - Loss: 2.6033935546875 - Train accuracy: 0.5834132432937622 - Test accuracy: 0.7649089097976685\n",
      "Epoch 982/2000 - Loss: 2.317941665649414 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7638542652130127\n",
      "Epoch 983/2000 - Loss: 2.5033862590789795 - Train accuracy: 0.5842761397361755 - Test accuracy: 0.763087272644043\n",
      "Epoch 984/2000 - Loss: 2.3266990184783936 - Train accuracy: 0.584467887878418 - Test accuracy: 0.7610738277435303\n",
      "Epoch 985/2000 - Loss: 2.2652316093444824 - Train accuracy: 0.584467887878418 - Test accuracy: 0.7604026794433594\n",
      "Epoch 986/2000 - Loss: 2.377211093902588 - Train accuracy: 0.5725790858268738 - Test accuracy: 0.7591562867164612\n",
      "Epoch 987/2000 - Loss: 2.473207473754883 - Train accuracy: 0.5811122059822083 - Test accuracy: 0.7603068351745605\n",
      "Epoch 988/2000 - Loss: 2.300769567489624 - Train accuracy: 0.5820709466934204 - Test accuracy: 0.759539783000946\n",
      "Epoch 989/2000 - Loss: 2.5564327239990234 - Train accuracy: 0.5780441164970398 - Test accuracy: 0.7603068351745605\n",
      "Epoch 990/2000 - Loss: 2.2775731086730957 - Train accuracy: 0.5790987610816956 - Test accuracy: 0.7633748650550842\n",
      "Epoch 991/2000 - Loss: 2.313976287841797 - Train accuracy: 0.5841802358627319 - Test accuracy: 0.7657718062400818\n",
      "Epoch 992/2000 - Loss: 2.2858288288116455 - Train accuracy: 0.5799616575241089 - Test accuracy: 0.7650048136711121\n",
      "Epoch 993/2000 - Loss: 2.4807002544403076 - Train accuracy: 0.581879198551178 - Test accuracy: 0.7636625170707703\n",
      "Epoch 994/2000 - Loss: 2.740079641342163 - Train accuracy: 0.5766059160232544 - Test accuracy: 0.7627037167549133\n",
      "Epoch 995/2000 - Loss: 2.4431493282318115 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7636625170707703\n",
      "Epoch 996/2000 - Loss: 2.497755765914917 - Train accuracy: 0.5799616575241089 - Test accuracy: 0.764717161655426\n",
      "Epoch 997/2000 - Loss: 2.50594162940979 - Train accuracy: 0.5851390361785889 - Test accuracy: 0.7659635543823242\n",
      "Epoch 998/2000 - Loss: 2.4008233547210693 - Train accuracy: 0.5899328589439392 - Test accuracy: 0.7654841542243958\n",
      "Epoch 999/2000 - Loss: 2.6300055980682373 - Train accuracy: 0.5830297470092773 - Test accuracy: 0.7649089097976685\n",
      "Epoch 1000/2000 - Loss: 2.3790009021759033 - Train accuracy: 0.5812080502510071 - Test accuracy: 0.7671141028404236\n",
      "Epoch 1001/2000 - Loss: 2.384169578552246 - Train accuracy: 0.5768935680389404 - Test accuracy: 0.7663470506668091\n",
      "Epoch 1002/2000 - Loss: 2.3769919872283936 - Train accuracy: 0.5779482126235962 - Test accuracy: 0.7655800580978394\n",
      "Epoch 1003/2000 - Loss: 2.361616611480713 - Train accuracy: 0.5843719840049744 - Test accuracy: 0.7672099471092224\n",
      "Epoch 1004/2000 - Loss: 2.2521960735321045 - Train accuracy: 0.5825503468513489 - Test accuracy: 0.7646212577819824\n",
      "Epoch 1005/2000 - Loss: 2.3971011638641357 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7626078724861145\n",
      "Epoch 1006/2000 - Loss: 2.2618441581726074 - Train accuracy: 0.5757430195808411 - Test accuracy: 0.7642377614974976\n",
      "Epoch 1007/2000 - Loss: 2.2343006134033203 - Train accuracy: 0.5838926434516907 - Test accuracy: 0.7617449760437012\n",
      "Epoch 1008/2000 - Loss: 2.227140188217163 - Train accuracy: 0.5837967395782471 - Test accuracy: 0.7619367241859436\n",
      "Epoch 1009/2000 - Loss: 2.2089650630950928 - Train accuracy: 0.5848513841629028 - Test accuracy: 0.764717161655426\n",
      "Epoch 1010/2000 - Loss: 2.1825382709503174 - Train accuracy: 0.5861936807632446 - Test accuracy: 0.7665388584136963\n",
      "Epoch 1011/2000 - Loss: 2.353201389312744 - Train accuracy: 0.5826461911201477 - Test accuracy: 0.7660594582557678\n",
      "Epoch 1012/2000 - Loss: 2.4291024208068848 - Train accuracy: 0.5815915465354919 - Test accuracy: 0.7655800580978394\n",
      "Epoch 1013/2000 - Loss: 2.3657872676849365 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7666347026824951\n",
      "Epoch 1014/2000 - Loss: 2.6930885314941406 - Train accuracy: 0.5862895250320435 - Test accuracy: 0.7650048136711121\n",
      "Epoch 1015/2000 - Loss: 2.583226442337036 - Train accuracy: 0.5797699093818665 - Test accuracy: 0.7627996206283569\n",
      "Epoch 1016/2000 - Loss: 2.4541168212890625 - Train accuracy: 0.576414167881012 - Test accuracy: 0.7627037167549133\n",
      "Epoch 1017/2000 - Loss: 2.391772747039795 - Train accuracy: 0.5787152647972107 - Test accuracy: 0.762128472328186\n",
      "Epoch 1018/2000 - Loss: 2.3800272941589355 - Train accuracy: 0.5899328589439392 - Test accuracy: 0.7612655758857727\n",
      "Epoch 1019/2000 - Loss: 2.3092386722564697 - Train accuracy: 0.5771812200546265 - Test accuracy: 0.7631831169128418\n",
      "Epoch 1020/2000 - Loss: 2.4844000339508057 - Train accuracy: 0.5846596360206604 - Test accuracy: 0.7638542652130127\n",
      "Epoch 1021/2000 - Loss: 2.441362142562866 - Train accuracy: 0.579002857208252 - Test accuracy: 0.7640460133552551\n",
      "Epoch 1022/2000 - Loss: 2.4296536445617676 - Train accuracy: 0.5735378861427307 - Test accuracy: 0.7611697316169739\n",
      "Epoch 1023/2000 - Loss: 2.425225257873535 - Train accuracy: 0.572483241558075 - Test accuracy: 0.7641419172286987\n",
      "Epoch 1024/2000 - Loss: 2.451725721359253 - Train accuracy: 0.5841802358627319 - Test accuracy: 0.7678810954093933\n",
      "Epoch 1025/2000 - Loss: 2.615499496459961 - Train accuracy: 0.5788111090660095 - Test accuracy: 0.7631831169128418\n",
      "Epoch 1026/2000 - Loss: 2.2252824306488037 - Train accuracy: 0.5816874504089355 - Test accuracy: 0.7614573240280151\n",
      "Epoch 1027/2000 - Loss: 2.2788543701171875 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7681687474250793\n",
      "Epoch 1028/2000 - Loss: 2.349256992340088 - Train accuracy: 0.5782358646392822 - Test accuracy: 0.7694151401519775\n",
      "Epoch 1029/2000 - Loss: 2.389117956161499 - Train accuracy: 0.5867689251899719 - Test accuracy: 0.7654841542243958\n",
      "Epoch 1030/2000 - Loss: 2.514096736907959 - Train accuracy: 0.5816874504089355 - Test accuracy: 0.7671141028404236\n",
      "Epoch 1031/2000 - Loss: 2.399170398712158 - Train accuracy: 0.584467887878418 - Test accuracy: 0.7702780365943909\n",
      "Epoch 1032/2000 - Loss: 2.4860103130340576 - Train accuracy: 0.5801534056663513 - Test accuracy: 0.7717161774635315\n",
      "Epoch 1033/2000 - Loss: 2.303717851638794 - Train accuracy: 0.5845637321472168 - Test accuracy: 0.76960688829422\n",
      "Epoch 1034/2000 - Loss: 2.3821828365325928 - Train accuracy: 0.5841802358627319 - Test accuracy: 0.7707574367523193\n",
      "Epoch 1035/2000 - Loss: 2.602391242980957 - Train accuracy: 0.5813039541244507 - Test accuracy: 0.7683604955673218\n",
      "Epoch 1036/2000 - Loss: 2.3998053073883057 - Train accuracy: 0.5823585987091064 - Test accuracy: 0.7642377614974976\n",
      "Epoch 1037/2000 - Loss: 2.624459743499756 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7631831169128418\n",
      "Epoch 1038/2000 - Loss: 2.6390881538391113 - Train accuracy: 0.5910834074020386 - Test accuracy: 0.7649089097976685\n",
      "Epoch 1039/2000 - Loss: 2.353135824203491 - Train accuracy: 0.5846596360206604 - Test accuracy: 0.7649089097976685\n",
      "Epoch 1040/2000 - Loss: 2.522728681564331 - Train accuracy: 0.5805369019508362 - Test accuracy: 0.7651965618133545\n",
      "Epoch 1041/2000 - Loss: 2.7048985958099365 - Train accuracy: 0.5808245539665222 - Test accuracy: 0.7666347026824951\n",
      "Epoch 1042/2000 - Loss: 2.55672025680542 - Train accuracy: 0.5803451538085938 - Test accuracy: 0.7686481475830078\n",
      "Epoch 1043/2000 - Loss: 2.4680678844451904 - Train accuracy: 0.5839884877204895 - Test accuracy: 0.7687439918518066\n",
      "Epoch 1044/2000 - Loss: 2.5765292644500732 - Train accuracy: 0.5836049914360046 - Test accuracy: 0.7691274881362915\n",
      "Epoch 1045/2000 - Loss: 2.7452011108398438 - Train accuracy: 0.579290509223938 - Test accuracy: 0.7733461260795593\n",
      "Epoch 1046/2000 - Loss: 2.6493258476257324 - Train accuracy: 0.5831255912780762 - Test accuracy: 0.7681687474250793\n",
      "Epoch 1047/2000 - Loss: 2.4895923137664795 - Train accuracy: 0.5861936807632446 - Test accuracy: 0.7678810954093933\n",
      "Epoch 1048/2000 - Loss: 2.3747098445892334 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7695110440254211\n",
      "Epoch 1049/2000 - Loss: 2.5254552364349365 - Train accuracy: 0.5850431323051453 - Test accuracy: 0.7690316438674927\n",
      "Epoch 1050/2000 - Loss: 2.7340798377990723 - Train accuracy: 0.5767977237701416 - Test accuracy: 0.7645254135131836\n",
      "Epoch 1051/2000 - Loss: 2.6473560333251953 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7660594582557678\n",
      "Epoch 1052/2000 - Loss: 2.48132061958313 - Train accuracy: 0.5815915465354919 - Test accuracy: 0.7659635543823242\n",
      "Epoch 1053/2000 - Loss: 2.675769329071045 - Train accuracy: 0.5812080502510071 - Test accuracy: 0.7618408203125\n",
      "Epoch 1054/2000 - Loss: 2.475099802017212 - Train accuracy: 0.5842761397361755 - Test accuracy: 0.7588686347007751\n",
      "Epoch 1055/2000 - Loss: 2.4269163608551025 - Train accuracy: 0.5814957022666931 - Test accuracy: 0.7640460133552551\n",
      "Epoch 1056/2000 - Loss: 2.4814913272857666 - Train accuracy: 0.5837967395782471 - Test accuracy: 0.7681687474250793\n",
      "Epoch 1057/2000 - Loss: 2.6140215396881104 - Train accuracy: 0.5777564644813538 - Test accuracy: 0.7665388584136963\n",
      "Epoch 1058/2000 - Loss: 2.466859817504883 - Train accuracy: 0.5797699093818665 - Test accuracy: 0.7663470506668091\n",
      "Epoch 1059/2000 - Loss: 2.3302297592163086 - Train accuracy: 0.5857142806053162 - Test accuracy: 0.7692233920097351\n",
      "Epoch 1060/2000 - Loss: 2.511183261871338 - Train accuracy: 0.5807286500930786 - Test accuracy: 0.7697986364364624\n",
      "Epoch 1061/2000 - Loss: 2.5855908393859863 - Train accuracy: 0.5855225324630737 - Test accuracy: 0.7705656886100769\n",
      "Epoch 1062/2000 - Loss: 2.4275262355804443 - Train accuracy: 0.5858101844787598 - Test accuracy: 0.7692233920097351\n",
      "Epoch 1063/2000 - Loss: 2.271299123764038 - Train accuracy: 0.5876318216323853 - Test accuracy: 0.7697027921676636\n",
      "Epoch 1064/2000 - Loss: 2.252009868621826 - Train accuracy: 0.586097776889801 - Test accuracy: 0.7679769992828369\n",
      "Epoch 1065/2000 - Loss: 2.3814897537231445 - Train accuracy: 0.5865771770477295 - Test accuracy: 0.7658677101135254\n",
      "Epoch 1066/2000 - Loss: 2.401750087738037 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.765675961971283\n",
      "Epoch 1067/2000 - Loss: 2.567841053009033 - Train accuracy: 0.5846596360206604 - Test accuracy: 0.767305850982666\n",
      "Epoch 1068/2000 - Loss: 2.6294939517974854 - Train accuracy: 0.5867689251899719 - Test accuracy: 0.7686481475830078\n",
      "Epoch 1069/2000 - Loss: 2.341036081314087 - Train accuracy: 0.5891658663749695 - Test accuracy: 0.7683604955673218\n",
      "Epoch 1070/2000 - Loss: 2.510019063949585 - Train accuracy: 0.5861936807632446 - Test accuracy: 0.7693192958831787\n",
      "Epoch 1071/2000 - Loss: 2.475701332092285 - Train accuracy: 0.5842761397361755 - Test accuracy: 0.7695110440254211\n",
      "Epoch 1072/2000 - Loss: 2.234470844268799 - Train accuracy: 0.5837008357048035 - Test accuracy: 0.767593502998352\n",
      "Epoch 1073/2000 - Loss: 2.5711822509765625 - Train accuracy: 0.5848513841629028 - Test accuracy: 0.7689357399940491\n",
      "Epoch 1074/2000 - Loss: 2.6452901363372803 - Train accuracy: 0.5806328058242798 - Test accuracy: 0.7684563994407654\n",
      "Epoch 1075/2000 - Loss: 2.537005662918091 - Train accuracy: 0.580920398235321 - Test accuracy: 0.7667306065559387\n",
      "Epoch 1076/2000 - Loss: 2.5146374702453613 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7658677101135254\n",
      "Epoch 1077/2000 - Loss: 2.4051926136016846 - Train accuracy: 0.5855225324630737 - Test accuracy: 0.767593502998352\n",
      "Epoch 1078/2000 - Loss: 2.444052219390869 - Train accuracy: 0.5884947180747986 - Test accuracy: 0.7676893472671509\n",
      "Epoch 1079/2000 - Loss: 2.30894136428833 - Train accuracy: 0.5826461911201477 - Test accuracy: 0.7631831169128418\n",
      "Epoch 1080/2000 - Loss: 2.379852294921875 - Train accuracy: 0.5811122059822083 - Test accuracy: 0.764717161655426\n",
      "Epoch 1081/2000 - Loss: 2.4020955562591553 - Train accuracy: 0.5865771770477295 - Test accuracy: 0.7666347026824951\n",
      "Epoch 1082/2000 - Loss: 2.4688339233398438 - Train accuracy: 0.5839884877204895 - Test accuracy: 0.767593502998352\n",
      "Epoch 1083/2000 - Loss: 2.7451870441436768 - Train accuracy: 0.5872483253479004 - Test accuracy: 0.7655800580978394\n",
      "Epoch 1084/2000 - Loss: 2.3310651779174805 - Train accuracy: 0.5824544429779053 - Test accuracy: 0.7680728435516357\n",
      "Epoch 1085/2000 - Loss: 2.3254363536834717 - Train accuracy: 0.5801534056663513 - Test accuracy: 0.7713326811790466\n",
      "Epoch 1086/2000 - Loss: 2.3584423065185547 - Train accuracy: 0.5822626948356628 - Test accuracy: 0.77219557762146\n",
      "Epoch 1087/2000 - Loss: 2.3131818771362305 - Train accuracy: 0.5846596360206604 - Test accuracy: 0.7728667259216309\n",
      "Epoch 1088/2000 - Loss: 2.478985548019409 - Train accuracy: 0.5780441164970398 - Test accuracy: 0.7729626297950745\n",
      "Epoch 1089/2000 - Loss: 2.70102858543396 - Train accuracy: 0.5866730809211731 - Test accuracy: 0.7728667259216309\n",
      "Epoch 1090/2000 - Loss: 2.2660834789276123 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7710450887680054\n",
      "Epoch 1091/2000 - Loss: 2.3959217071533203 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.770182192325592\n",
      "Epoch 1092/2000 - Loss: 2.3650879859924316 - Train accuracy: 0.5824544429779053 - Test accuracy: 0.7722914814949036\n",
      "Epoch 1093/2000 - Loss: 2.3524410724639893 - Train accuracy: 0.5799616575241089 - Test accuracy: 0.772770881652832\n",
      "Epoch 1094/2000 - Loss: 2.2945780754089355 - Train accuracy: 0.582166850566864 - Test accuracy: 0.7726749777793884\n",
      "Epoch 1095/2000 - Loss: 2.466329574584961 - Train accuracy: 0.5863854289054871 - Test accuracy: 0.7744966149330139\n",
      "Epoch 1096/2000 - Loss: 2.3960726261138916 - Train accuracy: 0.5857142806053162 - Test accuracy: 0.7723873257637024\n",
      "Epoch 1097/2000 - Loss: 2.4964802265167236 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7728667259216309\n",
      "Epoch 1098/2000 - Loss: 2.300137758255005 - Train accuracy: 0.5919463038444519 - Test accuracy: 0.7730584740638733\n",
      "Epoch 1099/2000 - Loss: 2.3400611877441406 - Train accuracy: 0.5907957553863525 - Test accuracy: 0.7708532810211182\n",
      "Epoch 1100/2000 - Loss: 2.2857956886291504 - Train accuracy: 0.5816874504089355 - Test accuracy: 0.7706615328788757\n",
      "Epoch 1101/2000 - Loss: 2.2343215942382812 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7709491848945618\n",
      "Epoch 1102/2000 - Loss: 2.6303820610046387 - Train accuracy: 0.5839884877204895 - Test accuracy: 0.7687439918518066\n",
      "Epoch 1103/2000 - Loss: 2.365373373031616 - Train accuracy: 0.5796740055084229 - Test accuracy: 0.7697027921676636\n",
      "Epoch 1104/2000 - Loss: 2.376098155975342 - Train accuracy: 0.5841802358627319 - Test accuracy: 0.7717161774635315\n",
      "Epoch 1105/2000 - Loss: 2.3786978721618652 - Train accuracy: 0.5793864130973816 - Test accuracy: 0.7757430672645569\n",
      "Epoch 1106/2000 - Loss: 2.4837310314178467 - Train accuracy: 0.5903164148330688 - Test accuracy: 0.7761265635490417\n",
      "Epoch 1107/2000 - Loss: 2.243103265762329 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7778523564338684\n",
      "Epoch 1108/2000 - Loss: 2.426859140396118 - Train accuracy: 0.5903164148330688 - Test accuracy: 0.774113118648529\n",
      "Epoch 1109/2000 - Loss: 2.5457210540771484 - Train accuracy: 0.5815915465354919 - Test accuracy: 0.7709491848945618\n",
      "Epoch 1110/2000 - Loss: 2.455946445465088 - Train accuracy: 0.5858101844787598 - Test accuracy: 0.7718120813369751\n",
      "Epoch 1111/2000 - Loss: 2.3680787086486816 - Train accuracy: 0.588686466217041 - Test accuracy: 0.7732502222061157\n",
      "Epoch 1112/2000 - Loss: 2.467745542526245 - Train accuracy: 0.5904122591018677 - Test accuracy: 0.772770881652832\n",
      "Epoch 1113/2000 - Loss: 2.550518274307251 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7723873257637024\n",
      "Epoch 1114/2000 - Loss: 2.439563512802124 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7745925188064575\n",
      "Epoch 1115/2000 - Loss: 2.2411253452301025 - Train accuracy: 0.5880153179168701 - Test accuracy: 0.772770881652832\n",
      "Epoch 1116/2000 - Loss: 2.4125146865844727 - Train accuracy: 0.5900287628173828 - Test accuracy: 0.770182192325592\n",
      "Epoch 1117/2000 - Loss: 2.581232786178589 - Train accuracy: 0.5885906219482422 - Test accuracy: 0.7699903845787048\n",
      "Epoch 1118/2000 - Loss: 2.4390060901641846 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7764142155647278\n",
      "Epoch 1119/2000 - Loss: 2.3782899379730225 - Train accuracy: 0.5848513841629028 - Test accuracy: 0.7753595113754272\n",
      "Epoch 1120/2000 - Loss: 2.3650295734405518 - Train accuracy: 0.588686466217041 - Test accuracy: 0.7729626297950745\n",
      "Epoch 1121/2000 - Loss: 2.2895009517669678 - Train accuracy: 0.5858101844787598 - Test accuracy: 0.7754554152488708\n",
      "Epoch 1122/2000 - Loss: 2.23376202583313 - Train accuracy: 0.587344229221344 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1123/2000 - Loss: 2.512136936187744 - Train accuracy: 0.5881112217903137 - Test accuracy: 0.7742090225219727\n",
      "Epoch 1124/2000 - Loss: 2.3559136390686035 - Train accuracy: 0.5861936807632446 - Test accuracy: 0.774113118648529\n",
      "Epoch 1125/2000 - Loss: 2.4865915775299072 - Train accuracy: 0.5859060287475586 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1126/2000 - Loss: 2.3352513313293457 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7728667259216309\n",
      "Epoch 1127/2000 - Loss: 2.405717611312866 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7715244293212891\n",
      "Epoch 1128/2000 - Loss: 2.4700074195861816 - Train accuracy: 0.5820709466934204 - Test accuracy: 0.77219557762146\n",
      "Epoch 1129/2000 - Loss: 2.3566582202911377 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7699903845787048\n",
      "Epoch 1130/2000 - Loss: 2.258213758468628 - Train accuracy: 0.5880153179168701 - Test accuracy: 0.7685522437095642\n",
      "Epoch 1131/2000 - Loss: 2.304814338684082 - Train accuracy: 0.5826461911201477 - Test accuracy: 0.7669223546981812\n",
      "Epoch 1132/2000 - Loss: 2.3253440856933594 - Train accuracy: 0.5822626948356628 - Test accuracy: 0.7679769992828369\n",
      "Epoch 1133/2000 - Loss: 2.4472808837890625 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7687439918518066\n",
      "Epoch 1134/2000 - Loss: 2.267890214920044 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7709491848945618\n",
      "Epoch 1135/2000 - Loss: 2.1868362426757812 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.772483229637146\n",
      "Epoch 1136/2000 - Loss: 2.4742178916931152 - Train accuracy: 0.5926174521446228 - Test accuracy: 0.7726749777793884\n",
      "Epoch 1137/2000 - Loss: 2.248619556427002 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7737296223640442\n",
      "Epoch 1138/2000 - Loss: 2.466456890106201 - Train accuracy: 0.5864813327789307 - Test accuracy: 0.7731543779373169\n",
      "Epoch 1139/2000 - Loss: 2.3167977333068848 - Train accuracy: 0.5839884877204895 - Test accuracy: 0.7744007706642151\n",
      "Epoch 1140/2000 - Loss: 2.519359827041626 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7745925188064575\n",
      "Epoch 1141/2000 - Loss: 2.595628499984741 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7756471633911133\n",
      "Epoch 1142/2000 - Loss: 2.4233617782592773 - Train accuracy: 0.5862895250320435 - Test accuracy: 0.776701807975769\n",
      "Epoch 1143/2000 - Loss: 2.4651739597320557 - Train accuracy: 0.5903164148330688 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1144/2000 - Loss: 2.3587942123413086 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7728667259216309\n",
      "Epoch 1145/2000 - Loss: 2.3125624656677246 - Train accuracy: 0.584755539894104 - Test accuracy: 0.7729626297950745\n",
      "Epoch 1146/2000 - Loss: 2.4285991191864014 - Train accuracy: 0.594151496887207 - Test accuracy: 0.777660608291626\n",
      "Epoch 1147/2000 - Loss: 2.3359994888305664 - Train accuracy: 0.5838926434516907 - Test accuracy: 0.7767977118492126\n",
      "Epoch 1148/2000 - Loss: 2.3126161098480225 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7746884226799011\n",
      "Epoch 1149/2000 - Loss: 2.318601608276367 - Train accuracy: 0.5822626948356628 - Test accuracy: 0.774113118648529\n",
      "Epoch 1150/2000 - Loss: 2.3235037326812744 - Train accuracy: 0.5925215482711792 - Test accuracy: 0.7738255262374878\n",
      "Epoch 1151/2000 - Loss: 2.352238893508911 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7743048667907715\n",
      "Epoch 1152/2000 - Loss: 2.3425447940826416 - Train accuracy: 0.5891658663749695 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1153/2000 - Loss: 2.434236526489258 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7748801708221436\n",
      "Epoch 1154/2000 - Loss: 2.2909979820251465 - Train accuracy: 0.5884947180747986 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1155/2000 - Loss: 2.3718836307525635 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7755513191223145\n",
      "Epoch 1156/2000 - Loss: 2.4907753467559814 - Train accuracy: 0.5859060287475586 - Test accuracy: 0.7761265635490417\n",
      "Epoch 1157/2000 - Loss: 2.3605074882507324 - Train accuracy: 0.5891658663749695 - Test accuracy: 0.7762224078178406\n",
      "Epoch 1158/2000 - Loss: 2.303520679473877 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7753595113754272\n",
      "Epoch 1159/2000 - Loss: 2.3893816471099854 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7752636671066284\n",
      "Epoch 1160/2000 - Loss: 2.367124080657959 - Train accuracy: 0.581879198551178 - Test accuracy: 0.7768935561180115\n",
      "Epoch 1161/2000 - Loss: 2.284421682357788 - Train accuracy: 0.5862895250320435 - Test accuracy: 0.7762224078178406\n",
      "Epoch 1162/2000 - Loss: 2.318936824798584 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7756471633911133\n",
      "Epoch 1163/2000 - Loss: 2.3998191356658936 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1164/2000 - Loss: 2.5025336742401123 - Train accuracy: 0.5779482126235962 - Test accuracy: 0.7769894599914551\n",
      "Epoch 1165/2000 - Loss: 2.380845546722412 - Train accuracy: 0.5855225324630737 - Test accuracy: 0.7780441045761108\n",
      "Epoch 1166/2000 - Loss: 2.439805507659912 - Train accuracy: 0.5883029699325562 - Test accuracy: 0.7789070010185242\n",
      "Epoch 1167/2000 - Loss: 2.5866055488586426 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7783317565917969\n",
      "Epoch 1168/2000 - Loss: 2.5631837844848633 - Train accuracy: 0.591562807559967 - Test accuracy: 0.7794822454452515\n",
      "Epoch 1169/2000 - Loss: 2.172330617904663 - Train accuracy: 0.5907957553863525 - Test accuracy: 0.7773729562759399\n",
      "Epoch 1170/2000 - Loss: 2.406034231185913 - Train accuracy: 0.5837008357048035 - Test accuracy: 0.7771812081336975\n",
      "Epoch 1171/2000 - Loss: 2.20231556892395 - Train accuracy: 0.5863854289054871 - Test accuracy: 0.7777564525604248\n",
      "Epoch 1172/2000 - Loss: 2.1658830642700195 - Train accuracy: 0.5862895250320435 - Test accuracy: 0.7773729562759399\n",
      "Epoch 1173/2000 - Loss: 2.373169422149658 - Train accuracy: 0.5828379392623901 - Test accuracy: 0.7752636671066284\n",
      "Epoch 1174/2000 - Loss: 2.3255629539489746 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1175/2000 - Loss: 2.3086154460906982 - Train accuracy: 0.5838926434516907 - Test accuracy: 0.7763183116912842\n",
      "Epoch 1176/2000 - Loss: 2.3268349170684814 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7765100598335266\n",
      "Epoch 1177/2000 - Loss: 2.3735949993133545 - Train accuracy: 0.5852348804473877 - Test accuracy: 0.7744966149330139\n",
      "Epoch 1178/2000 - Loss: 2.308727979660034 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7744966149330139\n",
      "Epoch 1179/2000 - Loss: 2.3701133728027344 - Train accuracy: 0.5840843915939331 - Test accuracy: 0.775071918964386\n",
      "Epoch 1180/2000 - Loss: 2.3513479232788086 - Train accuracy: 0.5909875631332397 - Test accuracy: 0.7732502222061157\n",
      "Epoch 1181/2000 - Loss: 2.4059720039367676 - Train accuracy: 0.5897411108016968 - Test accuracy: 0.7761265635490417\n",
      "Epoch 1182/2000 - Loss: 2.1770639419555664 - Train accuracy: 0.5839884877204895 - Test accuracy: 0.7765100598335266\n",
      "Epoch 1183/2000 - Loss: 2.584388017654419 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1184/2000 - Loss: 2.481459617614746 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7749760150909424\n",
      "Epoch 1185/2000 - Loss: 2.444746494293213 - Train accuracy: 0.5864813327789307 - Test accuracy: 0.7785235047340393\n",
      "Epoch 1186/2000 - Loss: 2.230255603790283 - Train accuracy: 0.5885906219482422 - Test accuracy: 0.7779482007026672\n",
      "Epoch 1187/2000 - Loss: 2.212162733078003 - Train accuracy: 0.5939597487449646 - Test accuracy: 0.7790987491607666\n",
      "Epoch 1188/2000 - Loss: 2.2616560459136963 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7782358527183533\n",
      "Epoch 1189/2000 - Loss: 2.241790294647217 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7743048667907715\n",
      "Epoch 1190/2000 - Loss: 2.5848233699798584 - Train accuracy: 0.5900287628173828 - Test accuracy: 0.7746884226799011\n",
      "Epoch 1191/2000 - Loss: 2.4862399101257324 - Train accuracy: 0.5824544429779053 - Test accuracy: 0.7761265635490417\n",
      "Epoch 1192/2000 - Loss: 2.407182216644287 - Train accuracy: 0.5855225324630737 - Test accuracy: 0.7783317565917969\n",
      "Epoch 1193/2000 - Loss: 2.352559804916382 - Train accuracy: 0.5919463038444519 - Test accuracy: 0.7783317565917969\n",
      "Epoch 1194/2000 - Loss: 2.3415403366088867 - Train accuracy: 0.5879194736480713 - Test accuracy: 0.777660608291626\n",
      "Epoch 1195/2000 - Loss: 2.352079153060913 - Train accuracy: 0.5828379392623901 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1196/2000 - Loss: 2.4215991497039795 - Train accuracy: 0.5918504595756531 - Test accuracy: 0.7757430672645569\n",
      "Epoch 1197/2000 - Loss: 2.3547539710998535 - Train accuracy: 0.5868648290634155 - Test accuracy: 0.7748801708221436\n",
      "Epoch 1198/2000 - Loss: 2.5561962127685547 - Train accuracy: 0.5865771770477295 - Test accuracy: 0.7763183116912842\n",
      "Epoch 1199/2000 - Loss: 2.228870391845703 - Train accuracy: 0.5899328589439392 - Test accuracy: 0.7767977118492126\n",
      "Epoch 1200/2000 - Loss: 2.349421977996826 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7784276008605957\n",
      "Epoch 1201/2000 - Loss: 2.3395063877105713 - Train accuracy: 0.5891658663749695 - Test accuracy: 0.7773729562759399\n",
      "Epoch 1202/2000 - Loss: 2.244011640548706 - Train accuracy: 0.5837967395782471 - Test accuracy: 0.7784276008605957\n",
      "Epoch 1203/2000 - Loss: 2.4040873050689697 - Train accuracy: 0.5937680006027222 - Test accuracy: 0.7810162901878357\n",
      "Epoch 1204/2000 - Loss: 2.217796564102173 - Train accuracy: 0.591275155544281 - Test accuracy: 0.781591534614563\n",
      "Epoch 1205/2000 - Loss: 2.451368808746338 - Train accuracy: 0.5822626948356628 - Test accuracy: 0.7801533937454224\n",
      "Epoch 1206/2000 - Loss: 2.3289601802825928 - Train accuracy: 0.5872483253479004 - Test accuracy: 0.7808245420455933\n",
      "Epoch 1207/2000 - Loss: 2.5329172611236572 - Train accuracy: 0.5897411108016968 - Test accuracy: 0.7796739935874939\n",
      "Epoch 1208/2000 - Loss: 2.338090181350708 - Train accuracy: 0.5810163021087646 - Test accuracy: 0.7765100598335266\n",
      "Epoch 1209/2000 - Loss: 2.6695351600646973 - Train accuracy: 0.5904122591018677 - Test accuracy: 0.7770853042602539\n",
      "Epoch 1210/2000 - Loss: 2.54083251953125 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1211/2000 - Loss: 2.6264004707336426 - Train accuracy: 0.586097776889801 - Test accuracy: 0.7748801708221436\n",
      "Epoch 1212/2000 - Loss: 2.3213021755218506 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7757430672645569\n",
      "Epoch 1213/2000 - Loss: 2.371570587158203 - Train accuracy: 0.5946308970451355 - Test accuracy: 0.7764142155647278\n",
      "Epoch 1214/2000 - Loss: 2.414853572845459 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1215/2000 - Loss: 2.310490131378174 - Train accuracy: 0.588974118232727 - Test accuracy: 0.7739213705062866\n",
      "Epoch 1216/2000 - Loss: 2.290846824645996 - Train accuracy: 0.5838926434516907 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1217/2000 - Loss: 2.412429094314575 - Train accuracy: 0.5869606733322144 - Test accuracy: 0.7722914814949036\n",
      "Epoch 1218/2000 - Loss: 2.499906063079834 - Train accuracy: 0.5837967395782471 - Test accuracy: 0.7730584740638733\n",
      "Epoch 1219/2000 - Loss: 2.418360948562622 - Train accuracy: 0.5842761397361755 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1220/2000 - Loss: 2.16184401512146 - Train accuracy: 0.588686466217041 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1221/2000 - Loss: 2.434605360031128 - Train accuracy: 0.5883029699325562 - Test accuracy: 0.7760306596755981\n",
      "Epoch 1222/2000 - Loss: 2.501873016357422 - Train accuracy: 0.5906040072441101 - Test accuracy: 0.7763183116912842\n",
      "Epoch 1223/2000 - Loss: 2.4598209857940674 - Train accuracy: 0.5881112217903137 - Test accuracy: 0.7740172743797302\n",
      "Epoch 1224/2000 - Loss: 2.2594048976898193 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.772770881652832\n",
      "Epoch 1225/2000 - Loss: 2.4320685863494873 - Train accuracy: 0.5736337304115295 - Test accuracy: 0.774113118648529\n",
      "Epoch 1226/2000 - Loss: 2.194843053817749 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1227/2000 - Loss: 2.3187100887298584 - Train accuracy: 0.5949184894561768 - Test accuracy: 0.7770853042602539\n",
      "Epoch 1228/2000 - Loss: 2.408552885055542 - Train accuracy: 0.5836049914360046 - Test accuracy: 0.7784276008605957\n",
      "Epoch 1229/2000 - Loss: 2.5507829189300537 - Train accuracy: 0.5863854289054871 - Test accuracy: 0.7782358527183533\n",
      "Epoch 1230/2000 - Loss: 2.275832176208496 - Train accuracy: 0.583509087562561 - Test accuracy: 0.7786193490028381\n",
      "Epoch 1231/2000 - Loss: 2.335706949234009 - Train accuracy: 0.5885906219482422 - Test accuracy: 0.7784276008605957\n",
      "Epoch 1232/2000 - Loss: 2.4301249980926514 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7787152528762817\n",
      "Epoch 1233/2000 - Loss: 2.37069034576416 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.7785235047340393\n",
      "Epoch 1234/2000 - Loss: 2.5063977241516113 - Train accuracy: 0.586097776889801 - Test accuracy: 0.7788110971450806\n",
      "Epoch 1235/2000 - Loss: 2.535102367401123 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7793864011764526\n",
      "Epoch 1236/2000 - Loss: 2.2367939949035645 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7782358527183533\n",
      "Epoch 1237/2000 - Loss: 2.1984004974365234 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7783317565917969\n",
      "Epoch 1238/2000 - Loss: 2.314953565597534 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7764142155647278\n",
      "Epoch 1239/2000 - Loss: 2.4114134311676025 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7799616456031799\n",
      "Epoch 1240/2000 - Loss: 2.298069477081299 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1241/2000 - Loss: 2.400463104248047 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7799616456031799\n",
      "Epoch 1242/2000 - Loss: 2.1691110134124756 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.7771812081336975\n",
      "Epoch 1243/2000 - Loss: 2.320164680480957 - Train accuracy: 0.5926174521446228 - Test accuracy: 0.7767977118492126\n",
      "Epoch 1244/2000 - Loss: 2.3725597858428955 - Train accuracy: 0.5800575017929077 - Test accuracy: 0.777660608291626\n",
      "Epoch 1245/2000 - Loss: 2.3809921741485596 - Train accuracy: 0.5900287628173828 - Test accuracy: 0.7779482007026672\n",
      "Epoch 1246/2000 - Loss: 2.378610610961914 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.7785235047340393\n",
      "Epoch 1247/2000 - Loss: 2.416023015975952 - Train accuracy: 0.5943432450294495 - Test accuracy: 0.7780441045761108\n",
      "Epoch 1248/2000 - Loss: 2.5025219917297363 - Train accuracy: 0.5891658663749695 - Test accuracy: 0.7773729562759399\n",
      "Epoch 1249/2000 - Loss: 2.2175772190093994 - Train accuracy: 0.5883029699325562 - Test accuracy: 0.7749760150909424\n",
      "Epoch 1250/2000 - Loss: 2.3195414543151855 - Train accuracy: 0.5869606733322144 - Test accuracy: 0.7759348154067993\n",
      "Epoch 1251/2000 - Loss: 2.3293957710266113 - Train accuracy: 0.5910834074020386 - Test accuracy: 0.7779482007026672\n",
      "Epoch 1252/2000 - Loss: 2.4387803077697754 - Train accuracy: 0.5905081629753113 - Test accuracy: 0.7756471633911133\n",
      "Epoch 1253/2000 - Loss: 2.4707181453704834 - Train accuracy: 0.5882070660591125 - Test accuracy: 0.7751677632331848\n",
      "Epoch 1254/2000 - Loss: 2.3465614318847656 - Train accuracy: 0.5850431323051453 - Test accuracy: 0.7762224078178406\n",
      "Epoch 1255/2000 - Loss: 2.4032156467437744 - Train accuracy: 0.5926174521446228 - Test accuracy: 0.7773729562759399\n",
      "Epoch 1256/2000 - Loss: 2.2610678672790527 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7785235047340393\n",
      "Epoch 1257/2000 - Loss: 2.1841869354248047 - Train accuracy: 0.5859060287475586 - Test accuracy: 0.7778523564338684\n",
      "Epoch 1258/2000 - Loss: 2.551828384399414 - Train accuracy: 0.5882070660591125 - Test accuracy: 0.7758389115333557\n",
      "Epoch 1259/2000 - Loss: 2.2642292976379395 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7774688601493835\n",
      "Epoch 1260/2000 - Loss: 2.3562533855438232 - Train accuracy: 0.5872483253479004 - Test accuracy: 0.7787152528762817\n",
      "Epoch 1261/2000 - Loss: 2.479111671447754 - Train accuracy: 0.5876318216323853 - Test accuracy: 0.7781400084495544\n",
      "Epoch 1262/2000 - Loss: 2.3420934677124023 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7765100598335266\n",
      "Epoch 1263/2000 - Loss: 2.489842176437378 - Train accuracy: 0.5897411108016968 - Test accuracy: 0.777660608291626\n",
      "Epoch 1264/2000 - Loss: 2.4272308349609375 - Train accuracy: 0.5881112217903137 - Test accuracy: 0.7798658013343811\n",
      "Epoch 1265/2000 - Loss: 2.3949239253997803 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7806327939033508\n",
      "Epoch 1266/2000 - Loss: 2.2290728092193604 - Train accuracy: 0.5827420949935913 - Test accuracy: 0.7796739935874939\n",
      "Epoch 1267/2000 - Loss: 2.3909740447998047 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7782358527183533\n",
      "Epoch 1268/2000 - Loss: 2.470750093460083 - Train accuracy: 0.5875359773635864 - Test accuracy: 0.7764142155647278\n",
      "Epoch 1269/2000 - Loss: 2.174323320388794 - Train accuracy: 0.5931926965713501 - Test accuracy: 0.7788110971450806\n",
      "Epoch 1270/2000 - Loss: 2.351332902908325 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7793864011764526\n",
      "Epoch 1271/2000 - Loss: 2.1584324836730957 - Train accuracy: 0.5868648290634155 - Test accuracy: 0.7801533937454224\n",
      "Epoch 1272/2000 - Loss: 2.3917953968048096 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7791946530342102\n",
      "Epoch 1273/2000 - Loss: 2.3726184368133545 - Train accuracy: 0.5898370146751404 - Test accuracy: 0.7786193490028381\n",
      "Epoch 1274/2000 - Loss: 2.3881044387817383 - Train accuracy: 0.5888782143592834 - Test accuracy: 0.7790029048919678\n",
      "Epoch 1275/2000 - Loss: 2.4574027061462402 - Train accuracy: 0.587056577205658 - Test accuracy: 0.7781400084495544\n",
      "Epoch 1276/2000 - Loss: 2.2900993824005127 - Train accuracy: 0.5905081629753113 - Test accuracy: 0.7771812081336975\n",
      "Epoch 1277/2000 - Loss: 2.4629390239715576 - Train accuracy: 0.5876318216323853 - Test accuracy: 0.7768935561180115\n",
      "Epoch 1278/2000 - Loss: 2.353379964828491 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7789070010185242\n",
      "Epoch 1279/2000 - Loss: 2.334611177444458 - Train accuracy: 0.5930009484291077 - Test accuracy: 0.7790987491607666\n",
      "Epoch 1280/2000 - Loss: 2.3439667224884033 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7798658013343811\n",
      "Epoch 1281/2000 - Loss: 2.399379253387451 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7786193490028381\n",
      "Epoch 1282/2000 - Loss: 2.5961527824401855 - Train accuracy: 0.5906040072441101 - Test accuracy: 0.7808245420455933\n",
      "Epoch 1283/2000 - Loss: 2.2839548587799072 - Train accuracy: 0.5833173394203186 - Test accuracy: 0.7795781493186951\n",
      "Epoch 1284/2000 - Loss: 2.593961477279663 - Train accuracy: 0.5917545557022095 - Test accuracy: 0.7797698974609375\n",
      "Epoch 1285/2000 - Loss: 2.1871747970581055 - Train accuracy: 0.588686466217041 - Test accuracy: 0.7786193490028381\n",
      "Epoch 1286/2000 - Loss: 2.456303834915161 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7784276008605957\n",
      "Epoch 1287/2000 - Loss: 2.306043863296509 - Train accuracy: 0.5937680006027222 - Test accuracy: 0.7803451418876648\n",
      "Epoch 1288/2000 - Loss: 2.2746191024780273 - Train accuracy: 0.5940555930137634 - Test accuracy: 0.7795781493186951\n",
      "Epoch 1289/2000 - Loss: 2.2410080432891846 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7788110971450806\n",
      "Epoch 1290/2000 - Loss: 2.5117805004119873 - Train accuracy: 0.5868648290634155 - Test accuracy: 0.7788110971450806\n",
      "Epoch 1291/2000 - Loss: 2.2080092430114746 - Train accuracy: 0.596164882183075 - Test accuracy: 0.7799616456031799\n",
      "Epoch 1292/2000 - Loss: 2.344569444656372 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7809204459190369\n",
      "Epoch 1293/2000 - Loss: 2.5209178924560547 - Train accuracy: 0.5888782143592834 - Test accuracy: 0.781879186630249\n",
      "Epoch 1294/2000 - Loss: 2.382535696029663 - Train accuracy: 0.5872483253479004 - Test accuracy: 0.7838926315307617\n",
      "Epoch 1295/2000 - Loss: 2.361673355102539 - Train accuracy: 0.5857142806053162 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1296/2000 - Loss: 2.3416011333465576 - Train accuracy: 0.588686466217041 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1297/2000 - Loss: 2.146834373474121 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1298/2000 - Loss: 2.4829630851745605 - Train accuracy: 0.5930009484291077 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1299/2000 - Loss: 2.368577003479004 - Train accuracy: 0.596164882183075 - Test accuracy: 0.781591534614563\n",
      "Epoch 1300/2000 - Loss: 2.2502098083496094 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7813997864723206\n",
      "Epoch 1301/2000 - Loss: 2.3352878093719482 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1302/2000 - Loss: 2.4287164211273193 - Train accuracy: 0.5875359773635864 - Test accuracy: 0.7829338312149048\n",
      "Epoch 1303/2000 - Loss: 2.526409387588501 - Train accuracy: 0.5878235697746277 - Test accuracy: 0.7820709347724915\n",
      "Epoch 1304/2000 - Loss: 2.5824756622314453 - Train accuracy: 0.5923298001289368 - Test accuracy: 0.7806327939033508\n",
      "Epoch 1305/2000 - Loss: 2.294062614440918 - Train accuracy: 0.5872483253479004 - Test accuracy: 0.7799616456031799\n",
      "Epoch 1306/2000 - Loss: 2.7113430500030518 - Train accuracy: 0.5890699625015259 - Test accuracy: 0.7800575494766235\n",
      "Epoch 1307/2000 - Loss: 2.310598611831665 - Train accuracy: 0.5907957553863525 - Test accuracy: 0.7790987491607666\n",
      "Epoch 1308/2000 - Loss: 2.1643166542053223 - Train accuracy: 0.5979865789413452 - Test accuracy: 0.7796739935874939\n",
      "Epoch 1309/2000 - Loss: 2.28489089012146 - Train accuracy: 0.5924257040023804 - Test accuracy: 0.7801533937454224\n",
      "Epoch 1310/2000 - Loss: 2.4081690311431885 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7798658013343811\n",
      "Epoch 1311/2000 - Loss: 2.363002300262451 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7816874384880066\n",
      "Epoch 1312/2000 - Loss: 2.3202013969421387 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.7814956903457642\n",
      "Epoch 1313/2000 - Loss: 2.3739237785339355 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7814956903457642\n",
      "Epoch 1314/2000 - Loss: 2.1714839935302734 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1315/2000 - Loss: 2.385922431945801 - Train accuracy: 0.596452534198761 - Test accuracy: 0.781591534614563\n",
      "Epoch 1316/2000 - Loss: 2.2628226280212402 - Train accuracy: 0.5876318216323853 - Test accuracy: 0.781879186630249\n",
      "Epoch 1317/2000 - Loss: 2.251201629638672 - Train accuracy: 0.5871524214744568 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1318/2000 - Loss: 2.4427216053009033 - Train accuracy: 0.5884947180747986 - Test accuracy: 0.7829338312149048\n",
      "Epoch 1319/2000 - Loss: 2.2328383922576904 - Train accuracy: 0.5900287628173828 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1320/2000 - Loss: 2.3272106647491455 - Train accuracy: 0.5931926965713501 - Test accuracy: 0.7813997864723206\n",
      "Epoch 1321/2000 - Loss: 2.195295810699463 - Train accuracy: 0.596164882183075 - Test accuracy: 0.7800575494766235\n",
      "Epoch 1322/2000 - Loss: 2.256075620651245 - Train accuracy: 0.5950143933296204 - Test accuracy: 0.782837986946106\n",
      "Epoch 1323/2000 - Loss: 2.2760069370269775 - Train accuracy: 0.5985618233680725 - Test accuracy: 0.784467875957489\n",
      "Epoch 1324/2000 - Loss: 2.347857713699341 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7831255793571472\n",
      "Epoch 1325/2000 - Loss: 2.458153009414673 - Train accuracy: 0.5888782143592834 - Test accuracy: 0.781879186630249\n",
      "Epoch 1326/2000 - Loss: 2.401710033416748 - Train accuracy: 0.5971236824989319 - Test accuracy: 0.7813039422035217\n",
      "Epoch 1327/2000 - Loss: 2.297389268875122 - Train accuracy: 0.5880153179168701 - Test accuracy: 0.7821668386459351\n",
      "Epoch 1328/2000 - Loss: 2.278249502182007 - Train accuracy: 0.5925215482711792 - Test accuracy: 0.7831255793571472\n",
      "Epoch 1329/2000 - Loss: 2.5086135864257812 - Train accuracy: 0.5908916592597961 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1330/2000 - Loss: 2.151907444000244 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.7850431203842163\n",
      "Epoch 1331/2000 - Loss: 2.212614059448242 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1332/2000 - Loss: 2.0912506580352783 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.784467875957489\n",
      "Epoch 1333/2000 - Loss: 2.1168415546417236 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1334/2000 - Loss: 2.246419668197632 - Train accuracy: 0.5946308970451355 - Test accuracy: 0.785426676273346\n",
      "Epoch 1335/2000 - Loss: 2.287337064743042 - Train accuracy: 0.5925215482711792 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1336/2000 - Loss: 2.2572810649871826 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1337/2000 - Loss: 2.4568772315979004 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.781591534614563\n",
      "Epoch 1338/2000 - Loss: 2.595411777496338 - Train accuracy: 0.5815915465354919 - Test accuracy: 0.781591534614563\n",
      "Epoch 1339/2000 - Loss: 2.273477792739868 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.779290497303009\n",
      "Epoch 1340/2000 - Loss: 2.5444445610046387 - Train accuracy: 0.5849472880363464 - Test accuracy: 0.7789070010185242\n",
      "Epoch 1341/2000 - Loss: 2.393134832382202 - Train accuracy: 0.5867689251899719 - Test accuracy: 0.7787152528762817\n",
      "Epoch 1342/2000 - Loss: 2.1407623291015625 - Train accuracy: 0.5940555930137634 - Test accuracy: 0.7808245420455933\n",
      "Epoch 1343/2000 - Loss: 2.3634262084960938 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7822626829147339\n",
      "Epoch 1344/2000 - Loss: 2.1559972763061523 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1345/2000 - Loss: 2.4858672618865967 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1346/2000 - Loss: 2.2664148807525635 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.7822626829147339\n",
      "Epoch 1347/2000 - Loss: 2.251751184463501 - Train accuracy: 0.5927133560180664 - Test accuracy: 0.7804410457611084\n",
      "Epoch 1348/2000 - Loss: 2.196671724319458 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7807286381721497\n",
      "Epoch 1349/2000 - Loss: 2.5018913745880127 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.781879186630249\n",
      "Epoch 1350/2000 - Loss: 2.2413291931152344 - Train accuracy: 0.5946308970451355 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1351/2000 - Loss: 2.3188841342926025 - Train accuracy: 0.5931926965713501 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1352/2000 - Loss: 2.2270169258117676 - Train accuracy: 0.5954937934875488 - Test accuracy: 0.784180223941803\n",
      "Epoch 1353/2000 - Loss: 2.157667875289917 - Train accuracy: 0.5881112217903137 - Test accuracy: 0.7820709347724915\n",
      "Epoch 1354/2000 - Loss: 2.5103759765625 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7810162901878357\n",
      "Epoch 1355/2000 - Loss: 2.2608702182769775 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7794822454452515\n",
      "Epoch 1356/2000 - Loss: 2.254023313522339 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1357/2000 - Loss: 2.2574682235717773 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.784467875957489\n",
      "Epoch 1358/2000 - Loss: 2.424720287322998 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.784467875957489\n",
      "Epoch 1359/2000 - Loss: 2.2524781227111816 - Train accuracy: 0.5943432450294495 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1360/2000 - Loss: 2.217076063156128 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7868648171424866\n",
      "Epoch 1361/2000 - Loss: 2.3006479740142822 - Train accuracy: 0.5923298001289368 - Test accuracy: 0.784755527973175\n",
      "Epoch 1362/2000 - Loss: 2.358008861541748 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1363/2000 - Loss: 2.3955657482147217 - Train accuracy: 0.5929051041603088 - Test accuracy: 0.784755527973175\n",
      "Epoch 1364/2000 - Loss: 2.1468265056610107 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7834132313728333\n",
      "Epoch 1365/2000 - Loss: 2.2413690090179443 - Train accuracy: 0.5918504595756531 - Test accuracy: 0.7834132313728333\n",
      "Epoch 1366/2000 - Loss: 2.25091290473938 - Train accuracy: 0.5998082160949707 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1367/2000 - Loss: 2.3823840618133545 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1368/2000 - Loss: 2.1423468589782715 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1369/2000 - Loss: 2.355046272277832 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1370/2000 - Loss: 2.183481216430664 - Train accuracy: 0.6035474538803101 - Test accuracy: 0.7838926315307617\n",
      "Epoch 1371/2000 - Loss: 2.3493199348449707 - Train accuracy: 0.5880153179168701 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1372/2000 - Loss: 2.359381675720215 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1373/2000 - Loss: 2.3027632236480713 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1374/2000 - Loss: 2.238452196121216 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1375/2000 - Loss: 2.4990086555480957 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7866730690002441\n",
      "Epoch 1376/2000 - Loss: 2.1270434856414795 - Train accuracy: 0.584755539894104 - Test accuracy: 0.7849472761154175\n",
      "Epoch 1377/2000 - Loss: 2.5401601791381836 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.7861936688423157\n",
      "Epoch 1378/2000 - Loss: 2.504714012145996 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7861936688423157\n",
      "Epoch 1379/2000 - Loss: 2.483211040496826 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1380/2000 - Loss: 2.5651235580444336 - Train accuracy: 0.5869606733322144 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1381/2000 - Loss: 2.3236207962036133 - Train accuracy: 0.5960690379142761 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1382/2000 - Loss: 2.4332194328308105 - Train accuracy: 0.5958772897720337 - Test accuracy: 0.7820709347724915\n",
      "Epoch 1383/2000 - Loss: 2.363814353942871 - Train accuracy: 0.587344229221344 - Test accuracy: 0.7808245420455933\n",
      "Epoch 1384/2000 - Loss: 2.2874691486358643 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7799616456031799\n",
      "Epoch 1385/2000 - Loss: 2.3152003288269043 - Train accuracy: 0.5955896377563477 - Test accuracy: 0.7813039422035217\n",
      "Epoch 1386/2000 - Loss: 2.223937511444092 - Train accuracy: 0.5930009484291077 - Test accuracy: 0.7817833423614502\n",
      "Epoch 1387/2000 - Loss: 2.173137664794922 - Train accuracy: 0.6021093130111694 - Test accuracy: 0.7823585867881775\n",
      "Epoch 1388/2000 - Loss: 2.3493220806121826 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1389/2000 - Loss: 2.488961696624756 - Train accuracy: 0.5865771770477295 - Test accuracy: 0.7824544310569763\n",
      "Epoch 1390/2000 - Loss: 2.446713924407959 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1391/2000 - Loss: 2.302887201309204 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1392/2000 - Loss: 2.2528934478759766 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1393/2000 - Loss: 2.2002925872802734 - Train accuracy: 0.587056577205658 - Test accuracy: 0.7821668386459351\n",
      "Epoch 1394/2000 - Loss: 2.337440013885498 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1395/2000 - Loss: 2.2725954055786133 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1396/2000 - Loss: 2.2030067443847656 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1397/2000 - Loss: 2.4646565914154053 - Train accuracy: 0.5895493626594543 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1398/2000 - Loss: 2.3427252769470215 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.782837986946106\n",
      "Epoch 1399/2000 - Loss: 2.0812313556671143 - Train accuracy: 0.6008629202842712 - Test accuracy: 0.7819750905036926\n",
      "Epoch 1400/2000 - Loss: 2.5339338779449463 - Train accuracy: 0.5904122591018677 - Test accuracy: 0.785426676273346\n",
      "Epoch 1401/2000 - Loss: 2.361332893371582 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1402/2000 - Loss: 2.249330997467041 - Train accuracy: 0.5917545557022095 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1403/2000 - Loss: 2.128919839859009 - Train accuracy: 0.5988494753837585 - Test accuracy: 0.784180223941803\n",
      "Epoch 1404/2000 - Loss: 2.3854737281799316 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1405/2000 - Loss: 2.1252782344818115 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1406/2000 - Loss: 2.3390004634857178 - Train accuracy: 0.5929051041603088 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1407/2000 - Loss: 2.5424013137817383 - Train accuracy: 0.5906040072441101 - Test accuracy: 0.7881112098693848\n",
      "Epoch 1408/2000 - Loss: 2.2878408432006836 - Train accuracy: 0.5980824828147888 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1409/2000 - Loss: 2.304006338119507 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1410/2000 - Loss: 2.3194241523742676 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.7887823581695557\n",
      "Epoch 1411/2000 - Loss: 2.4060957431793213 - Train accuracy: 0.6023969054222107 - Test accuracy: 0.787344217300415\n",
      "Epoch 1412/2000 - Loss: 2.34118914604187 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1413/2000 - Loss: 2.2675623893737793 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1414/2000 - Loss: 2.226335287094116 - Train accuracy: 0.5949184894561768 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1415/2000 - Loss: 2.4625296592712402 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1416/2000 - Loss: 2.38246750831604 - Train accuracy: 0.5882070660591125 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1417/2000 - Loss: 2.1551380157470703 - Train accuracy: 0.5980824828147888 - Test accuracy: 0.7851390242576599\n",
      "Epoch 1418/2000 - Loss: 2.245729684829712 - Train accuracy: 0.5881112217903137 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1419/2000 - Loss: 2.396230459213257 - Train accuracy: 0.5908916592597961 - Test accuracy: 0.7849472761154175\n",
      "Epoch 1420/2000 - Loss: 2.273972272872925 - Train accuracy: 0.5860019326210022 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1421/2000 - Loss: 2.2858011722564697 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.784180223941803\n",
      "Epoch 1422/2000 - Loss: 2.146167039871216 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1423/2000 - Loss: 2.3382163047790527 - Train accuracy: 0.6017258167266846 - Test accuracy: 0.784467875957489\n",
      "Epoch 1424/2000 - Loss: 2.1938366889953613 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1425/2000 - Loss: 2.323277235031128 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1426/2000 - Loss: 2.2863149642944336 - Train accuracy: 0.5840843915939331 - Test accuracy: 0.7884947061538696\n",
      "Epoch 1427/2000 - Loss: 2.241837501525879 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7897411584854126\n",
      "Epoch 1428/2000 - Loss: 2.4326553344726562 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7865771651268005\n",
      "Epoch 1429/2000 - Loss: 2.286656379699707 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7850431203842163\n",
      "Epoch 1430/2000 - Loss: 2.205744981765747 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1431/2000 - Loss: 2.337353229522705 - Train accuracy: 0.5928092002868652 - Test accuracy: 0.7872483134269714\n",
      "Epoch 1432/2000 - Loss: 2.1721091270446777 - Train accuracy: 0.5949184894561768 - Test accuracy: 0.7875359654426575\n",
      "Epoch 1433/2000 - Loss: 2.375255823135376 - Train accuracy: 0.5953978896141052 - Test accuracy: 0.787056565284729\n",
      "Epoch 1434/2000 - Loss: 2.2578675746917725 - Train accuracy: 0.5890699625015259 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1435/2000 - Loss: 2.2789363861083984 - Train accuracy: 0.589645266532898 - Test accuracy: 0.785426676273346\n",
      "Epoch 1436/2000 - Loss: 2.2661893367767334 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1437/2000 - Loss: 2.3374106884002686 - Train accuracy: 0.5927133560180664 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1438/2000 - Loss: 2.1979522705078125 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1439/2000 - Loss: 2.338291645050049 - Train accuracy: 0.6015340089797974 - Test accuracy: 0.7834132313728333\n",
      "Epoch 1440/2000 - Loss: 2.1677756309509277 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7816874384880066\n",
      "Epoch 1441/2000 - Loss: 2.282494306564331 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1442/2000 - Loss: 2.209027051925659 - Train accuracy: 0.5975071787834167 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1443/2000 - Loss: 2.202390193939209 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1444/2000 - Loss: 2.3699023723602295 - Train accuracy: 0.6005752682685852 - Test accuracy: 0.784467875957489\n",
      "Epoch 1445/2000 - Loss: 2.408522844314575 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1446/2000 - Loss: 2.2537002563476562 - Train accuracy: 0.5904122591018677 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1447/2000 - Loss: 2.3097734451293945 - Train accuracy: 0.593863844871521 - Test accuracy: 0.784755527973175\n",
      "Epoch 1448/2000 - Loss: 2.269071578979492 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1449/2000 - Loss: 2.302476167678833 - Train accuracy: 0.5919463038444519 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1450/2000 - Loss: 2.3391942977905273 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1451/2000 - Loss: 2.4487996101379395 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1452/2000 - Loss: 2.249798536300659 - Train accuracy: 0.5949184894561768 - Test accuracy: 0.7882071137428284\n",
      "Epoch 1453/2000 - Loss: 2.233633279800415 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1454/2000 - Loss: 2.180985927581787 - Train accuracy: 0.5940555930137634 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1455/2000 - Loss: 2.3146426677703857 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1456/2000 - Loss: 2.3201165199279785 - Train accuracy: 0.6003835201263428 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1457/2000 - Loss: 2.3505825996398926 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7861936688423157\n",
      "Epoch 1458/2000 - Loss: 2.199422836303711 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1459/2000 - Loss: 2.2418978214263916 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1460/2000 - Loss: 2.3097615242004395 - Train accuracy: 0.5937680006027222 - Test accuracy: 0.7886864542961121\n",
      "Epoch 1461/2000 - Loss: 2.313600540161133 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7878235578536987\n",
      "Epoch 1462/2000 - Loss: 2.380446195602417 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7872483134269714\n",
      "Epoch 1463/2000 - Loss: 2.4078266620635986 - Train accuracy: 0.5894535183906555 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1464/2000 - Loss: 2.23483943939209 - Train accuracy: 0.5909875631332397 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1465/2000 - Loss: 2.516242504119873 - Train accuracy: 0.5918504595756531 - Test accuracy: 0.7881112098693848\n",
      "Epoch 1466/2000 - Loss: 2.36892032623291 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1467/2000 - Loss: 2.242831230163574 - Train accuracy: 0.5903164148330688 - Test accuracy: 0.7878235578536987\n",
      "Epoch 1468/2000 - Loss: 2.163917303085327 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7861936688423157\n",
      "Epoch 1469/2000 - Loss: 2.25994873046875 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1470/2000 - Loss: 2.346323013305664 - Train accuracy: 0.5954937934875488 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1471/2000 - Loss: 2.349993944168091 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1472/2000 - Loss: 2.166152238845825 - Train accuracy: 0.5895493626594543 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1473/2000 - Loss: 2.2757673263549805 - Train accuracy: 0.5929051041603088 - Test accuracy: 0.787344217300415\n",
      "Epoch 1474/2000 - Loss: 2.2535369396209717 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7871524691581726\n",
      "Epoch 1475/2000 - Loss: 2.423163414001465 - Train accuracy: 0.5923298001289368 - Test accuracy: 0.787056565284729\n",
      "Epoch 1476/2000 - Loss: 2.377699375152588 - Train accuracy: 0.5894535183906555 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1477/2000 - Loss: 2.312546968460083 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7875359654426575\n",
      "Epoch 1478/2000 - Loss: 2.203477621078491 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1479/2000 - Loss: 2.292802572250366 - Train accuracy: 0.5892617702484131 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1480/2000 - Loss: 2.2871978282928467 - Train accuracy: 0.5910834074020386 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1481/2000 - Loss: 2.3329904079437256 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1482/2000 - Loss: 2.3009700775146484 - Train accuracy: 0.5943432450294495 - Test accuracy: 0.7825503349304199\n",
      "Epoch 1483/2000 - Loss: 2.444319725036621 - Train accuracy: 0.591275155544281 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1484/2000 - Loss: 2.478907346725464 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7835091352462769\n",
      "Epoch 1485/2000 - Loss: 2.3541252613067627 - Train accuracy: 0.5931926965713501 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1486/2000 - Loss: 2.4726619720458984 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1487/2000 - Loss: 2.2954044342041016 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1488/2000 - Loss: 2.4215564727783203 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7843720316886902\n",
      "Epoch 1489/2000 - Loss: 2.184778928756714 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.784180223941803\n",
      "Epoch 1490/2000 - Loss: 2.308560371398926 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1491/2000 - Loss: 2.1294708251953125 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1492/2000 - Loss: 2.1954617500305176 - Train accuracy: 0.599328875541687 - Test accuracy: 0.785426676273346\n",
      "Epoch 1493/2000 - Loss: 2.20105242729187 - Train accuracy: 0.591562807559967 - Test accuracy: 0.784755527973175\n",
      "Epoch 1494/2000 - Loss: 2.440166473388672 - Train accuracy: 0.5943432450294495 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1495/2000 - Loss: 2.369980812072754 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1496/2000 - Loss: 2.5948925018310547 - Train accuracy: 0.5928092002868652 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1497/2000 - Loss: 2.392634630203247 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7786193490028381\n",
      "Epoch 1498/2000 - Loss: 2.2360925674438477 - Train accuracy: 0.5930968523025513 - Test accuracy: 0.7820709347724915\n",
      "Epoch 1499/2000 - Loss: 2.1926498413085938 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7840843796730042\n",
      "Epoch 1500/2000 - Loss: 2.2552027702331543 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7849472761154175\n",
      "Epoch 1501/2000 - Loss: 2.334609270095825 - Train accuracy: 0.5866730809211731 - Test accuracy: 0.7872483134269714\n",
      "Epoch 1502/2000 - Loss: 2.227717161178589 - Train accuracy: 0.5953978896141052 - Test accuracy: 0.7865771651268005\n",
      "Epoch 1503/2000 - Loss: 2.1788859367370605 - Train accuracy: 0.5973154306411743 - Test accuracy: 0.7849472761154175\n",
      "Epoch 1504/2000 - Loss: 2.4007019996643066 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1505/2000 - Loss: 2.235865592956543 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7851390242576599\n",
      "Epoch 1506/2000 - Loss: 2.365006446838379 - Train accuracy: 0.6034516096115112 - Test accuracy: 0.7843720316886902\n",
      "Epoch 1507/2000 - Loss: 2.288952112197876 - Train accuracy: 0.5836049914360046 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1508/2000 - Loss: 2.1705079078674316 - Train accuracy: 0.6003835201263428 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1509/2000 - Loss: 2.554198741912842 - Train accuracy: 0.5928092002868652 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1510/2000 - Loss: 2.3099052906036377 - Train accuracy: 0.5910834074020386 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1511/2000 - Loss: 2.2652244567871094 - Train accuracy: 0.5956855416297913 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1512/2000 - Loss: 2.4385721683502197 - Train accuracy: 0.5946308970451355 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1513/2000 - Loss: 2.322075605392456 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1514/2000 - Loss: 2.4874541759490967 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.784467875957489\n",
      "Epoch 1515/2000 - Loss: 2.3400607109069824 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1516/2000 - Loss: 2.4918456077575684 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1517/2000 - Loss: 2.2853193283081055 - Train accuracy: 0.5906999111175537 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1518/2000 - Loss: 2.3445074558258057 - Train accuracy: 0.5925215482711792 - Test accuracy: 0.784755527973175\n",
      "Epoch 1519/2000 - Loss: 2.2312533855438232 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.7852349281311035\n",
      "Epoch 1520/2000 - Loss: 2.3111400604248047 - Train accuracy: 0.5908916592597961 - Test accuracy: 0.785426676273346\n",
      "Epoch 1521/2000 - Loss: 2.4043591022491455 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.785426676273346\n",
      "Epoch 1522/2000 - Loss: 2.2903130054473877 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1523/2000 - Loss: 2.413999080657959 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1524/2000 - Loss: 2.185034990310669 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.7820709347724915\n",
      "Epoch 1525/2000 - Loss: 2.2124528884887695 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1526/2000 - Loss: 2.321011781692505 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7829338312149048\n",
      "Epoch 1527/2000 - Loss: 2.332014322280884 - Train accuracy: 0.6014381647109985 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1528/2000 - Loss: 2.2738037109375 - Train accuracy: 0.5919463038444519 - Test accuracy: 0.7834132313728333\n",
      "Epoch 1529/2000 - Loss: 2.3792812824249268 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1530/2000 - Loss: 2.3982272148132324 - Train accuracy: 0.5863854289054871 - Test accuracy: 0.7829338312149048\n",
      "Epoch 1531/2000 - Loss: 2.2478179931640625 - Train accuracy: 0.591562807559967 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1532/2000 - Loss: 2.178917646408081 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7843720316886902\n",
      "Epoch 1533/2000 - Loss: 2.274069309234619 - Train accuracy: 0.5958772897720337 - Test accuracy: 0.7821668386459351\n",
      "Epoch 1534/2000 - Loss: 2.4143121242523193 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1535/2000 - Loss: 2.281769275665283 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1536/2000 - Loss: 2.156499147415161 - Train accuracy: 0.5954937934875488 - Test accuracy: 0.7788110971450806\n",
      "Epoch 1537/2000 - Loss: 2.2280020713806152 - Train accuracy: 0.5933844447135925 - Test accuracy: 0.7804410457611084\n",
      "Epoch 1538/2000 - Loss: 2.176501512527466 - Train accuracy: 0.5887823700904846 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1539/2000 - Loss: 2.3638718128204346 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1540/2000 - Loss: 2.1645617485046387 - Train accuracy: 0.591562807559967 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1541/2000 - Loss: 2.1793434619903564 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7821668386459351\n",
      "Epoch 1542/2000 - Loss: 2.3329601287841797 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7811121940612793\n",
      "Epoch 1543/2000 - Loss: 2.3465259075164795 - Train accuracy: 0.5979865789413452 - Test accuracy: 0.7838926315307617\n",
      "Epoch 1544/2000 - Loss: 2.557323694229126 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1545/2000 - Loss: 2.090481758117676 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7850431203842163\n",
      "Epoch 1546/2000 - Loss: 2.3360798358917236 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1547/2000 - Loss: 2.4652254581451416 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.7845637798309326\n",
      "Epoch 1548/2000 - Loss: 2.3749961853027344 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7849472761154175\n",
      "Epoch 1549/2000 - Loss: 2.481053113937378 - Train accuracy: 0.5931926965713501 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1550/2000 - Loss: 2.1166017055511475 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1551/2000 - Loss: 2.49393367767334 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1552/2000 - Loss: 2.1739063262939453 - Train accuracy: 0.6017258167266846 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1553/2000 - Loss: 2.3540680408477783 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7872483134269714\n",
      "Epoch 1554/2000 - Loss: 2.256803512573242 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7883029580116272\n",
      "Epoch 1555/2000 - Loss: 2.529035806655884 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7878235578536987\n",
      "Epoch 1556/2000 - Loss: 2.2593994140625 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.789357602596283\n",
      "Epoch 1557/2000 - Loss: 2.40604305267334 - Train accuracy: 0.5902205109596252 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1558/2000 - Loss: 2.324737071990967 - Train accuracy: 0.589645266532898 - Test accuracy: 0.7875359654426575\n",
      "Epoch 1559/2000 - Loss: 2.29061222076416 - Train accuracy: 0.5913710594177246 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1560/2000 - Loss: 2.226280450820923 - Train accuracy: 0.6025887131690979 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1561/2000 - Loss: 2.232074499130249 - Train accuracy: 0.5954937934875488 - Test accuracy: 0.7837008833885193\n",
      "Epoch 1562/2000 - Loss: 2.3600826263427734 - Train accuracy: 0.5880153179168701 - Test accuracy: 0.7885906100273132\n",
      "Epoch 1563/2000 - Loss: 2.1581709384918213 - Train accuracy: 0.601629912853241 - Test accuracy: 0.7892617583274841\n",
      "Epoch 1564/2000 - Loss: 2.3374595642089844 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1565/2000 - Loss: 2.2877697944641113 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.787056565284729\n",
      "Epoch 1566/2000 - Loss: 2.2241897583007812 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1567/2000 - Loss: 2.3096182346343994 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1568/2000 - Loss: 2.322657346725464 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1569/2000 - Loss: 2.4690611362457275 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1570/2000 - Loss: 2.2723653316497803 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.784180223941803\n",
      "Epoch 1571/2000 - Loss: 2.2676374912261963 - Train accuracy: 0.5863854289054871 - Test accuracy: 0.7823585867881775\n",
      "Epoch 1572/2000 - Loss: 2.137561082839966 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7810162901878357\n",
      "Epoch 1573/2000 - Loss: 2.393721580505371 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7827420830726624\n",
      "Epoch 1574/2000 - Loss: 2.1480181217193604 - Train accuracy: 0.6021093130111694 - Test accuracy: 0.784467875957489\n",
      "Epoch 1575/2000 - Loss: 2.2654073238372803 - Train accuracy: 0.6004793643951416 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1576/2000 - Loss: 2.339510202407837 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7846596240997314\n",
      "Epoch 1577/2000 - Loss: 2.541145086288452 - Train accuracy: 0.593863844871521 - Test accuracy: 0.787344217300415\n",
      "Epoch 1578/2000 - Loss: 2.3820595741271973 - Train accuracy: 0.5987535715103149 - Test accuracy: 0.7812080383300781\n",
      "Epoch 1579/2000 - Loss: 2.4669275283813477 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.7810162901878357\n",
      "Epoch 1580/2000 - Loss: 2.24692702293396 - Train accuracy: 0.5927133560180664 - Test accuracy: 0.7824544310569763\n",
      "Epoch 1581/2000 - Loss: 2.243441343307495 - Train accuracy: 0.5877277255058289 - Test accuracy: 0.7832214832305908\n",
      "Epoch 1582/2000 - Loss: 2.2803075313568115 - Train accuracy: 0.6003835201263428 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1583/2000 - Loss: 2.1244876384735107 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1584/2000 - Loss: 2.4772679805755615 - Train accuracy: 0.5939597487449646 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1585/2000 - Loss: 2.385808229446411 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7825503349304199\n",
      "Epoch 1586/2000 - Loss: 2.3186631202697754 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1587/2000 - Loss: 2.416964054107666 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.7830297350883484\n",
      "Epoch 1588/2000 - Loss: 2.350235939025879 - Train accuracy: 0.5903164148330688 - Test accuracy: 0.781591534614563\n",
      "Epoch 1589/2000 - Loss: 2.276292562484741 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.7826462388038635\n",
      "Epoch 1590/2000 - Loss: 2.229788303375244 - Train accuracy: 0.5976989269256592 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1591/2000 - Loss: 2.398139476776123 - Train accuracy: 0.5980824828147888 - Test accuracy: 0.7831255793571472\n",
      "Epoch 1592/2000 - Loss: 2.1679975986480713 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.7819750905036926\n",
      "Epoch 1593/2000 - Loss: 2.54634165763855 - Train accuracy: 0.6012464165687561 - Test accuracy: 0.784467875957489\n",
      "Epoch 1594/2000 - Loss: 2.208435297012329 - Train accuracy: 0.6004793643951416 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1595/2000 - Loss: 2.22245454788208 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.7850431203842163\n",
      "Epoch 1596/2000 - Loss: 2.2281055450439453 - Train accuracy: 0.5940555930137634 - Test accuracy: 0.7838926315307617\n",
      "Epoch 1597/2000 - Loss: 2.24348783493042 - Train accuracy: 0.6034516096115112 - Test accuracy: 0.786768913269043\n",
      "Epoch 1598/2000 - Loss: 2.358106851577759 - Train accuracy: 0.6008629202842712 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1599/2000 - Loss: 2.248180866241455 - Train accuracy: 0.6014381647109985 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1600/2000 - Loss: 2.248100519180298 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7868648171424866\n",
      "Epoch 1601/2000 - Loss: 2.2651102542877197 - Train accuracy: 0.6013422608375549 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1602/2000 - Loss: 2.177220106124878 - Train accuracy: 0.5909875631332397 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1603/2000 - Loss: 2.205829620361328 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1604/2000 - Loss: 2.3126847743988037 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1605/2000 - Loss: 2.4225995540618896 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1606/2000 - Loss: 2.455692768096924 - Train accuracy: 0.5906040072441101 - Test accuracy: 0.7897411584854126\n",
      "Epoch 1607/2000 - Loss: 2.4190125465393066 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1608/2000 - Loss: 2.2124156951904297 - Train accuracy: 0.5924257040023804 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1609/2000 - Loss: 2.2824361324310303 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1610/2000 - Loss: 2.5006027221679688 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1611/2000 - Loss: 2.185208320617676 - Train accuracy: 0.5982742309570312 - Test accuracy: 0.784755527973175\n",
      "Epoch 1612/2000 - Loss: 2.2213351726531982 - Train accuracy: 0.5917545557022095 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1613/2000 - Loss: 2.3365285396575928 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7835091352462769\n",
      "Epoch 1614/2000 - Loss: 2.4342122077941895 - Train accuracy: 0.5918504595756531 - Test accuracy: 0.7833173274993896\n",
      "Epoch 1615/2000 - Loss: 2.3836236000061035 - Train accuracy: 0.5958772897720337 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1616/2000 - Loss: 2.181544065475464 - Train accuracy: 0.5905081629753113 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1617/2000 - Loss: 2.1075127124786377 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.785426676273346\n",
      "Epoch 1618/2000 - Loss: 2.297244071960449 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.786768913269043\n",
      "Epoch 1619/2000 - Loss: 2.3606510162353516 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1620/2000 - Loss: 2.0557830333709717 - Train accuracy: 0.596164882183075 - Test accuracy: 0.7872483134269714\n",
      "Epoch 1621/2000 - Loss: 2.3933827877044678 - Train accuracy: 0.6034516096115112 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1622/2000 - Loss: 2.2449951171875 - Train accuracy: 0.6030680537223816 - Test accuracy: 0.7834132313728333\n",
      "Epoch 1623/2000 - Loss: 2.3422603607177734 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1624/2000 - Loss: 2.317762851715088 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1625/2000 - Loss: 2.277310371398926 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1626/2000 - Loss: 2.126607894897461 - Train accuracy: 0.601629912853241 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1627/2000 - Loss: 2.4180173873901367 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1628/2000 - Loss: 2.3061025142669678 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7861936688423157\n",
      "Epoch 1629/2000 - Loss: 2.286600351333618 - Train accuracy: 0.5925215482711792 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1630/2000 - Loss: 2.3089253902435303 - Train accuracy: 0.5926174521446228 - Test accuracy: 0.7859060168266296\n",
      "Epoch 1631/2000 - Loss: 2.3964285850524902 - Train accuracy: 0.5944390892982483 - Test accuracy: 0.7842761278152466\n",
      "Epoch 1632/2000 - Loss: 2.3594324588775635 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7839884757995605\n",
      "Epoch 1633/2000 - Loss: 2.175685167312622 - Train accuracy: 0.5976030826568604 - Test accuracy: 0.7843720316886902\n",
      "Epoch 1634/2000 - Loss: 2.236268997192383 - Train accuracy: 0.5982742309570312 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1635/2000 - Loss: 2.4420783519744873 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1636/2000 - Loss: 2.3980159759521484 - Train accuracy: 0.5946308970451355 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1637/2000 - Loss: 2.358886241912842 - Train accuracy: 0.5954937934875488 - Test accuracy: 0.7857142686843872\n",
      "Epoch 1638/2000 - Loss: 2.1427698135375977 - Train accuracy: 0.5930968523025513 - Test accuracy: 0.7850431203842163\n",
      "Epoch 1639/2000 - Loss: 2.444124698638916 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1640/2000 - Loss: 2.384976387023926 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7862895727157593\n",
      "Epoch 1641/2000 - Loss: 2.2821385860443115 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.784755527973175\n",
      "Epoch 1642/2000 - Loss: 2.1512584686279297 - Train accuracy: 0.5955896377563477 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1643/2000 - Loss: 2.0891849994659424 - Train accuracy: 0.5979865789413452 - Test accuracy: 0.7836049795150757\n",
      "Epoch 1644/2000 - Loss: 2.402811288833618 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1645/2000 - Loss: 2.289077043533325 - Train accuracy: 0.6022051572799683 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1646/2000 - Loss: 2.273193359375 - Train accuracy: 0.5927133560180664 - Test accuracy: 0.7837967276573181\n",
      "Epoch 1647/2000 - Loss: 2.343492269515991 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1648/2000 - Loss: 2.2190606594085693 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7835091352462769\n",
      "Epoch 1649/2000 - Loss: 2.39875864982605 - Train accuracy: 0.593863844871521 - Test accuracy: 0.7824544310569763\n",
      "Epoch 1650/2000 - Loss: 2.5583231449127197 - Train accuracy: 0.600671112537384 - Test accuracy: 0.7848513722419739\n",
      "Epoch 1651/2000 - Loss: 2.2016448974609375 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7863854169845581\n",
      "Epoch 1652/2000 - Loss: 2.4489798545837402 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1653/2000 - Loss: 2.3018205165863037 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7851390242576599\n",
      "Epoch 1654/2000 - Loss: 2.242070198059082 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7860019207000732\n",
      "Epoch 1655/2000 - Loss: 2.3210253715515137 - Train accuracy: 0.5997123718261719 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1656/2000 - Loss: 2.1547696590423584 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1657/2000 - Loss: 2.343449592590332 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7888782620429993\n",
      "Epoch 1658/2000 - Loss: 2.301462411880493 - Train accuracy: 0.5933844447135925 - Test accuracy: 0.7891658544540405\n",
      "Epoch 1659/2000 - Loss: 2.215484142303467 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.789932906627655\n",
      "Epoch 1660/2000 - Loss: 2.408823251724243 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7908916473388672\n",
      "Epoch 1661/2000 - Loss: 2.2938759326934814 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.789932906627655\n",
      "Epoch 1662/2000 - Loss: 2.2977030277252197 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1663/2000 - Loss: 2.175851345062256 - Train accuracy: 0.5914669036865234 - Test accuracy: 0.7903164029121399\n",
      "Epoch 1664/2000 - Loss: 2.3757686614990234 - Train accuracy: 0.5976030826568604 - Test accuracy: 0.7898370027542114\n",
      "Epoch 1665/2000 - Loss: 2.2460505962371826 - Train accuracy: 0.5997123718261719 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1666/2000 - Loss: 2.186190605163574 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7887823581695557\n",
      "Epoch 1667/2000 - Loss: 2.4713447093963623 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7888782620429993\n",
      "Epoch 1668/2000 - Loss: 2.42138671875 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.7886864542961121\n",
      "Epoch 1669/2000 - Loss: 2.5153565406799316 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7883029580116272\n",
      "Epoch 1670/2000 - Loss: 2.421050548553467 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1671/2000 - Loss: 2.4144797325134277 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7892617583274841\n",
      "Epoch 1672/2000 - Loss: 2.213682174682617 - Train accuracy: 0.5951102375984192 - Test accuracy: 0.789645254611969\n",
      "Epoch 1673/2000 - Loss: 2.217586040496826 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.789932906627655\n",
      "Epoch 1674/2000 - Loss: 2.1526920795440674 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7903164029121399\n",
      "Epoch 1675/2000 - Loss: 2.3178482055664062 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7909875512123108\n",
      "Epoch 1676/2000 - Loss: 2.2750179767608643 - Train accuracy: 0.6004793643951416 - Test accuracy: 0.7906998991966248\n",
      "Epoch 1677/2000 - Loss: 2.30358624458313 - Train accuracy: 0.5939597487449646 - Test accuracy: 0.7889741063117981\n",
      "Epoch 1678/2000 - Loss: 2.2650136947631836 - Train accuracy: 0.5973154306411743 - Test accuracy: 0.7890700101852417\n",
      "Epoch 1679/2000 - Loss: 2.3948261737823486 - Train accuracy: 0.5906999111175537 - Test accuracy: 0.7907958030700684\n",
      "Epoch 1680/2000 - Loss: 2.140308141708374 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1681/2000 - Loss: 2.126319169998169 - Train accuracy: 0.5943432450294495 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1682/2000 - Loss: 2.279254913330078 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7907958030700684\n",
      "Epoch 1683/2000 - Loss: 2.1862430572509766 - Train accuracy: 0.5916586518287659 - Test accuracy: 0.789357602596283\n",
      "Epoch 1684/2000 - Loss: 2.3507680892944336 - Train accuracy: 0.5933844447135925 - Test accuracy: 0.7881112098693848\n",
      "Epoch 1685/2000 - Loss: 2.273465871810913 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7881112098693848\n",
      "Epoch 1686/2000 - Loss: 2.376649856567383 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7894535064697266\n",
      "Epoch 1687/2000 - Loss: 2.383118152618408 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.789357602596283\n",
      "Epoch 1688/2000 - Loss: 2.418574810028076 - Train accuracy: 0.6104506254196167 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1689/2000 - Loss: 2.244835615158081 - Train accuracy: 0.5982742309570312 - Test accuracy: 0.7894535064697266\n",
      "Epoch 1690/2000 - Loss: 2.3646366596221924 - Train accuracy: 0.5976030826568604 - Test accuracy: 0.7882071137428284\n",
      "Epoch 1691/2000 - Loss: 2.260990858078003 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7879194617271423\n",
      "Epoch 1692/2000 - Loss: 2.1940665245056152 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1693/2000 - Loss: 2.5947823524475098 - Train accuracy: 0.5930009484291077 - Test accuracy: 0.7892617583274841\n",
      "Epoch 1694/2000 - Loss: 2.321248769760132 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7877277135848999\n",
      "Epoch 1695/2000 - Loss: 2.4156739711761475 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.787056565284729\n",
      "Epoch 1696/2000 - Loss: 2.487785577774048 - Train accuracy: 0.5920422077178955 - Test accuracy: 0.7883988618850708\n",
      "Epoch 1697/2000 - Loss: 2.3488805294036865 - Train accuracy: 0.5950143933296204 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1698/2000 - Loss: 2.3664650917053223 - Train accuracy: 0.5987535715103149 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1699/2000 - Loss: 2.2978413105010986 - Train accuracy: 0.5947267413139343 - Test accuracy: 0.7871524691581726\n",
      "Epoch 1700/2000 - Loss: 2.403278350830078 - Train accuracy: 0.5923298001289368 - Test accuracy: 0.7874400615692139\n",
      "Epoch 1701/2000 - Loss: 2.275634288787842 - Train accuracy: 0.596164882183075 - Test accuracy: 0.7877277135848999\n",
      "Epoch 1702/2000 - Loss: 2.2961716651916504 - Train accuracy: 0.5988494753837585 - Test accuracy: 0.789357602596283\n",
      "Epoch 1703/2000 - Loss: 2.4054198265075684 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7915627956390381\n",
      "Epoch 1704/2000 - Loss: 2.3265864849090576 - Train accuracy: 0.6014381647109985 - Test accuracy: 0.792233943939209\n",
      "Epoch 1705/2000 - Loss: 2.4231626987457275 - Train accuracy: 0.5951102375984192 - Test accuracy: 0.791946291923523\n",
      "Epoch 1706/2000 - Loss: 2.3626649379730225 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7907958030700684\n",
      "Epoch 1707/2000 - Loss: 2.253587245941162 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7918504476547241\n",
      "Epoch 1708/2000 - Loss: 2.3275997638702393 - Train accuracy: 0.6017258167266846 - Test accuracy: 0.791946291923523\n",
      "Epoch 1709/2000 - Loss: 2.141040563583374 - Train accuracy: 0.5960690379142761 - Test accuracy: 0.791946291923523\n",
      "Epoch 1710/2000 - Loss: 2.1967275142669678 - Train accuracy: 0.5939597487449646 - Test accuracy: 0.7931926846504211\n",
      "Epoch 1711/2000 - Loss: 2.466458320617676 - Train accuracy: 0.603259801864624 - Test accuracy: 0.7921380400657654\n",
      "Epoch 1712/2000 - Loss: 2.347076654434204 - Train accuracy: 0.6026845574378967 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1713/2000 - Loss: 2.4049408435821533 - Train accuracy: 0.6024928092956543 - Test accuracy: 0.7906998991966248\n",
      "Epoch 1714/2000 - Loss: 2.162083148956299 - Train accuracy: 0.6003835201263428 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1715/2000 - Loss: 2.243981122970581 - Train accuracy: 0.5965484380722046 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1716/2000 - Loss: 2.3478713035583496 - Train accuracy: 0.596452534198761 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1717/2000 - Loss: 2.3351800441741943 - Train accuracy: 0.5949184894561768 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1718/2000 - Loss: 2.145594596862793 - Train accuracy: 0.6034516096115112 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1719/2000 - Loss: 2.1823501586914062 - Train accuracy: 0.6018216609954834 - Test accuracy: 0.7888782620429993\n",
      "Epoch 1720/2000 - Loss: 2.625678539276123 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1721/2000 - Loss: 2.222275733947754 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7909875512123108\n",
      "Epoch 1722/2000 - Loss: 2.286378860473633 - Train accuracy: 0.6050814986228943 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1723/2000 - Loss: 2.2486679553985596 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7909875512123108\n",
      "Epoch 1724/2000 - Loss: 2.455637216567993 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.7901246547698975\n",
      "Epoch 1725/2000 - Loss: 2.2874910831451416 - Train accuracy: 0.601629912853241 - Test accuracy: 0.7892617583274841\n",
      "Epoch 1726/2000 - Loss: 2.4320569038391113 - Train accuracy: 0.5987535715103149 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1727/2000 - Loss: 2.2922685146331787 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1728/2000 - Loss: 2.4158036708831787 - Train accuracy: 0.5883988738059998 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1729/2000 - Loss: 2.441563606262207 - Train accuracy: 0.603259801864624 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1730/2000 - Loss: 2.282015800476074 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7856184244155884\n",
      "Epoch 1731/2000 - Loss: 2.5835366249084473 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7883029580116272\n",
      "Epoch 1732/2000 - Loss: 2.2646632194519043 - Train accuracy: 0.6015340089797974 - Test accuracy: 0.7903164029121399\n",
      "Epoch 1733/2000 - Loss: 2.3563332557678223 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.7907958030700684\n",
      "Epoch 1734/2000 - Loss: 2.3475656509399414 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1735/2000 - Loss: 2.231175184249878 - Train accuracy: 0.5955896377563477 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1736/2000 - Loss: 2.483644723892212 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7889741063117981\n",
      "Epoch 1737/2000 - Loss: 2.1534078121185303 - Train accuracy: 0.5971236824989319 - Test accuracy: 0.789645254611969\n",
      "Epoch 1738/2000 - Loss: 2.288029432296753 - Train accuracy: 0.6036433577537537 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1739/2000 - Loss: 2.1732430458068848 - Train accuracy: 0.5976030826568604 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1740/2000 - Loss: 2.1073195934295654 - Train accuracy: 0.603259801864624 - Test accuracy: 0.789357602596283\n",
      "Epoch 1741/2000 - Loss: 2.5720508098602295 - Train accuracy: 0.6014381647109985 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1742/2000 - Loss: 2.450502634048462 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1743/2000 - Loss: 2.413865566253662 - Train accuracy: 0.5921380519866943 - Test accuracy: 0.7885906100273132\n",
      "Epoch 1744/2000 - Loss: 2.2746284008026123 - Train accuracy: 0.599041223526001 - Test accuracy: 0.787056565284729\n",
      "Epoch 1745/2000 - Loss: 2.2448203563690186 - Train accuracy: 0.5953978896141052 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1746/2000 - Loss: 2.282564401626587 - Train accuracy: 0.596164882183075 - Test accuracy: 0.7884947061538696\n",
      "Epoch 1747/2000 - Loss: 2.091679811477661 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7913710474967957\n",
      "Epoch 1748/2000 - Loss: 2.2133054733276367 - Train accuracy: 0.596164882183075 - Test accuracy: 0.791275143623352\n",
      "Epoch 1749/2000 - Loss: 2.3791165351867676 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1750/2000 - Loss: 2.0746541023254395 - Train accuracy: 0.5988494753837585 - Test accuracy: 0.7916586995124817\n",
      "Epoch 1751/2000 - Loss: 2.3863494396209717 - Train accuracy: 0.5950143933296204 - Test accuracy: 0.7915627956390381\n",
      "Epoch 1752/2000 - Loss: 2.3426408767700195 - Train accuracy: 0.5971236824989319 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1753/2000 - Loss: 2.206453800201416 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.7918504476547241\n",
      "Epoch 1754/2000 - Loss: 2.2246038913726807 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7921380400657654\n",
      "Epoch 1755/2000 - Loss: 2.2680296897888184 - Train accuracy: 0.6002876162528992 - Test accuracy: 0.7921380400657654\n",
      "Epoch 1756/2000 - Loss: 2.0915863513946533 - Train accuracy: 0.6039309501647949 - Test accuracy: 0.795110285282135\n",
      "Epoch 1757/2000 - Loss: 2.304119825363159 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1758/2000 - Loss: 2.272146224975586 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1759/2000 - Loss: 2.343595504760742 - Train accuracy: 0.5976989269256592 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1760/2000 - Loss: 2.353828191757202 - Train accuracy: 0.6041226983070374 - Test accuracy: 0.7889741063117981\n",
      "Epoch 1761/2000 - Loss: 2.2154934406280518 - Train accuracy: 0.593576192855835 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1762/2000 - Loss: 2.4409031867980957 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7909875512123108\n",
      "Epoch 1763/2000 - Loss: 2.2932822704315186 - Train accuracy: 0.5930968523025513 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1764/2000 - Loss: 2.5165066719055176 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1765/2000 - Loss: 2.216970682144165 - Train accuracy: 0.5971236824989319 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1766/2000 - Loss: 2.455653190612793 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1767/2000 - Loss: 2.3403453826904297 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.7936720848083496\n",
      "Epoch 1768/2000 - Loss: 2.2066779136657715 - Train accuracy: 0.5985618233680725 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1769/2000 - Loss: 2.3981311321258545 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7915627956390381\n",
      "Epoch 1770/2000 - Loss: 2.305602788925171 - Train accuracy: 0.6010546684265137 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1771/2000 - Loss: 2.271785259246826 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.7891658544540405\n",
      "Epoch 1772/2000 - Loss: 2.335575580596924 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7879194617271423\n",
      "Epoch 1773/2000 - Loss: 2.1220171451568604 - Train accuracy: 0.5951102375984192 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1774/2000 - Loss: 2.2200944423675537 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7886864542961121\n",
      "Epoch 1775/2000 - Loss: 2.521291971206665 - Train accuracy: 0.5922339558601379 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1776/2000 - Loss: 2.2620906829833984 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1777/2000 - Loss: 2.2994468212127686 - Train accuracy: 0.5906999111175537 - Test accuracy: 0.7918504476547241\n",
      "Epoch 1778/2000 - Loss: 2.3324942588806152 - Train accuracy: 0.5981783270835876 - Test accuracy: 0.7866730690002441\n",
      "Epoch 1779/2000 - Loss: 2.484605550765991 - Train accuracy: 0.5937680006027222 - Test accuracy: 0.7860978245735168\n",
      "Epoch 1780/2000 - Loss: 2.2621872425079346 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7869606614112854\n",
      "Epoch 1781/2000 - Loss: 2.1864147186279297 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7898370027542114\n",
      "Epoch 1782/2000 - Loss: 2.222309112548828 - Train accuracy: 0.6044103503227234 - Test accuracy: 0.7876318097114563\n",
      "Epoch 1783/2000 - Loss: 2.109456777572632 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7864813208580017\n",
      "Epoch 1784/2000 - Loss: 2.204772472381592 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1785/2000 - Loss: 2.362950325012207 - Train accuracy: 0.5897411108016968 - Test accuracy: 0.7865771651268005\n",
      "Epoch 1786/2000 - Loss: 2.318612575531006 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1787/2000 - Loss: 2.260460138320923 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7901246547698975\n",
      "Epoch 1788/2000 - Loss: 2.490520715713501 - Train accuracy: 0.5929051041603088 - Test accuracy: 0.792521595954895\n",
      "Epoch 1789/2000 - Loss: 2.3242878913879395 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7917545437812805\n",
      "Epoch 1790/2000 - Loss: 2.1878316402435303 - Train accuracy: 0.596740186214447 - Test accuracy: 0.7914669513702393\n",
      "Epoch 1791/2000 - Loss: 2.061811685562134 - Train accuracy: 0.6017258167266846 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1792/2000 - Loss: 2.2261993885040283 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7947267293930054\n",
      "Epoch 1793/2000 - Loss: 2.2151570320129395 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7956855297088623\n",
      "Epoch 1794/2000 - Loss: 2.326369285583496 - Train accuracy: 0.5936720967292786 - Test accuracy: 0.794822633266449\n",
      "Epoch 1795/2000 - Loss: 2.1667325496673584 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7942473888397217\n",
      "Epoch 1796/2000 - Loss: 2.2554032802581787 - Train accuracy: 0.6013422608375549 - Test accuracy: 0.793863832950592\n",
      "Epoch 1797/2000 - Loss: 2.199286460876465 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7956855297088623\n",
      "Epoch 1798/2000 - Loss: 2.337869167327881 - Train accuracy: 0.6049855947494507 - Test accuracy: 0.7958772778511047\n",
      "Epoch 1799/2000 - Loss: 2.360166311264038 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.794822633266449\n",
      "Epoch 1800/2000 - Loss: 2.1967787742614746 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1801/2000 - Loss: 2.469930410385132 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7921380400657654\n",
      "Epoch 1802/2000 - Loss: 2.221611738204956 - Train accuracy: 0.5900287628173828 - Test accuracy: 0.7932885885238647\n",
      "Epoch 1803/2000 - Loss: 2.1771693229675293 - Train accuracy: 0.6036433577537537 - Test accuracy: 0.7940555810928345\n",
      "Epoch 1804/2000 - Loss: 2.401167392730713 - Train accuracy: 0.603259801864624 - Test accuracy: 0.7936720848083496\n",
      "Epoch 1805/2000 - Loss: 2.2696728706359863 - Train accuracy: 0.6036433577537537 - Test accuracy: 0.7939597368240356\n",
      "Epoch 1806/2000 - Loss: 2.3310232162475586 - Train accuracy: 0.6033557057380676 - Test accuracy: 0.7935762405395508\n",
      "Epoch 1807/2000 - Loss: 2.2926056385040283 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.7935762405395508\n",
      "Epoch 1808/2000 - Loss: 2.270216703414917 - Train accuracy: 0.6054649949073792 - Test accuracy: 0.7935762405395508\n",
      "Epoch 1809/2000 - Loss: 2.308049440383911 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7936720848083496\n",
      "Epoch 1810/2000 - Loss: 2.3488190174102783 - Train accuracy: 0.5985618233680725 - Test accuracy: 0.792233943939209\n",
      "Epoch 1811/2000 - Loss: 2.2170345783233643 - Train accuracy: 0.6028763055801392 - Test accuracy: 0.7933844923973083\n",
      "Epoch 1812/2000 - Loss: 2.2719852924346924 - Train accuracy: 0.600671112537384 - Test accuracy: 0.792521595954895\n",
      "Epoch 1813/2000 - Loss: 2.298442840576172 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.789932906627655\n",
      "Epoch 1814/2000 - Loss: 2.250027656555176 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1815/2000 - Loss: 2.4785706996917725 - Train accuracy: 0.5980824828147888 - Test accuracy: 0.7920421957969666\n",
      "Epoch 1816/2000 - Loss: 2.284327745437622 - Train accuracy: 0.601917564868927 - Test accuracy: 0.7920421957969666\n",
      "Epoch 1817/2000 - Loss: 2.503817081451416 - Train accuracy: 0.6023969054222107 - Test accuracy: 0.7917545437812805\n",
      "Epoch 1818/2000 - Loss: 2.252781867980957 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7913710474967957\n",
      "Epoch 1819/2000 - Loss: 2.386946678161621 - Train accuracy: 0.5983700752258301 - Test accuracy: 0.789357602596283\n",
      "Epoch 1820/2000 - Loss: 2.2436182498931885 - Train accuracy: 0.6026845574378967 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1821/2000 - Loss: 2.303696870803833 - Train accuracy: 0.603259801864624 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1822/2000 - Loss: 2.5160064697265625 - Train accuracy: 0.5966442823410034 - Test accuracy: 0.789357602596283\n",
      "Epoch 1823/2000 - Loss: 2.2915074825286865 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1824/2000 - Loss: 2.347437858581543 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.7887823581695557\n",
      "Epoch 1825/2000 - Loss: 2.4594149589538574 - Train accuracy: 0.600671112537384 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1826/2000 - Loss: 2.1050455570220947 - Train accuracy: 0.5956855416297913 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1827/2000 - Loss: 2.092639446258545 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1828/2000 - Loss: 2.153052568435669 - Train accuracy: 0.5998082160949707 - Test accuracy: 0.7934803366661072\n",
      "Epoch 1829/2000 - Loss: 2.353149652481079 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1830/2000 - Loss: 2.3750360012054443 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7888782620429993\n",
      "Epoch 1831/2000 - Loss: 2.290679454803467 - Train accuracy: 0.5987535715103149 - Test accuracy: 0.7931926846504211\n",
      "Epoch 1832/2000 - Loss: 2.1566359996795654 - Train accuracy: 0.594151496887207 - Test accuracy: 0.7949184775352478\n",
      "Epoch 1833/2000 - Loss: 2.342369318008423 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.7946308851242065\n",
      "Epoch 1834/2000 - Loss: 2.231616973876953 - Train accuracy: 0.5984659790992737 - Test accuracy: 0.7934803366661072\n",
      "Epoch 1835/2000 - Loss: 2.3619272708892822 - Train accuracy: 0.5945349931716919 - Test accuracy: 0.7915627956390381\n",
      "Epoch 1836/2000 - Loss: 2.320594549179077 - Train accuracy: 0.6034516096115112 - Test accuracy: 0.792233943939209\n",
      "Epoch 1837/2000 - Loss: 2.273531675338745 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1838/2000 - Loss: 2.3590543270111084 - Train accuracy: 0.6044103503227234 - Test accuracy: 0.7949184775352478\n",
      "Epoch 1839/2000 - Loss: 2.287247657775879 - Train accuracy: 0.6012464165687561 - Test accuracy: 0.7961649298667908\n",
      "Epoch 1840/2000 - Loss: 2.1708106994628906 - Train accuracy: 0.60872483253479 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1841/2000 - Loss: 2.2332310676574707 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7932885885238647\n",
      "Epoch 1842/2000 - Loss: 2.242469549179077 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.797698974609375\n",
      "Epoch 1843/2000 - Loss: 2.393528938293457 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7963566780090332\n",
      "Epoch 1844/2000 - Loss: 2.2536559104919434 - Train accuracy: 0.5918504595756531 - Test accuracy: 0.7972195744514465\n",
      "Epoch 1845/2000 - Loss: 2.192403793334961 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1846/2000 - Loss: 2.072920322418213 - Train accuracy: 0.601917564868927 - Test accuracy: 0.7934803366661072\n",
      "Epoch 1847/2000 - Loss: 2.259856939315796 - Train accuracy: 0.5973154306411743 - Test accuracy: 0.7939597368240356\n",
      "Epoch 1848/2000 - Loss: 2.315368413925171 - Train accuracy: 0.5952061414718628 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1849/2000 - Loss: 2.0749318599700928 - Train accuracy: 0.5972195863723755 - Test accuracy: 0.7906040549278259\n",
      "Epoch 1850/2000 - Loss: 2.269192934036255 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.7929050922393799\n",
      "Epoch 1851/2000 - Loss: 2.225698709487915 - Train accuracy: 0.5976030826568604 - Test accuracy: 0.7942473888397217\n",
      "Epoch 1852/2000 - Loss: 2.3945999145507812 - Train accuracy: 0.6014381647109985 - Test accuracy: 0.7942473888397217\n",
      "Epoch 1853/2000 - Loss: 2.306243896484375 - Train accuracy: 0.5985618233680725 - Test accuracy: 0.7952061295509338\n",
      "Epoch 1854/2000 - Loss: 2.2802627086639404 - Train accuracy: 0.6051774024963379 - Test accuracy: 0.7956855297088623\n",
      "Epoch 1855/2000 - Loss: 2.2749955654144287 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7956855297088623\n",
      "Epoch 1856/2000 - Loss: 2.1616899967193604 - Train accuracy: 0.606807291507721 - Test accuracy: 0.796452522277832\n",
      "Epoch 1857/2000 - Loss: 2.2923080921173096 - Train accuracy: 0.6015340089797974 - Test accuracy: 0.7962607741355896\n",
      "Epoch 1858/2000 - Loss: 2.257096529006958 - Train accuracy: 0.601917564868927 - Test accuracy: 0.7960690259933472\n",
      "Epoch 1859/2000 - Loss: 2.3492255210876465 - Train accuracy: 0.6069990396499634 - Test accuracy: 0.7961649298667908\n",
      "Epoch 1860/2000 - Loss: 2.105118989944458 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7960690259933472\n",
      "Epoch 1861/2000 - Loss: 2.4247453212738037 - Train accuracy: 0.6012464165687561 - Test accuracy: 0.7940555810928345\n",
      "Epoch 1862/2000 - Loss: 2.403977632522583 - Train accuracy: 0.5951102375984192 - Test accuracy: 0.7895493507385254\n",
      "Epoch 1863/2000 - Loss: 2.2947919368743896 - Train accuracy: 0.5979865789413452 - Test accuracy: 0.7891658544540405\n",
      "Epoch 1864/2000 - Loss: 2.286651611328125 - Train accuracy: 0.601917564868927 - Test accuracy: 0.7883029580116272\n",
      "Epoch 1865/2000 - Loss: 2.3894529342651367 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7904122471809387\n",
      "Epoch 1866/2000 - Loss: 2.4309020042419434 - Train accuracy: 0.5975071787834167 - Test accuracy: 0.7900287508964539\n",
      "Epoch 1867/2000 - Loss: 2.565703868865967 - Train accuracy: 0.5940555930137634 - Test accuracy: 0.7880153656005859\n",
      "Epoch 1868/2000 - Loss: 2.199601411819458 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7855225205421448\n",
      "Epoch 1869/2000 - Loss: 2.447084903717041 - Train accuracy: 0.5911793112754822 - Test accuracy: 0.7853307723999023\n",
      "Epoch 1870/2000 - Loss: 2.286663293838501 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1871/2000 - Loss: 2.094667911529541 - Train accuracy: 0.5966442823410034 - Test accuracy: 0.7921380400657654\n",
      "Epoch 1872/2000 - Loss: 2.2770628929138184 - Train accuracy: 0.6018216609954834 - Test accuracy: 0.7930968403816223\n",
      "Epoch 1873/2000 - Loss: 2.4375975131988525 - Train accuracy: 0.5960690379142761 - Test accuracy: 0.7931926846504211\n",
      "Epoch 1874/2000 - Loss: 2.2466742992401123 - Train accuracy: 0.5927133560180664 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1875/2000 - Loss: 2.280932664871216 - Train accuracy: 0.5997123718261719 - Test accuracy: 0.7953978776931763\n",
      "Epoch 1876/2000 - Loss: 2.2351808547973633 - Train accuracy: 0.6002876162528992 - Test accuracy: 0.7932885885238647\n",
      "Epoch 1877/2000 - Loss: 2.1647121906280518 - Train accuracy: 0.5919463038444519 - Test accuracy: 0.7942473888397217\n",
      "Epoch 1878/2000 - Loss: 2.1557657718658447 - Train accuracy: 0.5934803485870361 - Test accuracy: 0.7950143814086914\n",
      "Epoch 1879/2000 - Loss: 2.177217721939087 - Train accuracy: 0.6020134091377258 - Test accuracy: 0.7906998991966248\n",
      "Epoch 1880/2000 - Loss: 2.3252971172332764 - Train accuracy: 0.5998082160949707 - Test accuracy: 0.7906998991966248\n",
      "Epoch 1881/2000 - Loss: 2.2575736045837402 - Train accuracy: 0.5953978896141052 - Test accuracy: 0.7961649298667908\n",
      "Epoch 1882/2000 - Loss: 2.485898494720459 - Train accuracy: 0.5973154306411743 - Test accuracy: 0.7913710474967957\n",
      "Epoch 1883/2000 - Loss: 2.2736477851867676 - Train accuracy: 0.5966442823410034 - Test accuracy: 0.7936720848083496\n",
      "Epoch 1884/2000 - Loss: 2.2608749866485596 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7898370027542114\n",
      "Epoch 1885/2000 - Loss: 2.3859007358551025 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7858101725578308\n",
      "Epoch 1886/2000 - Loss: 2.2374136447906494 - Train accuracy: 0.5974113345146179 - Test accuracy: 0.7902204990386963\n",
      "Epoch 1887/2000 - Loss: 2.1590991020202637 - Train accuracy: 0.6005752682685852 - Test accuracy: 0.7944391369819641\n",
      "Epoch 1888/2000 - Loss: 2.146493673324585 - Train accuracy: 0.5994247198104858 - Test accuracy: 0.7947267293930054\n",
      "Epoch 1889/2000 - Loss: 2.4519054889678955 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7930009365081787\n",
      "Epoch 1890/2000 - Loss: 2.2477779388427734 - Train accuracy: 0.6031639575958252 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1891/2000 - Loss: 2.2547075748443604 - Train accuracy: 0.6010546684265137 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1892/2000 - Loss: 2.298257827758789 - Train accuracy: 0.6035474538803101 - Test accuracy: 0.7957813739776611\n",
      "Epoch 1893/2000 - Loss: 2.200665235519409 - Train accuracy: 0.5987535715103149 - Test accuracy: 0.7943432331085205\n",
      "Epoch 1894/2000 - Loss: 2.2014107704162598 - Train accuracy: 0.5997123718261719 - Test accuracy: 0.7947267293930054\n",
      "Epoch 1895/2000 - Loss: 2.441152334213257 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.7945349812507629\n",
      "Epoch 1896/2000 - Loss: 2.1534876823425293 - Train accuracy: 0.6021093130111694 - Test accuracy: 0.7913710474967957\n",
      "Epoch 1897/2000 - Loss: 2.2157204151153564 - Train accuracy: 0.5942473411560059 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1898/2000 - Loss: 2.351482391357422 - Train accuracy: 0.5997123718261719 - Test accuracy: 0.7886864542961121\n",
      "Epoch 1899/2000 - Loss: 2.111283302307129 - Train accuracy: 0.6018216609954834 - Test accuracy: 0.7882071137428284\n",
      "Epoch 1900/2000 - Loss: 2.1948626041412354 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7909875512123108\n",
      "Epoch 1901/2000 - Loss: 2.40616774559021 - Train accuracy: 0.6000000238418579 - Test accuracy: 0.789645254611969\n",
      "Epoch 1902/2000 - Loss: 2.476330280303955 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.791946291923523\n",
      "Epoch 1903/2000 - Loss: 2.4379866123199463 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1904/2000 - Loss: 2.3857383728027344 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1905/2000 - Loss: 2.4450788497924805 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7911792993545532\n",
      "Epoch 1906/2000 - Loss: 2.3173410892486572 - Train accuracy: 0.599328875541687 - Test accuracy: 0.791275143623352\n",
      "Epoch 1907/2000 - Loss: 2.289114236831665 - Train accuracy: 0.6020134091377258 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1908/2000 - Loss: 2.2959492206573486 - Train accuracy: 0.6007670164108276 - Test accuracy: 0.7936720848083496\n",
      "Epoch 1909/2000 - Loss: 2.2542662620544434 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7931926846504211\n",
      "Epoch 1910/2000 - Loss: 2.2472681999206543 - Train accuracy: 0.6024928092956543 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1911/2000 - Loss: 2.2146008014678955 - Train accuracy: 0.604218602180481 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1912/2000 - Loss: 2.209336519241333 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7914669513702393\n",
      "Epoch 1913/2000 - Loss: 2.282593250274658 - Train accuracy: 0.5999041199684143 - Test accuracy: 0.791946291923523\n",
      "Epoch 1914/2000 - Loss: 2.306156635284424 - Train accuracy: 0.5963566899299622 - Test accuracy: 0.7934803366661072\n",
      "Epoch 1915/2000 - Loss: 2.4357352256774902 - Train accuracy: 0.6041226983070374 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1916/2000 - Loss: 2.1554675102233887 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1917/2000 - Loss: 2.323380470275879 - Train accuracy: 0.6030680537223816 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1918/2000 - Loss: 2.176011562347412 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7947267293930054\n",
      "Epoch 1919/2000 - Loss: 2.3557422161102295 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7937679886817932\n",
      "Epoch 1920/2000 - Loss: 2.3705930709838867 - Train accuracy: 0.5948226451873779 - Test accuracy: 0.7933844923973083\n",
      "Epoch 1921/2000 - Loss: 2.2398154735565186 - Train accuracy: 0.6057526469230652 - Test accuracy: 0.7952061295509338\n",
      "Epoch 1922/2000 - Loss: 2.2381744384765625 - Train accuracy: 0.6031639575958252 - Test accuracy: 0.7945349812507629\n",
      "Epoch 1923/2000 - Loss: 2.3530936241149902 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7954937815666199\n",
      "Epoch 1924/2000 - Loss: 2.3991079330444336 - Train accuracy: 0.5976989269256592 - Test accuracy: 0.7967401742935181\n",
      "Epoch 1925/2000 - Loss: 2.267883062362671 - Train accuracy: 0.6027804613113403 - Test accuracy: 0.7949184775352478\n",
      "Epoch 1926/2000 - Loss: 2.2117860317230225 - Train accuracy: 0.6024928092956543 - Test accuracy: 0.7943432331085205\n",
      "Epoch 1927/2000 - Loss: 2.4435312747955322 - Train accuracy: 0.6024928092956543 - Test accuracy: 0.7950143814086914\n",
      "Epoch 1928/2000 - Loss: 2.459989070892334 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7984659671783447\n",
      "Epoch 1929/2000 - Loss: 2.2704761028289795 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.7987536191940308\n",
      "Epoch 1930/2000 - Loss: 2.161255359649658 - Train accuracy: 0.6048897504806519 - Test accuracy: 0.7985618114471436\n",
      "Epoch 1931/2000 - Loss: 2.4814226627349854 - Train accuracy: 0.5991371273994446 - Test accuracy: 0.7956855297088623\n",
      "Epoch 1932/2000 - Loss: 2.2577085494995117 - Train accuracy: 0.6001917719841003 - Test accuracy: 0.7955896258354187\n",
      "Epoch 1933/2000 - Loss: 2.288912773132324 - Train accuracy: 0.5985618233680725 - Test accuracy: 0.7954937815666199\n",
      "Epoch 1934/2000 - Loss: 2.249441623687744 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7953978776931763\n",
      "Epoch 1935/2000 - Loss: 2.33160138130188 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7979865670204163\n",
      "Epoch 1936/2000 - Loss: 2.2601115703582764 - Train accuracy: 0.599041223526001 - Test accuracy: 0.7971236705780029\n",
      "Epoch 1937/2000 - Loss: 2.1593518257141113 - Train accuracy: 0.608437180519104 - Test accuracy: 0.7966442704200745\n",
      "Epoch 1938/2000 - Loss: 2.302363157272339 - Train accuracy: 0.599328875541687 - Test accuracy: 0.7941514849662781\n",
      "Epoch 1939/2000 - Loss: 2.045680284500122 - Train accuracy: 0.6035474538803101 - Test accuracy: 0.7947267293930054\n",
      "Epoch 1940/2000 - Loss: 2.5224390029907227 - Train accuracy: 0.601629912853241 - Test accuracy: 0.7957813739776611\n",
      "Epoch 1941/2000 - Loss: 2.3628573417663574 - Train accuracy: 0.6028763055801392 - Test accuracy: 0.7954937815666199\n",
      "Epoch 1942/2000 - Loss: 2.0648374557495117 - Train accuracy: 0.601917564868927 - Test accuracy: 0.7958772778511047\n",
      "Epoch 1943/2000 - Loss: 2.2088003158569336 - Train accuracy: 0.603259801864624 - Test accuracy: 0.7950143814086914\n",
      "Epoch 1944/2000 - Loss: 2.235870361328125 - Train accuracy: 0.5930009484291077 - Test accuracy: 0.7932885885238647\n",
      "Epoch 1945/2000 - Loss: 2.1991121768951416 - Train accuracy: 0.6069990396499634 - Test accuracy: 0.7955896258354187\n",
      "Epoch 1946/2000 - Loss: 2.1367921829223633 - Train accuracy: 0.6057526469230652 - Test accuracy: 0.7954937815666199\n",
      "Epoch 1947/2000 - Loss: 2.4807794094085693 - Train accuracy: 0.6050814986228943 - Test accuracy: 0.7950143814086914\n",
      "Epoch 1948/2000 - Loss: 2.222466468811035 - Train accuracy: 0.6050814986228943 - Test accuracy: 0.7931926846504211\n",
      "Epoch 1949/2000 - Loss: 2.2783701419830322 - Train accuracy: 0.6013422608375549 - Test accuracy: 0.7923297882080078\n",
      "Epoch 1950/2000 - Loss: 2.259629726409912 - Train accuracy: 0.6046020984649658 - Test accuracy: 0.792521595954895\n",
      "Epoch 1951/2000 - Loss: 2.370759963989258 - Train accuracy: 0.5994247198104858 - Test accuracy: 0.7917545437812805\n",
      "Epoch 1952/2000 - Loss: 2.3325953483581543 - Train accuracy: 0.6030680537223816 - Test accuracy: 0.7935762405395508\n",
      "Epoch 1953/2000 - Loss: 2.3592398166656494 - Train accuracy: 0.5978906750679016 - Test accuracy: 0.7943432331085205\n",
      "Epoch 1954/2000 - Loss: 2.14665150642395 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7952061295509338\n",
      "Epoch 1955/2000 - Loss: 2.4950637817382812 - Train accuracy: 0.5962607860565186 - Test accuracy: 0.7927133440971375\n",
      "Epoch 1956/2000 - Loss: 2.179583787918091 - Train accuracy: 0.5956855416297913 - Test accuracy: 0.7945349812507629\n",
      "Epoch 1957/2000 - Loss: 2.370547294616699 - Train accuracy: 0.6036433577537537 - Test accuracy: 0.8011505007743835\n",
      "Epoch 1958/2000 - Loss: 2.2266151905059814 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7978907227516174\n",
      "Epoch 1959/2000 - Loss: 2.3737874031066895 - Train accuracy: 0.6000000238418579 - Test accuracy: 0.797411322593689\n",
      "Epoch 1960/2000 - Loss: 2.405139684677124 - Train accuracy: 0.5969319343566895 - Test accuracy: 0.7945349812507629\n",
      "Epoch 1961/2000 - Loss: 2.116520404815674 - Train accuracy: 0.6047938466072083 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1962/2000 - Loss: 2.2400736808776855 - Train accuracy: 0.5970277786254883 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1963/2000 - Loss: 2.4002840518951416 - Train accuracy: 0.5996164679527283 - Test accuracy: 0.7939597368240356\n",
      "Epoch 1964/2000 - Loss: 2.3939945697784424 - Train accuracy: 0.6028763055801392 - Test accuracy: 0.793863832950592\n",
      "Epoch 1965/2000 - Loss: 2.480384588241577 - Train accuracy: 0.5995206236839294 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1966/2000 - Loss: 2.3252522945404053 - Train accuracy: 0.6044103503227234 - Test accuracy: 0.7881112098693848\n",
      "Epoch 1967/2000 - Loss: 2.335571527481079 - Train accuracy: 0.6011505126953125 - Test accuracy: 0.7891658544540405\n",
      "Epoch 1968/2000 - Loss: 2.244497299194336 - Train accuracy: 0.5977948307991028 - Test accuracy: 0.7934803366661072\n",
      "Epoch 1969/2000 - Loss: 2.100372076034546 - Train accuracy: 0.6054649949073792 - Test accuracy: 0.7949184775352478\n",
      "Epoch 1970/2000 - Loss: 2.322384834289551 - Train accuracy: 0.5976989269256592 - Test accuracy: 0.7928091883659363\n",
      "Epoch 1971/2000 - Loss: 2.1576273441314697 - Train accuracy: 0.6004793643951416 - Test accuracy: 0.7935762405395508\n",
      "Epoch 1972/2000 - Loss: 2.2686550617218018 - Train accuracy: 0.6023010611534119 - Test accuracy: 0.7923297882080078\n",
      "Epoch 1973/2000 - Loss: 2.189440965652466 - Train accuracy: 0.5932886004447937 - Test accuracy: 0.7926174402236938\n",
      "Epoch 1974/2000 - Loss: 2.3806512355804443 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.7901246547698975\n",
      "Epoch 1975/2000 - Loss: 2.40724515914917 - Train accuracy: 0.5988494753837585 - Test accuracy: 0.7910833954811096\n",
      "Epoch 1976/2000 - Loss: 2.296135902404785 - Train accuracy: 0.6011505126953125 - Test accuracy: 0.7939597368240356\n",
      "Epoch 1977/2000 - Loss: 2.101181983947754 - Train accuracy: 0.6009587645530701 - Test accuracy: 0.7962607741355896\n",
      "Epoch 1978/2000 - Loss: 2.246718645095825 - Train accuracy: 0.6015340089797974 - Test accuracy: 0.7965484261512756\n",
      "Epoch 1979/2000 - Loss: 2.121370553970337 - Train accuracy: 0.5989453792572021 - Test accuracy: 0.7967401742935181\n",
      "Epoch 1980/2000 - Loss: 2.459095001220703 - Train accuracy: 0.604218602180481 - Test accuracy: 0.7937679886817932\n",
      "Epoch 1981/2000 - Loss: 2.2588906288146973 - Train accuracy: 0.5959731340408325 - Test accuracy: 0.7915627956390381\n",
      "Epoch 1982/2000 - Loss: 2.3295137882232666 - Train accuracy: 0.5994247198104858 - Test accuracy: 0.7916586995124817\n",
      "Epoch 1983/2000 - Loss: 2.3057072162628174 - Train accuracy: 0.599328875541687 - Test accuracy: 0.791946291923523\n",
      "Epoch 1984/2000 - Loss: 2.441429376602173 - Train accuracy: 0.6046020984649658 - Test accuracy: 0.7959731817245483\n",
      "Epoch 1985/2000 - Loss: 2.3220651149749756 - Train accuracy: 0.5968360304832458 - Test accuracy: 0.7953020334243774\n",
      "Epoch 1986/2000 - Loss: 2.393857717514038 - Train accuracy: 0.5992329716682434 - Test accuracy: 0.7967401742935181\n",
      "Epoch 1987/2000 - Loss: 2.2193281650543213 - Train accuracy: 0.5986577272415161 - Test accuracy: 0.7944391369819641\n",
      "Epoch 1988/2000 - Loss: 2.4880242347717285 - Train accuracy: 0.6000958681106567 - Test accuracy: 0.7930968403816223\n",
      "Epoch 1989/2000 - Loss: 2.1143240928649902 - Train accuracy: 0.607094943523407 - Test accuracy: 0.7924256920814514\n",
      "Epoch 1990/2000 - Loss: 2.0966038703918457 - Train accuracy: 0.6000000238418579 - Test accuracy: 0.7945349812507629\n",
      "Epoch 1991/2000 - Loss: 2.1642799377441406 - Train accuracy: 0.6062320470809937 - Test accuracy: 0.7940555810928345\n",
      "Epoch 1992/2000 - Loss: 2.207993984222412 - Train accuracy: 0.5955896377563477 - Test accuracy: 0.7973154187202454\n",
      "Epoch 1993/2000 - Loss: 2.1817398071289062 - Train accuracy: 0.6056567430496216 - Test accuracy: 0.7966442704200745\n",
      "Epoch 1994/2000 - Loss: 2.1950325965881348 - Train accuracy: 0.6040268540382385 - Test accuracy: 0.7917545437812805\n",
      "Epoch 1995/2000 - Loss: 2.4209563732147217 - Train accuracy: 0.5976989269256592 - Test accuracy: 0.7920421957969666\n",
      "Epoch 1996/2000 - Loss: 2.130406141281128 - Train accuracy: 0.6069031357765198 - Test accuracy: 0.7978907227516174\n",
      "Epoch 1997/2000 - Loss: 2.149345874786377 - Train accuracy: 0.5953019857406616 - Test accuracy: 0.7977948188781738\n",
      "Epoch 1998/2000 - Loss: 2.19171142578125 - Train accuracy: 0.5957813858985901 - Test accuracy: 0.7980824708938599\n",
      "Epoch 1999/2000 - Loss: 2.0225536823272705 - Train accuracy: 0.6044103503227234 - Test accuracy: 0.7957813739776611\n",
      "0.7957813739776611\n"
     ]
    }
   ],
   "source": [
    "MODEL_NEURONS = 100\n",
    "MODEL_EPOCHS= 2000\n",
    "MODEL_LR = 1.0e-1\n",
    "MODEL_LABEL_NUM = len(np.unique(y_train))\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(x_train.shape[1], n_neurons)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_neurons, MODEL_LABEL_NUM)\n",
    "        self.ac2 = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        logits = self.fc2(x)\n",
    "        x = self.ac2(logits)\n",
    "        return x\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train).float()\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "x_test_tensor = torch.tensor(x_test).float()\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "label_onehot = torch.zeros(y_train.shape[0], MODEL_LABEL_NUM)\n",
    "label_onehot.scatter_(1, y_train_tensor.unsqueeze(1), 1)\n",
    "class_weights = 1.0/label_onehot.mean(axis=0)\n",
    "\n",
    "network = MLP(MODEL_NEURONS)\n",
    "loss = torch.nn.BCELoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=MODEL_LR)#, weight_decay=1e-3)\n",
    "\n",
    "#MODEL_EPOCHS = 0 # Untrained\n",
    "for epoch in range(MODEL_EPOCHS):\n",
    "    x_train_tensor_masked = masker(torch.tensor(x_train).float()) # A different set of RandomMasks for each batch\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    preds = network(x_train_tensor_masked)\n",
    "    label_onehot = torch.zeros(y_train.shape[0], MODEL_LABEL_NUM)\n",
    "    label_onehot.scatter_(1, y_train_tensor.unsqueeze(1), 1)\n",
    "    loss_value = loss(preds, label_onehot)\n",
    "    loss_value.backward()        \n",
    "    optimizer.step()\n",
    "\n",
    "    train_accuracy = (preds.argmax(dim=1) == y_train_tensor).float().mean() \n",
    "\n",
    "    test_preds = network.forward(x_test_tensor)        \n",
    "    test_accuracy = (test_preds.argmax(dim=1) == y_test_tensor).float().mean() \n",
    "    print(f'Epoch {epoch}/{MODEL_EPOCHS} - Loss: {loss_value.item()} - Train accuracy: {train_accuracy} - Test accuracy: {test_accuracy}')  \n",
    "    #if test_accuracy > 0.6: # Undertrained\n",
    "    #    break\n",
    "\n",
    "test_preds = network.forward(x_test_tensor)        \n",
    "test_accuracy = (test_preds.argmax(dim=1) == y_test_tensor).float().mean() \n",
    "print(test_accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(network.state_dict(), os.path.join(PROJ_DIR,'assets','models','avila-ood-mean-mlp.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
