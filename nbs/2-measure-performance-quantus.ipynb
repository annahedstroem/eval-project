{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure performance\n",
    "This notebook loads a file with precomputed measures for metrics available in Quantus (*faithfulness_correlations* & *monotonicity_correlations*) for a set of rankings for a given instance of the dataset and measures the performance of the different alternative measures\n",
    "\n",
    "# There's a .py version for this script in the src folder which is the one that should be used to generate the files:\n",
    "`src/2-measure-performance-quantus.py`\n",
    "\n",
    "## 1. Load libraries, model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row\n",
      "label\n",
      "rankings\n",
      "faithfulness_correlations\n",
      "faithfulness_correlations_inv\n",
      "monotonicity_correlations_inv\n",
      "pixel_flippings\n",
      "qmeans\n",
      "qmean_invs\n",
      "qmean_bas\n",
      "qargmaxs\n",
      "qargmax_invs\n",
      "qargmax_bas\n",
      "qaucs\n",
      "qauc_invs\n",
      "qauc_bas\n",
      "output_curves\n",
      "is_hit_curves\n",
      "output_curves_inv\n",
      "is_hit_curves_inv\n",
      "output_curves_bas\n",
      "is_hit_curves_bas\n"
     ]
    }
   ],
   "source": [
    "FILENAME = 'avila_11_measures.npz'\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "\n",
    "inv_lookup = np.load(os.path.join(PROJ_DIR, 'results', 'avila_permutations_inv_lookup.npz'))['inv_lookup']\n",
    "\n",
    "faithfulness_correlations = data['faithfulness_correlations']\n",
    "faithfulness_correlations_basX = []\n",
    "faithfulness_correlations_inv = faithfulness_correlations - data['faithfulness_correlations_inv']\n",
    "monotonicity_correlations = data['monotonicity_correlations']\n",
    "monotonicity_correlations_basX = []\n",
    "monotonicity_correlations_inv = data['monotonicity_correlations_inv']\n",
    "\n",
    "# Compute the baseline with varying number of samples\n",
    "def compute_qbas(measure, num_samples):\n",
    "    random_indices = np.random.randint(0,  measure.shape[0], (measure.shape[0], num_samples))\n",
    "    random_qmeans = measure[random_indices]\n",
    "    mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "    # First way to deal with std==0; add some epsilon\n",
    "    #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "    # Second way to deal with std==0; ignore std (divide by 1)\n",
    "    std = np.std(random_qmeans, axis=1)\n",
    "    std[std==0] = 1\n",
    "\n",
    "    # Always ignore std\n",
    "    std=1\n",
    "    return (measure - mean) / std\n",
    "\n",
    "for i in range(1,11):\n",
    "    faithfulness_correlations_basX.append(compute_qbas(faithfulness_correlations, i))\n",
    "    monotonicity_correlations_basX.append(compute_qbas(monotonicity_correlations, i))\n",
    "\n",
    "# Compute the qinv version\n",
    "def compute_qinv(measure, inv_lookup):\n",
    "    return measure - measure[inv_lookup]\n",
    "\n",
    "faithfulness_correlations_inv = compute_qinv(faithfulness_correlations, inv_lookup)\n",
    "monotonicity_correlations_inv = compute_qinv(monotonicity_correlations, inv_lookup)\n",
    "\n",
    "MEASURES = [('faithfulness_correlations', faithfulness_correlations, faithfulness_correlations_basX, faithfulness_correlations_inv), ('monotonicity_correlations', monotonicity_correlations, monotonicity_correlations_basX, monotonicity_correlations_inv)]\n",
    "\n",
    "level_indices_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    # Compute z-score for stratification\n",
    "    q_mean = np.mean(q)\n",
    "    q_std = np.std(q)\n",
    "    z_scores = ((q - q_mean) / q_std).flatten()\n",
    "\n",
    "    # Stratify z-scores to be able to compare performance on different parts of the spectrum\n",
    "    indices = np.arange(z_scores.shape[0])\n",
    "    z_scores_numbered = np.vstack((z_scores, indices))\n",
    "    level_indices = []\n",
    "    boundaries = [float('-inf'), 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "    for i in range(1,len(boundaries)+1):\n",
    "        bottom_limit = boundaries[i-1]\n",
    "        top_limit = float('inf')\n",
    "        if i < len(boundaries):\n",
    "            top_limit = boundaries[i]\n",
    "        level_indices.append((z_scores_numbered[:,np.logical_and(bottom_limit<=z_scores, z_scores<top_limit)][1,:].astype(int),(bottom_limit, top_limit)))\n",
    "    \n",
    "    level_indices_by_measure[name] = level_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0040658   0.19762787  0.0938892  -0.4524167  -0.38390726 -0.56621015\n",
      " -0.22212431 -0.33148053  0.28807935  0.07943838]\n",
      "[ 0.21191725  0.7692199   0.37717423 -0.11780098 -0.23927434 -0.36162317\n",
      " -0.4605855  -0.4075103  -0.20984188  0.6636807 ]\n",
      "[-0.25803754 -0.09681147 -0.81192577  0.12770975  0.2759414   0.34141186\n",
      " -0.13912895  0.13981551  0.10794356  0.02536194]\n",
      "[999 998 997 996 995 994 993 992 991 990]\n"
     ]
    }
   ],
   "source": [
    "print(faithfulness_correlations[:10])\n",
    "print(faithfulness_correlations_inv[:10])\n",
    "print(faithfulness_correlations[inv_lookup[:10]])\n",
    "print(inv_lookup[-1000:-990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f - mean:-0.0000 std:0.3545\n",
      "f_inv - mean:0.0001 std:0.3545\n",
      "spearman -0.14381271647166918\n",
      "pearson -0.14575276887313865\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "f = data['faithfulness_correlations']\n",
    "f_inv = data['faithfulness_correlations_inv']\n",
    "\n",
    "print(f'f - mean:{np.mean(f):.4f} std:{np.std(f):.4f}')\n",
    "print(f'f_inv - mean:{np.mean(f_inv):.4f} std:{np.std(f_inv):.4f}')\n",
    "print(f'spearman {spearmanr(f, f_inv)[0]}')\n",
    "print(f'pearson {pearsonr(f, f_inv)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11841377\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(f_inv[np.where(f>0.8)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure performance\n",
    "### 2.1 Order preservation\n",
    " 1. The issue with using qmean directly is that it doesn't have a fixed scale and you don't get an idea of how good your explanation is compared to other explanations\n",
    " 2. To address this, ideally you would determine the distribution of all qmeans and then compute the z-score. That's very costly, so you either:\n",
    "    1. Estimate the qmeans distribution with X samples $\\rightarrow$ qbasX\n",
    "    2. Calculate an alternative to the z-index directly $\\rightarrow$ qinv\n",
    " 3. The problem with both alternatives is that you adulterate the value of your original qmean measurement, so you may end up in a situation where $qmean_i<qmean_j$ but $qinv_i<qinv_j$, which is undesirable\n",
    " 4. Hence, we measure how many times that happens for each measure.\n",
    "\n",
    " (This may be measuring the same as Pearson correlation, which is computed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_bas1: 0.7499\n",
      "faithfulness_correlations_bas2: 0.8088\n",
      "faithfulness_correlations_bas3: 0.8383\n",
      "faithfulness_correlations_bas4: 0.8578\n",
      "faithfulness_correlations_bas5: 0.8713\n",
      "faithfulness_correlations_bas6: 0.8813\n",
      "faithfulness_correlations_bas7: 0.8899\n",
      "faithfulness_correlations_bas8: 0.8968\n",
      "faithfulness_correlations_bas9: 0.9018\n",
      "faithfulness_correlations_bas10: 0.9069\n",
      "faithfulness_correlations_inv: 0.8245\n",
      "monotonicity_correlations_bas1: 0.7507\n",
      "monotonicity_correlations_bas2: 0.8088\n",
      "monotonicity_correlations_bas3: 0.8382\n",
      "monotonicity_correlations_bas4: 0.8574\n",
      "monotonicity_correlations_bas5: 0.8708\n",
      "monotonicity_correlations_bas6: 0.8807\n",
      "monotonicity_correlations_bas7: 0.8886\n",
      "monotonicity_correlations_bas8: 0.8952\n",
      "monotonicity_correlations_bas9: 0.9007\n",
      "monotonicity_correlations_bas10: 0.9053\n",
      "monotonicity_correlations_inv: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def measure_correct_orderings(truths, estimators):\n",
    "    '''\n",
    "    Creates len(truth) x,y pairs and computes the fraction of them for which (truths[x]<truths[y] and estimators[x]<estimators[y]) or (truths[x]>truths[y] and estimators[x]>estimators[y])\n",
    "    Inputs:\n",
    "        - Truths & estimators contain num_elems floats\n",
    "    Output:\n",
    "        - Float representing the fraction of correctly ordered pairings\n",
    "    '''\n",
    "    xs = np.random.permutation(truths.size)\n",
    "    ys = np.random.permutation(truths.size)\n",
    "    truthX_lt_Y = truths[xs] < truths[ys]\n",
    "    estimatorX_lt_Y = estimators[xs] < estimators[ys]\n",
    "    hits = truthX_lt_Y==estimatorX_lt_Y\n",
    "    return hits.sum()/truths.size\n",
    "\n",
    "correct_pairings_basX_by_measure = {}\n",
    "correct_pairings_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    correct_pairings_basX = []\n",
    "    for i in range(len(qbasX)):\n",
    "        correct_pairings_basX.append(measure_correct_orderings(q, qbasX[i]))\n",
    "        print(f'{name}_bas{i+1}: {correct_pairings_basX[i]:.4f}')\n",
    "    correct_pairings_inv = measure_correct_orderings(q, qinv)\n",
    "    print(f'{name}_inv: {correct_pairings_inv:.4f}')\n",
    "    \n",
    "    correct_pairings_basX_by_measure[name] = correct_pairings_basX\n",
    "    correct_pairings_inv_by_measure[name] = correct_pairings_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Spearman correlation\n",
    "Same thing, is the order of qmeans preserved in qbasX/qinv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_bas1: 0.6981\n",
      "faithfulness_correlations_bas2: 0.8185\n",
      "faithfulness_correlations_bas3: 0.8697\n",
      "faithfulness_correlations_bas4: 0.8984\n",
      "faithfulness_correlations_bas5: 0.9167\n",
      "faithfulness_correlations_bas6: 0.9293\n",
      "faithfulness_correlations_bas7: 0.9386\n",
      "faithfulness_correlations_bas8: 0.9459\n",
      "faithfulness_correlations_bas9: 0.9515\n",
      "faithfulness_correlations_bas10: 0.9561\n",
      "faithfulness_correlations_inv: 0.8435\n",
      "monotonicity_correlations_bas1: 0.6983\n",
      "monotonicity_correlations_bas2: 0.8203\n",
      "monotonicity_correlations_bas3: 0.8711\n",
      "monotonicity_correlations_bas4: 0.9000\n",
      "monotonicity_correlations_bas5: 0.9180\n",
      "monotonicity_correlations_bas6: 0.9304\n",
      "monotonicity_correlations_bas7: 0.9397\n",
      "monotonicity_correlations_bas8: 0.9466\n",
      "monotonicity_correlations_bas9: 0.9522\n",
      "monotonicity_correlations_bas10: 0.9567\n",
      "monotonicity_correlations_inv: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_basX_by_measure = {}\n",
    "spearman_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    spearman_basX = []\n",
    "    for i in range(len(qbasX)):\n",
    "        spearman_basX.append(spearmanr(q, qbasX[i])[0])\n",
    "        print(f'{name}_bas{i+1}: {spearman_basX[i]:.4f}')\n",
    "    spearman_inv = spearmanr(q, qinv)[0]\n",
    "    print(f'{name}_inv: {spearman_inv:.4f}')\n",
    "\n",
    "    spearman_basX_by_measure[name] = spearman_basX\n",
    "    spearman_inv_by_measure[name] = spearman_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Ability to detect exceptionally good rankings\n",
    "As stated above, there are some ordering errors in the estimators. Are they in the relevant part of the distribution? i.e. Do they affect the ability to identify exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_auc_bas0 0.6888 | 0.7870 | 0.8528 | 0.8873 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas1 0.7267 | 0.8398 | 0.9064 | 0.9341 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas2 0.7430 | 0.8618 | 0.9287 | 0.9531 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas3 0.7519 | 0.8746 | 0.9412 | 0.9631 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas4 0.7577 | 0.8828 | 0.9495 | 0.9693 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas5 0.7617 | 0.8883 | 0.9550 | 0.9738 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas6 0.7642 | 0.8926 | 0.9593 | 0.9771 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas7 0.7666 | 0.8956 | 0.9628 | 0.9794 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas8 0.7681 | 0.8981 | 0.9655 | 0.9815 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas9 0.7694 | 0.9002 | 0.9678 | 0.9832 | 1.0000 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_aucs_inv 0.7295 | 0.8493 | 0.9238 | 0.9544 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas0 0.6979 | 0.7978 | 0.8569 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas1 0.7371 | 0.8498 | 0.9125 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas2 0.7528 | 0.8721 | 0.9356 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas3 0.7616 | 0.8851 | 0.9485 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas4 0.7672 | 0.8929 | 0.9570 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas5 0.7706 | 0.8986 | 0.9626 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas6 0.7733 | 0.9025 | 0.9673 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas7 0.7754 | 0.9053 | 0.9706 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas8 0.7769 | 0.9076 | 0.9737 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_auc_bas9 0.7782 | 0.9096 | 0.9759 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n",
      "monotonicity_correlations_aucs_inv 0.7900 | 0.9252 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_detection(target_indices, estimator):\n",
    "    if len(target_indices)==0:\n",
    "        return 1\n",
    "    target = np.zeros_like(estimator, dtype=int)\n",
    "    target[target_indices] = 1\n",
    "    return metrics.roc_auc_score(target, estimator)\n",
    "\n",
    "aucs_basX_by_measure = {}\n",
    "aucs_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    aucs_inv = []\n",
    "    aucs_basX = [[] for i in qbasX]\n",
    "\n",
    "    for indices, (bottom_limit, upper_limit) in level_indices_by_measure[name][2:]:\n",
    "        aucs_inv.append(measure_detection(indices, qinv))\n",
    "        for i in range(len(qbasX)):\n",
    "            aucs_basX[i].append(measure_detection(indices, qbasX[i]))\n",
    "\n",
    "    for i in range(len(qbasX)):\n",
    "        print(f'{name}_auc_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_basX[i])))\n",
    "    print(f'{name}_aucs_inv ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_inv)))\n",
    "\n",
    "    aucs_basX_by_measure[name] = aucs_basX\n",
    "    aucs_inv_by_measure[name] = aucs_inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ability to rank exceptionally good rankings\n",
    "How well is the order preserved for exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_spearman_exceptional_bas0 0.1317 | 0.1309 | 0.1274 | 0.0616 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas1 0.1892 | 0.1897 | 0.1829 | 0.1075 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas2 0.2335 | 0.2334 | 0.2193 | 0.1259 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas3 0.2705 | 0.2678 | 0.2556 | 0.1411 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas4 0.2987 | 0.2984 | 0.2832 | 0.1682 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas5 0.3218 | 0.3250 | 0.3070 | 0.1846 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas6 0.3493 | 0.3506 | 0.3357 | 0.1927 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas7 0.3711 | 0.3683 | 0.3551 | 0.2175 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas8 0.3915 | 0.3899 | 0.3739 | 0.2169 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas9 0.4083 | 0.4044 | 0.3917 | 0.2387 | nan | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_inv 0.2148 | 0.2270 | 0.2417 | 0.1502 | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas0 0.1497 | 0.0714 | 0.1074 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas1 0.2176 | 0.1133 | 0.1627 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas2 0.2686 | 0.1476 | 0.2054 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas3 0.3145 | 0.1746 | 0.2401 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas4 0.3500 | 0.1991 | 0.2679 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas5 0.3817 | 0.2210 | 0.2923 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas6 0.4085 | 0.2387 | 0.3139 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas7 0.4346 | 0.2581 | 0.3339 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas8 0.4591 | 0.2716 | 0.3551 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas9 0.4786 | 0.2871 | 0.3716 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_inv 1.0000 | 1.0000 | 1.0000 | nan | nan | nan | nan\n"
     ]
    }
   ],
   "source": [
    "spearman_exceptional_basX_by_measure = {}\n",
    "spearman_exceptional_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "\n",
    "    spearman_exceptional_inv = []\n",
    "    spearman_exceptional_basX = [[] for i in qbasX]\n",
    "\n",
    "    for indices, (bottom_limit, upper_limit) in level_indices_by_measure[name][2:]:\n",
    "        spearman_exceptional_inv.append(spearmanr(q[indices], qinv[indices])[0])\n",
    "        for i in range(len(qbasX)):\n",
    "            spearman_exceptional_basX[i].append(spearmanr(q[indices], qbasX[i][indices])[0])\n",
    "\n",
    "    for i in range(len(qbasX)):\n",
    "        print(f'{name}_spearman_exceptional_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_basX[i])))\n",
    "    print(f'{name}_spearman_exceptional_inv ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_inv)))\n",
    "\n",
    "    spearman_exceptional_basX_by_measure[name] = spearman_exceptional_basX\n",
    "    spearman_exceptional_inv_by_measure[name] = spearman_exceptional_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    np.savez(os.path.join(PROJ_DIR, 'results', FILENAME.replace('_measures',f'_results_{name}')), \\\n",
    "            correct_pairings_inv=correct_pairings_inv_by_measure[name], \\\n",
    "            correct_pairings_basX=correct_pairings_basX_by_measure[name], \\\n",
    "            spearman_inv=spearman_inv_by_measure[name], \\\n",
    "            spearman_basX=spearman_basX_by_measure[name], \\\n",
    "            aucs_inv=aucs_inv_by_measure[name], \\\n",
    "            aucs_basX=aucs_basX_by_measure[name], \\\n",
    "            spearman_exceptional_inv=spearman_exceptional_inv_by_measure[name], \\\n",
    "            spearman_exceptional_basX=spearman_exceptional_basX_by_measure[name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-quantus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
