{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure performance\n",
    "This notebook loads a file with precomputed measures for metrics available in Quantus (*faithfulness_correlations* & *monotonicity_correlations*) for a set of rankings for a given instance of the dataset and measures the performance of the different alternative measures\n",
    "\n",
    "# There's a .py version for this script in the src folder which is the one that should be used to generate the files:\n",
    "`src/2-measure-performance-quantus.py`\n",
    "\n",
    "## 1. Load libraries, model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'avila_70_measures.npz'\n",
    "\n",
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = fl.load_generated_data(os.path.join(PROJ_DIR, 'results', FILENAME))\n",
    "\n",
    "if 'inv_lookup' in data.keys():\n",
    "    inv_lookup = data['inv_lookup']\n",
    "else:\n",
    "    inv_lookup = np.load(os.path.join(PROJ_DIR, 'results', 'avila_permutations_inv_lookup.npz'))['inv_lookup']\n",
    "\n",
    "faithfulness_correlations = data['faithfulness_correlations']\n",
    "faithfulness_correlations_basX = []\n",
    "monotonicity_correlations = data['monotonicity_correlations']\n",
    "monotonicity_correlations_basX = []\n",
    "\n",
    "# Compute the baseline with varying number of samples\n",
    "def compute_qbas(measure, num_samples):\n",
    "    random_indices = np.random.randint(0,  measure.shape[0], (measure.shape[0], num_samples))\n",
    "    random_qmeans = measure[random_indices]\n",
    "    mean = np.mean(random_qmeans, axis=1)\n",
    "\n",
    "    # First way to deal with std==0; add some epsilon\n",
    "    #std = np.std(random_qmeans, axis=1) + 1e-10\n",
    "\n",
    "    # Second way to deal with std==0; ignore std (divide by 1)\n",
    "    std = np.std(random_qmeans, axis=1)\n",
    "    std[std==0] = 1\n",
    "\n",
    "    # Always ignore std\n",
    "    std=1\n",
    "    return (measure - mean) / std\n",
    "\n",
    "for i in range(1,11):\n",
    "    faithfulness_correlations_basX.append(compute_qbas(faithfulness_correlations, i))\n",
    "    monotonicity_correlations_basX.append(compute_qbas(monotonicity_correlations, i))\n",
    "\n",
    "# Compute the qinv version\n",
    "def compute_qinv(measure, inv_lookup):\n",
    "    return measure - measure[inv_lookup]\n",
    "\n",
    "faithfulness_correlations_inv = compute_qinv(faithfulness_correlations, inv_lookup)\n",
    "monotonicity_correlations_inv = compute_qinv(monotonicity_correlations, inv_lookup)\n",
    "\n",
    "MEASURES = [('faithfulness_correlations', faithfulness_correlations, faithfulness_correlations_basX, faithfulness_correlations_inv), ('monotonicity_correlations', monotonicity_correlations, monotonicity_correlations_basX, monotonicity_correlations_inv)]\n",
    "\n",
    "level_indices_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    # Compute z-score for stratification\n",
    "    q_mean = np.mean(q)\n",
    "    q_std = np.std(q)\n",
    "    z_scores = ((q - q_mean) / q_std).flatten()\n",
    "\n",
    "    # Stratify z-scores to be able to compare performance on different parts of the spectrum\n",
    "    indices = np.arange(z_scores.shape[0])\n",
    "    z_scores_numbered = np.vstack((z_scores, indices))\n",
    "    level_indices = []\n",
    "    boundaries = [float('-inf'), 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "    for i in range(1,len(boundaries)+1):\n",
    "        bottom_limit = boundaries[i-1]\n",
    "        top_limit = float('inf')\n",
    "        if i < len(boundaries):\n",
    "            top_limit = boundaries[i]\n",
    "        level_indices.append((z_scores_numbered[:,np.logical_and(bottom_limit<=z_scores, z_scores<top_limit)][1,:].astype(int),(bottom_limit, top_limit)))\n",
    "    \n",
    "    level_indices_by_measure[name] = level_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure performance\n",
    "### 2.1 Order preservation\n",
    " 1. The issue with using qmean directly is that it doesn't have a fixed scale and you don't get an idea of how good your explanation is compared to other explanations\n",
    " 2. To address this, ideally you would determine the distribution of all qmeans and then compute the z-score. That's very costly, so you either:\n",
    "    1. Estimate the qmeans distribution with X samples $\\rightarrow$ qbasX\n",
    "    2. Calculate an alternative to the z-index directly $\\rightarrow$ qinv\n",
    " 3. The problem with both alternatives is that you adulterate the value of your original qmean measurement, so you may end up in a situation where $qmean_i<qmean_j$ but $qinv_i<qinv_j$, which is undesirable\n",
    " 4. Hence, we measure how many times that happens for each measure.\n",
    "\n",
    " (This may be measuring the same as Pearson correlation, which is computed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_bas1: 0.7499\n",
      "faithfulness_correlations_bas2: 0.8078\n",
      "faithfulness_correlations_bas3: 0.8376\n",
      "faithfulness_correlations_bas4: 0.8566\n",
      "faithfulness_correlations_bas5: 0.8708\n",
      "faithfulness_correlations_bas6: 0.8804\n",
      "faithfulness_correlations_bas7: 0.8891\n",
      "faithfulness_correlations_bas8: 0.8957\n",
      "faithfulness_correlations_bas9: 0.9013\n",
      "faithfulness_correlations_bas10: 0.9061\n",
      "faithfulness_correlations_inv: 0.7529\n",
      "monotonicity_correlations_bas1: 0.7505\n",
      "monotonicity_correlations_bas2: 0.8082\n",
      "monotonicity_correlations_bas3: 0.8379\n",
      "monotonicity_correlations_bas4: 0.8568\n",
      "monotonicity_correlations_bas5: 0.8707\n",
      "monotonicity_correlations_bas6: 0.8804\n",
      "monotonicity_correlations_bas7: 0.8888\n",
      "monotonicity_correlations_bas8: 0.8950\n",
      "monotonicity_correlations_bas9: 0.9004\n",
      "monotonicity_correlations_bas10: 0.9053\n",
      "monotonicity_correlations_inv: 0.7431\n"
     ]
    }
   ],
   "source": [
    "def measure_correct_orderings(truths, estimators):\n",
    "    '''\n",
    "    Creates len(truth) x,y pairs and computes the fraction of them for which (truths[x]<truths[y] and estimators[x]<estimators[y]) or (truths[x]>truths[y] and estimators[x]>estimators[y])\n",
    "    Inputs:\n",
    "        - Truths & estimators contain num_elems floats\n",
    "    Output:\n",
    "        - Float representing the fraction of correctly ordered pairings\n",
    "    '''\n",
    "    xs = np.random.permutation(truths.size)\n",
    "    ys = np.random.permutation(truths.size)\n",
    "    truthX_lt_Y = truths[xs] < truths[ys]\n",
    "    estimatorX_lt_Y = estimators[xs] < estimators[ys]\n",
    "    hits = truthX_lt_Y==estimatorX_lt_Y\n",
    "    return hits.sum()/truths.size\n",
    "\n",
    "correct_pairings_basX_by_measure = {}\n",
    "correct_pairings_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    correct_pairings_basX = []\n",
    "    for i in range(len(qbasX)):\n",
    "        correct_pairings_basX.append(measure_correct_orderings(q, qbasX[i]))\n",
    "        print(f'{name}_bas{i+1}: {correct_pairings_basX[i]:.4f}')\n",
    "    correct_pairings_inv = measure_correct_orderings(q, qinv)\n",
    "    print(f'{name}_inv: {correct_pairings_inv:.4f}')\n",
    "    \n",
    "    correct_pairings_basX_by_measure[name] = correct_pairings_basX\n",
    "    correct_pairings_inv_by_measure[name] = correct_pairings_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Spearman correlation\n",
    "Same thing, is the order of qmeans preserved in qbasX/qinv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_bas1: 0.6959\n",
      "faithfulness_correlations_bas2: 0.8152\n",
      "faithfulness_correlations_bas3: 0.8667\n",
      "faithfulness_correlations_bas4: 0.8958\n",
      "faithfulness_correlations_bas5: 0.9145\n",
      "faithfulness_correlations_bas6: 0.9272\n",
      "faithfulness_correlations_bas7: 0.9369\n",
      "faithfulness_correlations_bas8: 0.9442\n",
      "faithfulness_correlations_bas9: 0.9500\n",
      "faithfulness_correlations_bas10: 0.9547\n",
      "faithfulness_correlations_inv: 0.7017\n",
      "monotonicity_correlations_bas1: 0.6984\n",
      "monotonicity_correlations_bas2: 0.8204\n",
      "monotonicity_correlations_bas3: 0.8707\n",
      "monotonicity_correlations_bas4: 0.8994\n",
      "monotonicity_correlations_bas5: 0.9174\n",
      "monotonicity_correlations_bas6: 0.9300\n",
      "monotonicity_correlations_bas7: 0.9392\n",
      "monotonicity_correlations_bas8: 0.9463\n",
      "monotonicity_correlations_bas9: 0.9518\n",
      "monotonicity_correlations_bas10: 0.9564\n",
      "monotonicity_correlations_inv: 0.6817\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_basX_by_measure = {}\n",
    "spearman_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    spearman_basX = []\n",
    "    for i in range(len(qbasX)):\n",
    "        spearman_basX.append(spearmanr(q, qbasX[i])[0])\n",
    "        print(f'{name}_bas{i+1}: {spearman_basX[i]:.4f}')\n",
    "    spearman_inv = spearmanr(q, qinv)[0]\n",
    "    print(f'{name}_inv: {spearman_inv:.4f}')\n",
    "\n",
    "    spearman_basX_by_measure[name] = spearman_basX\n",
    "    spearman_inv_by_measure[name] = spearman_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Ability to detect exceptionally good rankings\n",
    "As stated above, there are some ordering errors in the estimators. Are they in the relevant part of the distribution? i.e. Do they affect the ability to identify exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_auc_bas0 0.6893 | 0.7855 | 0.8526 | 0.8962 | 0.9298 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas1 0.7275 | 0.8380 | 0.9057 | 0.9412 | 0.9682 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas2 0.7453 | 0.8607 | 0.9269 | 0.9597 | 0.9780 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas3 0.7551 | 0.8736 | 0.9395 | 0.9685 | 0.9848 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas4 0.7616 | 0.8818 | 0.9474 | 0.9745 | 0.9886 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas5 0.7659 | 0.8876 | 0.9530 | 0.9782 | 0.9902 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas6 0.7692 | 0.8921 | 0.9568 | 0.9812 | 0.9927 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas7 0.7715 | 0.8953 | 0.9603 | 0.9834 | 0.9932 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas8 0.7736 | 0.8981 | 0.9624 | 0.9850 | 0.9939 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_auc_bas9 0.7753 | 0.9000 | 0.9645 | 0.9865 | 0.9949 | 1.0000 | 1.0000\n",
      "faithfulness_correlations_aucs_inv 0.6910 | 0.7883 | 0.8548 | 0.8965 | 0.9326 | 1.0000 | 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoruña/UDC-Datos/Proyectos/Explicabilidad/Berlín/eval-project/nbs/2-measure-performance-quantus.ipynb Celda 8\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     aucs_inv\u001b[39m.\u001b[39mappend(measure_detection(indices, qinv))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(qbasX)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         aucs_basX[i]\u001b[39m.\u001b[39mappend(measure_detection(indices, qbasX[i]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(qbasX)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m_auc_bas\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,aucs_basX[i])))\n",
      "\u001b[1;32m/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoruña/UDC-Datos/Proyectos/Explicabilidad/Berlín/eval-project/nbs/2-measure-performance-quantus.ipynb Celda 8\u001b[0m in \u001b[0;36mmeasure_detection\u001b[0;34m(target_indices, estimator)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(estimator, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m target[target_indices] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eirasf/Library/CloudStorage/OneDrive-UniversidadedaCoru%C3%B1a/UDC-Datos/Proyectos/Explicabilidad/Berl%C3%ADn/eval-project/nbs/2-measure-performance-quantus.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m metrics\u001b[39m.\u001b[39;49mroc_auc_score(target, estimator)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[1;32m    571\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[1;32m    575\u001b[0m         y_score,\n\u001b[1;32m    576\u001b[0m         average,\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:772\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    769\u001b[0m y_true \u001b[39m=\u001b[39m y_true \u001b[39m==\u001b[39m pos_label\n\u001b[1;32m    771\u001b[0m \u001b[39m# sort scores and corresponding truth values\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m desc_score_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margsort(y_score, kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmergesort\u001b[39;49m\u001b[39m\"\u001b[39;49m)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    773\u001b[0m y_score \u001b[39m=\u001b[39m y_score[desc_score_indices]\n\u001b[1;32m    774\u001b[0m y_true \u001b[39m=\u001b[39m y_true[desc_score_indices]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1120\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1013\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margsort\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1014\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[39m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \n\u001b[1;32m   1119\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margsort\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_detection(target_indices, estimator):\n",
    "    if len(target_indices)==0:\n",
    "        return 1\n",
    "    target = np.zeros_like(estimator, dtype=int)\n",
    "    target[target_indices] = 1\n",
    "    return metrics.roc_auc_score(target, estimator)\n",
    "\n",
    "aucs_basX_by_measure = {}\n",
    "aucs_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    aucs_inv = []\n",
    "    aucs_basX = [[] for i in qbasX]\n",
    "\n",
    "    for indices, (bottom_limit, upper_limit) in level_indices_by_measure[name][2:]:\n",
    "        aucs_inv.append(measure_detection(indices, qinv))\n",
    "        for i in range(len(qbasX)):\n",
    "            aucs_basX[i].append(measure_detection(indices, qbasX[i]))\n",
    "\n",
    "    for i in range(len(qbasX)):\n",
    "        print(f'{name}_auc_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_basX[i])))\n",
    "    print(f'{name}_aucs_inv ' + ' | '.join(map(lambda x: f'{x:.4f}',aucs_inv)))\n",
    "\n",
    "aucs_basX_by_measure[name] = aucs_basX\n",
    "aucs_inv_by_measure[name] = aucs_inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ability to rank exceptionally good rankings\n",
    "How well is the order preserved for exceptionally good rankings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_correlations_spearman_exceptional_bas0 0.1346 | 0.1287 | 0.1271 | 0.1064 | 0.0297 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas1 0.1918 | 0.1907 | 0.1838 | 0.1639 | 0.0574 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas2 0.2330 | 0.2323 | 0.2256 | 0.2023 | 0.0895 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas3 0.2686 | 0.2681 | 0.2615 | 0.2308 | 0.0834 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas4 0.3006 | 0.2948 | 0.2926 | 0.2514 | 0.0939 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas5 0.3257 | 0.3242 | 0.3142 | 0.2797 | 0.1364 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas6 0.3488 | 0.3435 | 0.3407 | 0.2928 | 0.1086 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas7 0.3715 | 0.3690 | 0.3563 | 0.3124 | 0.1892 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas8 0.3892 | 0.3860 | 0.3768 | 0.3309 | 0.1656 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_bas9 0.4094 | 0.4070 | 0.3971 | 0.3460 | 0.1571 | nan | nan\n",
      "faithfulness_correlations_spearman_exceptional_inv 0.1317 | 0.1326 | 0.1307 | 0.1114 | 0.0129 | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas0 0.0861 | 0.1376 | 0.0828 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas1 0.1291 | 0.2031 | 0.1261 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas2 0.1547 | 0.2521 | 0.1660 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas3 0.1805 | 0.2880 | 0.1891 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas4 0.2039 | 0.3215 | 0.2145 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas5 0.2219 | 0.3489 | 0.2347 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas6 0.2377 | 0.3744 | 0.2529 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas7 0.2534 | 0.3960 | 0.2664 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas8 0.2694 | 0.4172 | 0.2824 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_bas9 0.2832 | 0.4385 | 0.2973 | nan | nan | nan | nan\n",
      "monotonicity_correlations_spearman_exceptional_inv 0.0755 | 0.1188 | 0.0492 | nan | nan | nan | nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch-quantus/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4878: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    }
   ],
   "source": [
    "spearman_exceptional_basX_by_measure = {}\n",
    "spearman_exceptional_inv_by_measure = {}\n",
    "for name, q, qbasX, qinv in MEASURES:\n",
    "\n",
    "    spearman_exceptional_inv = []\n",
    "    spearman_exceptional_basX = [[] for i in qbasX]\n",
    "\n",
    "    for indices, (bottom_limit, upper_limit) in level_indices_by_measure[name][2:]:\n",
    "        spearman_exceptional_inv.append(spearmanr(q[indices], qinv[indices])[0])\n",
    "        for i in range(len(qbasX)):\n",
    "            spearman_exceptional_basX[i].append(spearmanr(q[indices], qbasX[i][indices])[0])\n",
    "\n",
    "    for i in range(len(qbasX)):\n",
    "        print(f'{name}_spearman_exceptional_bas{i} ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_basX[i])))\n",
    "    print(f'{name}_spearman_exceptional_inv ' + ' | '.join(map(lambda x: f'{x:.4f}', spearman_exceptional_inv)))\n",
    "\n",
    "    spearman_exceptional_basX_by_measure[name] = spearman_exceptional_basX\n",
    "    spearman_exceptional_inv_by_measure[name] = spearman_exceptional_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, q, qbasX, qinv in MEASURES:\n",
    "    np.savez(os.path.join(PROJ_DIR, 'results', FILENAME.replace('_measures',f'_results_{name}')), \\\n",
    "            correct_pairings_inv=correct_pairings_inv_by_measure[name], \\\n",
    "            correct_pairings_basX=correct_pairings_basX_by_measure[name], \\\n",
    "            spearman_inv=spearman_inv_by_measure[name], \\\n",
    "            spearman_basX=spearman_basX_by_measure[name], \\\n",
    "            aucs_inv=aucs_inv_by_measure[name], \\\n",
    "            aucs_basX=aucs_basX_by_measure[name], \\\n",
    "            spearman_exceptional_inv=spearman_exceptional_inv_by_measure[name], \\\n",
    "            spearman_exceptional_basX=spearman_exceptional_basX_by_measure[name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-quantus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
