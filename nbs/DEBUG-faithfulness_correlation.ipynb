{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05f878c-8c4b-4099-8899-e00a367e1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "Loading Resnet18\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "PROJ_DIR = os.path.realpath(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(os.path.join(PROJ_DIR,'src'))\n",
    "import xai_faithfulness_experiments_lib_edits as fl\n",
    "import numpy as np\n",
    "import captum_generator as cg\n",
    "import quantus\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "\n",
    "METHOD_NAMES = ['Saliency', 'IntegratedGradients', 'InputXGradient', 'GuidedBackprop', 'Deconvolution', 'LayerGradCam', 'GuidedGradCam']\n",
    "\n",
    "ACTIVATION_THRESHOLD = 0.9\n",
    "Z_SCORE_THRESHOLD = 4\n",
    "DESIRED_EXPLANATIONS = 1000\n",
    "\n",
    "CHUNKINESS = 32\n",
    "\n",
    "DATASET = 'imagenet'\n",
    "MODEL_NAME = 'resnet18'\n",
    "\n",
    "# Load dataset\n",
    "if DATASET == '20newsgroups-truncated':\n",
    "    DATASET_PATH = os.path.join(PROJ_DIR,'assets', 'data', f'{DATASET}.npz')\n",
    "    # Load dataset\n",
    "    file_data = np.load(DATASET_PATH)\n",
    "    x_train = torch.from_numpy(file_data['x_train']).float().to(device)\n",
    "    y_train = torch.from_numpy(file_data['y_train']).to(device)\n",
    "    test_loader = [(x_train, y_train)]\n",
    "else:\n",
    "    #torch.manual_seed(0)\n",
    "    test_loader = fl.get_image_test_loader(DATASET, 1000, PROJ_DIR, shuffle = True)\n",
    "\n",
    "\n",
    "# Load model\n",
    "if DATASET == 'imagenet':\n",
    "    network = fl.load_pretrained_imagenet_model(arch = MODEL_NAME.replace('-logits', ''), use_logits = '-logits' in MODEL_NAME)\n",
    "    DATA_MEAN = [0.485, 0.456, 0.406]\n",
    "    DATA_STD = [0.229, 0.224, 0.225]\n",
    "elif DATASET == 'mnist':\n",
    "    MODEL_PATH = os.path.join(PROJ_DIR,'assets', 'models', f'{DATASET}-{MODEL_NAME}-mlp.pth')\n",
    "    network = fl.load_pretrained_mnist_model(MODEL_PATH)\n",
    "    DATA_MEAN = [0.1307]\n",
    "    DATA_STD = [0.3081]\n",
    "elif DATASET == 'cifar':\n",
    "    MODEL_PATH = os.path.join(PROJ_DIR,'assets', 'models', f'{DATASET}-{MODEL_NAME}-mlp.pth')\n",
    "    network = fl.load_pretrained_cifar_model(MODEL_PATH)\n",
    "elif DATASET == '20newsgroups-truncated':\n",
    "    MODEL_PATH = os.path.join(PROJ_DIR,'assets', 'models', f'{DATASET}{MODEL_NAME}-mlp.pth')\n",
    "    network = fl.load_pretrained_mlp_large_model(MODEL_PATH, x_train.shape[1], 20, [1000, 1000, 800, 500])\n",
    "    DATA_MEAN = [0.2675, 0.2565, 0.2761]\n",
    "    DATA_STD = [0.5071, 0.4867, 0.4408]\n",
    "else:\n",
    "    raise Exception(f'ERROR: Unknown dataset {DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9137854-e774-4903-89c4-132da7b1c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch  0\n",
      "Estimating mean and std...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.77it/s]\n",
      "/home/eirasf/miniconda3/envs/xai-anna/lib/python3.11/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/eirasf/miniconda3/envs/xai-anna/lib/python3.11/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.03830202331943748 std 0.3306022372672858\n",
      "Method #0: 0.35844624097077227\n",
      "Method #1: -2.223316608934815\n",
      "Method #2: 0.07022504853255701\n",
      "Method #3: 1.7396248933815515\n",
      "Method #4: -1.2338932601738555\n",
      "Method #5: -0.41872867666989705\n",
      "Method #6: -0.45402814856493495\n",
      "Estimating mean and std...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean -0.03969074446130821 std 0.3345781660762455\n",
      "Method #0: 1.6142461829915913\n",
      "Method #1: -0.9731085074880945\n",
      "Method #2: 1.8220839182220863\n",
      "Method #3: -0.6001254367297141\n",
      "Method #4: 1.6239881312929938\n",
      "Method #5: 1.0587795720430302\n",
      "Method #6: -0.8211470074107878\n",
      "Estimating mean and std...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:01<00:03, 20.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m#For each ranking, retrieve and store Quantus' faithfulness metrics\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     a_batch \u001b[38;5;241m=\u001b[39m fl\u001b[38;5;241m.\u001b[39m_get_random_ranking_row(row\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     qmeans\u001b[38;5;241m.\u001b[39mappend(\u001b[43mquantus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFaithfulnessCorrelation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mnr_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msubset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mperturb_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mperturb_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturb_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseline_replacement_by_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msimilarity_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelation_pearson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mreturn_aggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdisable_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#measures = fl.get_measures_for_ranking(row, fl._get_chunky_random_ranking_row(row.shape, CHUNKINESS, CHUNKINESS, True), label, network, with_inverse=False, with_random=False, masking_values=masking_values)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#qmeans.append(measures['mean'])\u001b[39;00m\n\u001b[1;32m     66\u001b[0m qmean_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(qmeans)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/quantus/metrics/faithfulness/faithfulness_correlation.py:246\u001b[0m, in \u001b[0;36mFaithfulnessCorrelation.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    155\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    This implementation represents the main logic of the metric and makes the class object callable.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    It completes instance-wise evaluation of explanations (a_batch) with respect to input data (x_batch),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m        >> scores = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=a_batch_saliency}\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/quantus/metrics/base.py:225\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_instance_iterator(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_instance, data_instance \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m--> 225\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_results[id_instance] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Call custom post-processing.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/quantus/metrics/faithfulness/faithfulness_correlation.py:316\u001b[0m, in \u001b[0;36mFaithfulnessCorrelation.evaluate_instance\u001b[0;34m(self, model, x, y, a, s)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# Predict on perturbed input x.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m x_input \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mshape_input(x_perturbed, x\u001b[38;5;241m.\u001b[39mshape, channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 316\u001b[0m y_pred_perturb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m[:, y])\n\u001b[1;32m    317\u001b[0m pred_deltas\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(y_pred \u001b[38;5;241m-\u001b[39m y_pred_perturb))\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# Sum attributions of the random subset.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/quantus/helpers/model/pytorch_model.py:123\u001b[0m, in \u001b[0;36mPyTorchModel.predict\u001b[0;34m(self, x, grad, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m grad_context:\n\u001b[1;32m    122\u001b[0m     pred_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_softmax_arg_model()\n\u001b[0;32m--> 123\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpred_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Escritorio/eval-project/src/xai_faithfulness_experiments_lib_edits.py:98\u001b[0m, in \u001b[0;36mLogitToOHEWrapper.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 98\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Apply softmax to convert logits to probabilities\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torchvision/models/resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xai-anna/lib/python3.11/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "#FILENAME = f'{DATASET}_{MODEL_NAME}_noise_exceptionals_chunky.pkl'\n",
    "FILENAME = f'{DATASET}_{MODEL_NAME}_exceptionals_fc.pkl'\n",
    "\n",
    "if os.path.isfile(os.path.join(PROJ_DIR, 'results', FILENAME)):\n",
    "    with open(os.path.join(PROJ_DIR, 'results', FILENAME), 'rb') as fIn:\n",
    "        results = pickle.load(fIn)\n",
    "else:\n",
    "    # The mean is zero because this dataset is standardized\n",
    "    num_vars = None\n",
    "    masking_values = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_elements = []\n",
    "\n",
    "        for batch_idx, (x_train, y_train) in enumerate(test_loader):\n",
    "            print(f'Loaded batch  {batch_idx}')\n",
    "            if masking_values is None:\n",
    "                masking_values = torch.from_numpy(np.zeros(x_train.shape[1:])).float().to(device)\n",
    "                num_vars  = 1\n",
    "                for d in x_train.shape[1:]:\n",
    "                    num_vars *= d\n",
    "                num_samples = min(fl.NUM_SAMPLES, num_vars)\n",
    "                input_shape = x_train.shape[1:]\n",
    "            # Find elements from the batch that activate the network enough\n",
    "            outputs = network(x_train.to(device))\n",
    "            activated_indices = (outputs[torch.arange(x_train.shape[0]), y_train]>ACTIVATION_THRESHOLD).nonzero().flatten()\n",
    "\n",
    "            for i, sample_index in enumerate(activated_indices):\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(f' Exploring activating sample {i+1}/{activated_indices.size()[0]}')\n",
    "                row = x_train[sample_index.item()].to(device)\n",
    "                label = y_train[sample_index.item()].to(device)\n",
    "            \n",
    "                x_batch = row.unsqueeze(0).cpu().numpy()\n",
    "                y_batch = label.unsqueeze(0).cpu().numpy()\n",
    "\n",
    "                print('Estimating mean and std...')\n",
    "                #Compute 100 random rankings to compute the average q\n",
    "                qmeans = []\n",
    "                for _ in tqdm(range(100)):\n",
    "                    #For each ranking, retrieve and store Quantus' faithfulness metrics\n",
    "                    a_batch = fl._get_random_ranking_row(row.shape).unsqueeze(0)\n",
    "                    \n",
    "                    qmeans.append(quantus.FaithfulnessCorrelation(\n",
    "                                                            nr_runs=10,\n",
    "                                                            subset_size=4,  \n",
    "                                                            perturb_baseline=\"black\",\n",
    "                                                            perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                            similarity_func=quantus.similarity_func.correlation_pearson,  \n",
    "                                                            abs=False,  \n",
    "                                                            return_aggregate=False,\n",
    "                                                            disable_warnings=True\n",
    "                                                        )(model=network, \n",
    "                                                        x_batch=x_batch, \n",
    "                                                        y_batch=y_batch,\n",
    "                                                        a_batch=a_batch.cpu().numpy(),\n",
    "                                                        device=device,\n",
    "                                                        channel_first=True)[0])\n",
    "\n",
    "\n",
    "                    #measures = fl.get_measures_for_ranking(row, fl._get_chunky_random_ranking_row(row.shape, CHUNKINESS, CHUNKINESS, True), label, network, with_inverse=False, with_random=False, masking_values=masking_values)\n",
    "                    #qmeans.append(measures['mean'])\n",
    "                qmean_mean = np.mean(qmeans)\n",
    "                qmean_std = np.std(qmeans)\n",
    "                print('mean', qmean_mean, 'std', qmean_std)\n",
    "        \n",
    "                #Grab captum generated explanations and check their z-index\n",
    "                captum_rankings = torch.tensor(cg.generate_rankings(row, label, network)).to(device)\n",
    "                for method_index, ranking in enumerate(captum_rankings):\n",
    "                    #measures = fl.get_measures_for_ranking(row, ranking, label, network, with_inverse=False, with_random=False, masking_values=masking_values)\n",
    "                    #zscore = (measures['mean'] -  qmean_mean) /  qmean_std\n",
    "\n",
    "                    fc = quantus.FaithfulnessCorrelation(\n",
    "                                                            nr_runs=10,\n",
    "                                                            subset_size=4,  \n",
    "                                                            perturb_baseline=\"black\",\n",
    "                                                            perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                            similarity_func=quantus.similarity_func.correlation_pearson,  \n",
    "                                                            abs=False,  \n",
    "                                                            return_aggregate=False,\n",
    "                                                            disable_warnings=True\n",
    "                                                        )(model=network, \n",
    "                                                        x_batch=x_batch, \n",
    "                                                        y_batch=y_batch,\n",
    "                                                        a_batch=ranking.unsqueeze(0).cpu().numpy(),\n",
    "                                                        device=device,\n",
    "                                                        channel_first=True)[0]\n",
    "                    zscore = (fc -  qmean_mean) /  qmean_std\n",
    "\n",
    "                    print(f'Method #{method_index}: {zscore}')\n",
    "\n",
    "                    if zscore > 4:\n",
    "                        valid_elements.append({'row': row,\\\n",
    "                                            'ranking': ranking,\\\n",
    "                                            'label': label,\\\n",
    "                                            'qmean_mean': qmean_mean,\\\n",
    "                                            'qmean_std': qmean_std,\\\n",
    "                                            'method': method_index\n",
    "                                            })\n",
    "                        print(f'{len(valid_elements)}/{DESIRED_EXPLANATIONS}')\n",
    "                        if len(valid_elements) >= DESIRED_EXPLANATIONS:\n",
    "                            break\n",
    "                if len(valid_elements) >= DESIRED_EXPLANATIONS:\n",
    "                    break\n",
    "\n",
    "    results = []\n",
    "    for v in valid_elements:\n",
    "        row  = v['row']\n",
    "        ranking = v['ranking']\n",
    "        label = v['label']\n",
    "        measures = fl.get_measures_for_ranking(row, ranking, label, network, with_inverse=True, with_random=True, masking_values=masking_values, noisy_inverse=True)\n",
    "        v['qmean'] = measures['mean']\n",
    "        v['qinv'] = measures['mean_inv']\n",
    "        v['qbas'] = measures['mean_bas']\n",
    "        results.append(v)\n",
    "    with open(os.path.join(PROJ_DIR, 'results', FILENAME), 'wb') as fOut:\n",
    "        pickle.dump(results, fOut)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096caec-4adf-4e7c-adb9-e767d6d31355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = [x for x in results if x['qmean']>0.5]\n",
    "filtered = results\n",
    "#filtered = [x for x in results if x['method']==5]\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from matplotlib import pyplot as plt\n",
    "zindices = list(map(lambda x: (x['qmean']-x['qmean_mean'])/x['qmean_std'], filtered))\n",
    "#zindices = list(map(lambda x: x['qmean'], filtered))\n",
    "qinv = list(map(lambda x: x['qinv'], filtered))\n",
    "qbas = list(map(lambda x: x['qbas'], filtered))\n",
    "\n",
    "print(spearmanr(zindices, qinv).statistic)\n",
    "plt.scatter(zindices,  qinv, s=0.1)\n",
    "plt.show()\n",
    "print(spearmanr(zindices, qbas).statistic)\n",
    "plt.scatter(zindices,  qbas, s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73eed52-9a68-4a01-9393-ac7899c1379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(zindices, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bff05-c5ff-4c77-9716-68a034098913",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ELEMS = 10\n",
    "NUM_CURVES = 10\n",
    "\n",
    "#indices = torch.tensor(qinv).topk(NUM_ELEMS, largest=False).indices\n",
    "indices = torch.tensor(zindices).topk(NUM_ELEMS, largest=True).indices\n",
    "\n",
    "data_std_tensor = torch.tensor(np.reshape(DATA_STD, (3,1,1))).to(device)\n",
    "data_mean_tensor = torch.tensor(np.reshape(DATA_MEAN, (3,1,1))).to(device)\n",
    "\n",
    "for i in indices:\n",
    "    v = filtered[i]\n",
    "    print(METHOD_NAMES[v['method']])\n",
    "    print(v.keys())\n",
    "    row  = v['row']\n",
    "    ranking = v['ranking']\n",
    "    inverse_ranking = v['inverse_ranking']\n",
    "    label = v['label']\n",
    "    masking_values = torch.from_numpy(np.zeros(row.shape)).float().to(device)\n",
    "    measures = fl.get_measures_for_ranking(row, ranking, label, network, with_inverse=True, with_random=True, masking_values=masking_values)\n",
    "    measures_inverse = fl.get_measures_for_ranking(row, inverse_ranking, label, network, with_inverse=False, with_random=False, masking_values=masking_values)\n",
    "    \n",
    "    masking_values_red = torch.clone(masking_values)\n",
    "    masking_values_red[1,:,:] = 1\n",
    "    printable_image_tensor = row * data_std_tensor + data_mean_tensor\n",
    "\n",
    "    print('Mean', measures['mean'])\n",
    "    print('qmean', v['qmean_mean'])\n",
    "    print('qstd',v['qmean_std'])\n",
    "    print(network(row.unsqueeze(0)).max())\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 2))\n",
    "    axs[0].plot(measures['output_curve'], color='green', label='r')\n",
    "    axs[0].plot(measures['output_curve_inv'], color='orange', label='i')\n",
    "    axs[0].plot(measures_inverse['output_curve'], color='red', label='i-ff')\n",
    "    axs[0].plot(measures['output_curve_bas'], color='gray', linewidth=0.2)\n",
    "    axs[0].set_title('Chunky randoms')\n",
    "    axs[0].legend()\n",
    "    for _ in range(NUM_CURVES):\n",
    "        measures_random = fl.get_measures_for_ranking(row, fl._get_chunky_random_ranking_row(ranking.shape, CHUNKINESS, CHUNKINESS, True), label, network, with_inverse=False, with_random=False, masking_values=masking_values)\n",
    "        axs[0].plot(measures_random['output_curve'], color='gray', linewidth=0.2)\n",
    "    axs[1].imshow(np.moveaxis(printable_image_tensor.detach().cpu().numpy(), 0, -1))\n",
    "    axs[2].imshow(v['ranking'].sum(axis=0).detach().cpu().numpy(), cmap='plasma')\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 2))\n",
    "    axs[0].plot(measures['output_curve'], color='green')\n",
    "    axs[0].plot(measures['output_curve_inv'], color='orange')\n",
    "    axs[0].plot(measures_inverse['output_curve'], color='red')\n",
    "    axs[0].plot(measures['output_curve_bas'], color='gray', linewidth=0.2)\n",
    "    axs[0].set_title('Regular randoms')\n",
    "    for _ in range(NUM_CURVES):\n",
    "        measures_random = fl.get_measures_for_ranking(row, fl._get_random_ranking_row(ranking.shape), label, network, with_inverse=False, with_random=False, masking_values=masking_values)\n",
    "        axs[0].plot(measures_random['output_curve'], color='gray', linewidth=0.2)\n",
    "    axs[1].imshow(np.moveaxis(printable_image_tensor.detach().cpu().numpy(), 0, -1))\n",
    "    axs[2].imshow(v['ranking'].sum(axis=0).detach().cpu().numpy(), cmap='plasma')\n",
    "    plt.show()\n",
    "\n",
    "    masked = fl._get_masked_inputs(row, masking_values, ranking, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, ranking, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m, r) in enumerate(zip(masked, masked_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('Ranking')\n",
    "    plt.show()\n",
    "    masked_inverse = fl._get_masked_inputs(row, masking_values, torch.tensor(fl._attributions_to_ranking_row(ranking.flatten().detach().cpu(), reverse=True).reshape(ranking.shape)).to(device), torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_inverse_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, torch.tensor(fl._attributions_to_ranking_row(ranking.flatten().detach().cpu(), reverse=True).reshape(ranking.shape)).to(device), torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m,r) in enumerate(zip(masked_inverse, masked_inverse_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('Inverse')\n",
    "    plt.show()\n",
    "    masked_inverse = fl._get_masked_inputs(row, masking_values, v['inverse_ranking'], torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_inverse_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, v['inverse_ranking'], torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m,r) in enumerate(zip(masked_inverse, masked_inverse_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('Inverse in file')\n",
    "    plt.show()\n",
    "    random_row = fl._get_random_ranking_row(ranking.shape)\n",
    "    masked_random = fl._get_masked_inputs(row, masking_values, random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_random_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m,r) in enumerate(zip(masked_random,masked_random_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('Random')\n",
    "    plt.show()\n",
    "    random_row = fl._get_random_ranking_row((1,*ranking.shape[1:]))\n",
    "    random_row = random_row.repeat((ranking.shape[0],1,1))\n",
    "    masked_random = fl._get_masked_inputs(row, masking_values, random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_random_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m,r) in enumerate(zip(masked_random,masked_random_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('1c Random')\n",
    "    plt.show()\n",
    "    chunky_random_row = fl._get_chunky_random_ranking_row(ranking.shape, 32, 32, True)\n",
    "    masked_random = fl._get_masked_inputs(row, masking_values, chunky_random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    masked_random_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, chunky_random_row, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "    for pos, (m,r) in enumerate(zip(masked_random,masked_random_printable)):\n",
    "        axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "        axs[pos].set_yticks([])\n",
    "        axs[pos].set_xticks([])\n",
    "        axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "    plt.suptitle('Chunky random')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cc550-acb1-4da1-a7a6-89dee8f7a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GuidedGradCam,LayerGradCam,LayerAttribution\n",
    "explanation = GuidedGradCam(network, network.network.features[28]).attribute(inputs=row.unsqueeze(0), target=label.unsqueeze(0))\n",
    "print(explanation.shape)\n",
    "explanation=LayerAttribution.interpolate(explanation, row.shape[1:])\n",
    "#explanation = torch.stack([explanation, explanation, explanation], dim=1).squeeze()\n",
    "explanation = explanation.squeeze()\n",
    "print(printable_image_tensor.shape)\n",
    "print(explanation.shape)\n",
    "plt.imshow(np.moveaxis(printable_image_tensor.detach().cpu().numpy(),0,-1))\n",
    "plt.show()\n",
    "printable_explanation = (explanation - explanation.min())/(explanation.max()-explanation.min())\n",
    "plt.imshow(np.moveaxis(printable_explanation.detach().cpu().numpy(),0,-1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ranking = torch.tensor(fl._attributions_to_ranking_row(explanation.flatten().detach().cpu(), reverse=False).reshape(ranking.shape)).to(device)\n",
    "plt.imshow(np.moveaxis(ranking.detach().cpu().numpy(),0,-1))\n",
    "plt.show()\n",
    "masked = fl._get_masked_inputs(row, masking_values, ranking, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "masked_printable = fl._get_masked_inputs(printable_image_tensor, masking_values_red, ranking, torch.tensor([0.2, 0.4, 0.6, 0.8]).to(device))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 2))\n",
    "for pos, (m, r) in enumerate(zip(masked, masked_printable)):\n",
    "    axs[pos].imshow(np.moveaxis(r.detach().cpu().numpy(), 0, -1))\n",
    "    axs[pos].set_yticks([])\n",
    "    axs[pos].set_xticks([])\n",
    "    axs[pos].set_title(f'{network(m.unsqueeze(0)).squeeze()[label].item():.4f}')\n",
    "plt.suptitle('Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([i for i in range(len(network.network.features)) if type(network.network.features[i]) == torch.nn.modules.conv.Conv2d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8aec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in network.modules():\n",
    "    print(type(m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
