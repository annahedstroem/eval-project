{"cells":[{"cell_type":"markdown","metadata":{"id":"l21QqnHCbivV"},"source":["# Load library from Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5364,"status":"ok","timestamp":1668419561977,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"},"user_tz":-60},"id":"svlX--ECT3mO","outputId":"f0c031eb-0009-4646-a829-d8516d57606c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import sys\n","PATH_DIR = '/content/drive/MyDrive/XAI-Anna-Carlos/'\n","sys.path.append(PATH_DIR)\n","\n","#import xai_faithfulness_experiments_lib_edits as ff\n","#%load_ext autoreload\n","#%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"VDjUF6yeVde1"},"source":["## Load data"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random,os\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","\n","PATH_DATA = '/content/drive/MyDrive/Projects/eval-project/titanic/'\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","def check_null_and_fill(df):\n","    for col in df.columns:\n","        if len(df.loc[df[col].isnull() == True]) != 0:\n","            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n","                df.loc[df[col].isnull() == True,col] = df[col].mean()\n","            else:\n","                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n","                \n","def prepare_titanic_data(val_size: float = 0.25, seed: int = 202):\n","    \"\"\"\n","    # Source: https://www.kaggle.com/code/rhythmcam/pytorch-titanic-classification\n","    \"\"\"\n","    \n","    seed_everything(seed=seed)\n","\n","    # Read sources and drop elements.\n","    drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin','SibSp','Parch']\n","    train = pd.read_csv(PATH_DATA + \"train.csv\")\n","    test = pd.read_csv(PATH_DATA +  \"test.csv\")\n","    train = train.drop(drop_elements, axis=1)\n","    test = test.drop(drop_elements, axis=1)\n","\n","    # Check for nulls and fill.       \n","    check_null_and_fill(train)\n","    check_null_and_fill(test)\n","\n","    str_list = [] \n","    num_list = []\n","    for colname, colvalue in train.iteritems():\n","        if type(colvalue[1]) == str:\n","            str_list.append(colname)\n","        else:\n","            num_list.append(colname)\n","    \n","    # One-hot encoding.\n","    train = pd.get_dummies(train, columns=str_list)\n","    test = pd.get_dummies(test, columns=str_list)\n","\n","    # Drop targets.\n","    target_value = \"Survived\"\n","    X = train.drop(target_value, axis=1).values\n","    y = train[target_value].values\n","    X_test = test.values\n","\n","    # Split validation set and map to tensors.\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=val_size, random_state=seed)\n","    X_train_tensor, X_valid_tensor, y_train_tensor, y_valid_tensor = map(torch.tensor, (X_train, X_valid, y_train, y_valid))\n","   \n","    return (train, test), (X_train, X_valid, y_train, y_valid), (X_train_tensor, X_valid_tensor, y_train_tensor, y_valid_tensor)"],"metadata":{"id":"qBZXCG-QrXWv","executionInfo":{"status":"ok","timestamp":1668420246892,"user_tz":-60,"elapsed":238,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["(train, test), (X_train, X_valid, y_train, y_valid), (X_train_tensor, X_valid_tensor, y_train_tensor, y_valid_tensor) = prepare_titanic_data()"],"metadata":{"id":"nGPtkyJmj20v","executionInfo":{"status":"ok","timestamp":1668420247220,"user_tz":-60,"elapsed":1,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Data statistics\n","pd.DataFrame(train).describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"PfrSOAxZt2U6","executionInfo":{"status":"ok","timestamp":1668420251979,"user_tz":-60,"elapsed":336,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}},"outputId":"c92f48f6-7e08-4e55-cbf2-a39fd162aa3a"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Survived      Pclass         Age        Fare  Sex_female    Sex_male  \\\n","count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n","mean     0.383838    2.308642   29.699118   32.204208    0.352413    0.647587   \n","std      0.486592    0.836071   13.002015   49.693429    0.477990    0.477990   \n","min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n","25%      0.000000    2.000000   22.000000    7.910400    0.000000    0.000000   \n","50%      0.000000    3.000000   29.699118   14.454200    0.000000    1.000000   \n","75%      1.000000    3.000000   35.000000   31.000000    1.000000    1.000000   \n","max      1.000000    3.000000   80.000000  512.329200    1.000000    1.000000   \n","\n","       Embarked_C  Embarked_Q  Embarked_S  \n","count  891.000000  891.000000  891.000000  \n","mean     0.188552    0.086420    0.725028  \n","std      0.391372    0.281141    0.446751  \n","min      0.000000    0.000000    0.000000  \n","25%      0.000000    0.000000    0.000000  \n","50%      0.000000    0.000000    1.000000  \n","75%      0.000000    0.000000    1.000000  \n","max      1.000000    1.000000    1.000000  "],"text/html":["\n","  <div id=\"df-80957948-f82a-4102-8645-8d020a6b1150\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>29.699118</td>\n","      <td>32.204208</td>\n","      <td>0.352413</td>\n","      <td>0.647587</td>\n","      <td>0.188552</td>\n","      <td>0.086420</td>\n","      <td>0.725028</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.002015</td>\n","      <td>49.693429</td>\n","      <td>0.477990</td>\n","      <td>0.477990</td>\n","      <td>0.391372</td>\n","      <td>0.281141</td>\n","      <td>0.446751</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>7.910400</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>29.699118</td>\n","      <td>14.454200</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>31.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>512.329200</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80957948-f82a-4102-8645-8d020a6b1150')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80957948-f82a-4102-8645-8d020a6b1150 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80957948-f82a-4102-8645-8d020a6b1150');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[" # Get possible values.\n","possible_vals = {}\n","for i, col in enumerate(train.columns[1:]):\n","    print(f\"{col}: {np.unique(X_train[:, i])}\")\n","    possible_vals[col] = np.unique(X_train[:, i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jan3Cc_v8eu","executionInfo":{"status":"ok","timestamp":1668420718788,"user_tz":-60,"elapsed":218,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}},"outputId":"94821897-2bdf-4023-dee9-467e3cbe3379"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Pclass: [1. 2. 3.]\n","Age: [ 0.42        0.67        0.75        1.          2.          3.\n","  4.          5.          6.          7.          8.          9.\n"," 10.         11.         12.         13.         14.         15.\n"," 16.         17.         18.         19.         20.         20.5\n"," 21.         22.         23.         23.5        24.         25.\n"," 26.         27.         28.         28.5        29.         29.69911765\n"," 30.         30.5        31.         32.         32.5        33.\n"," 34.         34.5        35.         36.         36.5        37.\n"," 38.         39.         40.         40.5        41.         42.\n"," 43.         44.         45.         45.5        46.         47.\n"," 48.         49.         50.         51.         52.         53.\n"," 54.         55.         55.5        56.         57.         58.\n"," 59.         60.         61.         62.         63.         64.\n"," 65.         66.         70.         70.5        71.         74.\n"," 80.        ]\n","Fare: [  0.       4.0125   6.2375   6.4375   6.45     6.4958   6.75     6.95\n","   6.975    7.0458   7.05     7.0542   7.125    7.1417   7.225    7.2292\n","   7.25     7.3125   7.4958   7.55     7.65     7.725    7.7292   7.7333\n","   7.7375   7.75     7.775    7.7958   7.8      7.8292   7.8542   7.875\n","   7.8792   7.8875   7.8958   7.925    8.0292   8.05     8.1125   8.1583\n","   8.3625   8.4042   8.4333   8.5167   8.6625   9.       9.35     9.4833\n","   9.5      9.5875   9.825    9.8375   9.8417   9.8458  10.1708  10.4625\n","  10.5     11.1333  11.2417  11.5     12.      12.2875  12.35    12.475\n","  12.525   12.65    12.875   13.      13.4167  13.5     13.7917  13.8583\n","  14.1083  14.4     14.4542  14.5     15.      15.0458  15.05    15.1\n","  15.2458  15.5     15.55    15.7417  15.75    15.85    15.9     16.1\n","  16.7     17.4     17.8     18.      18.75    18.7875  19.2583  19.5\n","  19.9667  20.2125  20.25    20.525   20.575   21.      21.075   21.6792\n","  22.025   22.3583  22.525   23.      23.25    23.45    24.      24.15\n","  25.4667  25.5875  25.9292  26.      26.25    26.2833  26.2875  26.55\n","  27.      27.7208  27.75    27.9     28.5     29.      29.125   29.7\n","  30.      30.0708  30.5     31.      31.275   31.3875  32.5     33.\n","  34.375   35.5     36.75    37.0042  38.5     39.      39.6     39.6875\n","  40.125   41.5792  46.9     49.5     49.5042  50.      50.4958  51.4792\n","  51.8625  52.      52.5542  53.1     55.4417  55.9     56.4958  56.9292\n","  57.9792  59.4     61.175   61.3792  63.3583  65.      66.6     69.3\n","  69.55    71.      73.5     75.25    76.7292  77.9583  78.2667  78.85\n","  79.2     79.65    80.      81.8583  82.1708  83.1583  83.475   86.5\n","  90.      91.0792  93.5    106.425  108.9    110.8833 113.275  120.\n"," 133.65   134.5    135.6333 146.5208 151.55   153.4625 164.8667 211.3375\n"," 211.5    221.7792 227.525  247.5208 262.375  263.     512.3292]\n","Sex_female: [0. 1.]\n","Sex_male: [0. 1.]\n","Embarked_C: [0. 1.]\n","Embarked_Q: [0. 1.]\n","Embarked_S: [0. 1.]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yj_0mHZBcb8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Feature imputation strategies\n","\n","- Simple mean\n","- Sample from existing values\n","- Dependent on dtype\n","    - Categorical:\n","    - Boolean:\n","    - Float:\n"],"metadata":{"id":"hxREjwEjccqc"}},{"cell_type":"markdown","metadata":{"id":"qJBNApvaWUAJ"},"source":["# Load model"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":1329,"status":"ok","timestamp":1668420977774,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"},"user_tz":-60},"id":"ZtWSnUP4WV0w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f9138d6-6b24-43aa-a3aa-ed0bc1e7dfc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7533632516860962\n"]}],"source":["def load_pretrained_model(path: str, dataset: str = \"MNIST\"):\n","\n","    class MNISTClassifier(torch.nn.Module):\n","        \"\"\"\n","        # Source: https://nextjournal.com/gkoehler/pytorch-mnist\n","        \"\"\"\n","        def __init__(self):\n","            super(MNISTClassifier, self).__init__()\n","            self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n","            self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n","            self.conv2_drop = torch.nn.Dropout2d()\n","            self.fc1 = torch.nn.Linear(320, 50)\n","            torch.self.fc2 = nn.Linear(50, 10)\n","\n","        def forward(self, x):\n","            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","            x = x.view(-1, 320)\n","            x = F.relu(self.fc1(x))\n","            x = F.dropout(x, training=self.training)\n","            x = self.fc2(x)\n","            return F.log_softmax(x)\n","\n","    if dataset == \"MNIST\":\n","        network = MNISTClassifier()\n","        if os.path.isfile(path):\n","            network.load_state_dict(torch.load(path))\n","            network.eval()\n","            network.to(device)\n","        else:\n","            raise Exception('ERROR: Could not find model at ',path)\n","        return network\n","\n","    elif dataset == \"Titanic\":\n","\n","        MODEL_NEURONS = 100\n","        MODEL_EPOCHS= 500\n","        MODEL_LR = 1.0e-3\n","        MODEL_LABEL_NUM = 2\n","\n","        class MLP(torch.nn.Module):\n","            def __init__(self, n_neurons):\n","                super(MLP, self).__init__()\n","                self.fc1 = torch.nn.Linear(X.shape[1], n_neurons)\n","                self.ac1 = torch.nn.Sigmoid()\n","                self.fc2 = torch.nn.Linear(n_neurons,MODEL_LABEL_NUM) \n","            \n","            def forward(self, x):\n","                x = self.fc1(x)\n","                x = self.ac1(x)\n","                x = self.fc2(x)\n","                return x\n","\n","        network = MLP(MODEL_NEURONS)\n","        loss = torch.nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(network.parameters(), lr=MODEL_LR)\n","\n","        X_train_tensor_float = X_train_tensor.float()\n","        X_valid_tensor_float = X_valid_tensor.float()\n","\n","        for epoch in range(MODEL_EPOCHS):\n","            optimizer.zero_grad()\n","            \n","            preds = network(X_train_tensor_float)\n","            loss_value = loss(preds, y_train_tensor)\n","            loss_value.backward()        \n","            optimizer.step()\n","\n","            test_preds = network.forward(X_valid_tensor_float)        \n","            accuracy = (test_preds.argmax(dim=1) == y_valid_tensor).float().mean()    \n","            \n","        print(accuracy.item())\n","\n","        return network\n","\n","PATH_PRETRAINED = './mnist-classifier.pth'\n","network = load_pretrained_model(path=PATH_PRETRAINED, dataset=\"Titanic\")"]},{"cell_type":"markdown","metadata":{"id":"2cOCxmm9eT00"},"source":["## Get measures for a given ranking"]},{"cell_type":"code","source":["example_data = X_valid\n","example_targets = y_valid"],"metadata":{"id":"Q5X0MXOrvJJ9","executionInfo":{"status":"ok","timestamp":1668420977973,"user_tz":-60,"elapsed":2,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1668420978301,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"},"user_tz":-60},"id":"tE_3bT-xeswr"},"outputs":[],"source":["import numpy as np\n","example_num = 10\n","row = example_data[example_num]\n","label = example_targets[example_num]\n","\n","# Create a random ranking for testing purposes\n","some_ranking = np.random.rand(row.size)"]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"gND4NZ6HpEYQ","executionInfo":{"status":"ok","timestamp":1668421013796,"user_tz":-60,"elapsed":261,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import os.path\n","import numpy as np\n","import copy\n","\n","NUM_SAMPLES = 20\n","\n","def load_generated_data_old_format(path):\n","    '''\n","    Loads a file that contains a set of feature rankings for a given input\n","    Returns a dictionary with:\n","      - input: The input that the rankings try to explain for the one pretrained model that we use\n","      - label: Label that the rankings try to explain\n","      - rankings: The actual feature rankings\n","      - qmeans: One qmean value for each ranking\n","      - qmean_invs: One qmean value for each inverse ranking\n","      - qargmaxs: One qmean value for each ranking\n","      - qargmax_invs: One qmean value for each inverse ranking\n","      - qaucs: One qauc for each ranking\n","      - qauc_invs: One qauc for each inverse ranking\n","      - output_curves: One curve for each ranking representing the output of the label output of the model at the given selection levels\n","      - is_hit_curves: One curve for each ranking representing whether the output of the label output of the model at the given selection levels is the maximum output of the model\n","      - output_curves_inv: One curve for each inverse ranking representing the output of the label output of the model at the given selection levels\n","      - is_hit_curves_inv: One curve for each ranking representing whether the output of the label output of the model at the given selection levels is the maximum output of the model\n","    '''\n","    data = np.load(path)\n","\n","    input = data['arr_0']\n","    label = data['arr_1']\n","    rankings = data['arr_2']\n","    plots = data['arr_3']\n","    inverse_plots = data['arr_4']\n","    hit_plots = data['arr_5']\n","    inverse_hit_plots = data['arr_6']\n","    measures = data['arr_7']\n","    measures_with_inverse = data['arr_8']\n","\n","    return {'input': input, \\\n","            'label': label, \\\n","            'rankings': rankings, \\\n","            'qmeans': measures, \\\n","            'qmean_invs': measures_with_inverse, \\\n","            'qargmaxs': None, \\\n","            'qargmax_invs': None, \\\n","            'qaucs': None, \\\n","            'qauc_invs': None, \\\n","            'output_curves': plots, \\\n","            'is_hit_curves': hit_plots, \\\n","            'output_curves_inv': inverse_plots, \\\n","            'is_hit_curves_inv': inverse_hit_plots \\\n","            }\n","\n","def load_generated_data(path):\n","    return np.load(path)\n","\n","    ''' Q measures:\n","   - Mean activation\n","   - Activation at the first point where the label is the argmax of the outputs\n","   - Activation at a fixed selection point\n","   - AUC\n","   '''\n","def measure_mean_activation(curve):\n","  return np.mean(curve)\n","\n","def measure_at_selection_level(curve, selection_level): # Selection level should be in [0, 1]\n","  selection_point = int(selection_level * curve.shape[0]) # May need to subtract 1 or floor\n","  return curve[selection_point]\n","\n","def measure_output_at_first_argmax(curve, is_hit): # Returns output at the first selection point that makes is_hit True.\n","  selection_point = np.argmax(is_hit) # Finds the first True (returns 0 if there are no Trues)\n","  if (selection_point==0) and True in is_hit[0]: # Check if it's zero because there are no Trues\n","        selection_point=len(is_hit)-1\n","\n","\n","  return curve[selection_point]\n","\n","def measure_auc(values: np.array, dx: int = 1):\n","    return np.trapz(values, dx=dx)\n","\n","''' Utility functions '''\n","def _get_masked_inputs(original_input, alternative_input, ranking_row, selection_levels):\n","  '''\n","  Generates as many masked inputs as selection levels are provided\n","  Inputs are torch tensors already on device\n","  '''\n","  # Reshape selection_levels to be able to broadcast the selection levels and get\n","  # as many masks as selection levels are provided\n","  new_shape = (selection_levels.shape[0], 1, 1, 1) # Same shape but with a trailing 1\n","  selection_levels = torch.reshape(selection_levels, new_shape)\n","  # Compute all masks in batch\n","  masks = torch.le(ranking_row,selection_levels)\n","  # Compute masked inputs from masks and original and alternative inputs\n","  inputs_masked = (original_input*masks) + (alternative_input*torch.logical_not(masks))\n","  return inputs_masked\n","\n","def _get_random_ranking_row(dimensions):\n","  num_elems = 1\n","  for d in dimensions:\n","    num_elems *= d\n","  input = np.random.permutation(num_elems).reshape(dimensions)/(num_elems-1)\n","  return torch.from_numpy(input)\n","\n","def _get_class_logits_for_masked_inputs(original_input, alternative_input, ranking_row, selection_levels, model, class_num):\n","  with torch.no_grad():\n","    # Send everything to device and work there\n","    input = original_input.to(device)\n","    alternative = alternative_input.to(device)\n","    ranking = ranking_row.to(device)\n","    levels = selection_levels.to(device)\n","    inputs = _get_masked_inputs(input, alternative, ranking, levels)\n","    logits = model(inputs).to('cpu').numpy()\n","  return logits[:,class_num],np.equal(np.argmax(logits, axis=1),class_num.item())\n","\n","'''def save_explanation_exploratory_plot(input, curve, is_hit, output_label, filename='unnamed'):\n","  # Plot and save the figures\n","  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n","  axes[0].imshow(input[0], cmap='gray', interpolation='none')\n","  axes[0].title.set_text(output_label)\n","  axes[0].axis(\"off\")\n","  for i in range(1, len(curve)):\n","    axes[1].plot([i-1,i],curve[i-1:i+1], lw=5 if is_hit[i] else 1, color='b')\n","  fig.savefig(f'{filename}.png')\n","  plt.show()'''\n","\n","def _get_explanation_exploratory_curve(input, ranking_row, num_samples, output_label, model):\n","  assert(torch.max(ranking_row)==1.0)\n","  assert(torch.min(ranking_row)==0.0)\n","  alternative = torch.from_numpy(np.full(input.shape,  0, dtype=np.float32)) #ZEROED-OUT\n","\n","  # Selection levels\n","  selection_levels = torch.from_numpy(np.linspace(0, 1, num_samples))\n","\n","  # Increasing order\n","  class_logit,is_hit = _get_class_logits_for_masked_inputs(input, alternative, ranking_row, selection_levels, model, output_label)\n","\n","  # Compute the numerical value for the measure\n","  #measure = measure_curves(class_logit)\n","\n","  return class_logit,is_hit\n","\n","def _attributions_to_ranking_row(attributions, reverse=False):\n","    ranked_attributions = copy.copy(attributions)\n","    ranked_attributions.tolist().sort(reverse=reverse)\n","    ranked_attributions = np.array(ranked_attributions)\n","    ranking_row = np.zeros(attributions.shape)\n","    num_attributes = len(ranked_attributions)\n","    for i in range(num_attributes):\n","        x = int(ranked_attributions[i])\n","        ranking_row[x] = i/(num_attributes-1)\n","    return ranking_row\n","\n","def get_measures_for_ranking(input, ranking_row, output_label, model, measures=['mean','at_first_argmax','auc'], num_samples=NUM_SAMPLES, with_inverse=False, with_random=False):\n","    curve,is_hit = _get_explanation_exploratory_curve(input, ranking_row, num_samples, output_label, model)\n","\n","    result = {'output_curve': curve, \\\n","              'is_hit_curve': is_hit}\n","\n","    for measure in measures:\n","        if measure=='mean':\n","            result['mean'] = measure_mean_activation(curve)\n","        elif measure=='at_first_argmax':\n","            result['at_first_argmax'] = measure_output_at_first_argmax(curve, is_hit)\n","        elif measure=='auc':\n","            result['auc'] = measure_auc(curve)\n","\n","    if with_inverse:\n","        # Get the measures for the inverse ranking\n","        result_inverse = get_measures_for_ranking(input, 1-ranking_row, output_label, model, measures, num_samples, with_inverse=False, with_random=False)\n","        result['output_curve_inv'] = result_inverse['output_curve']\n","        result['is_hit_curve_inv'] = result_inverse['is_hit_curve']\n","        for measure in measures:\n","            if measure=='mean':\n","                result['mean_inv'] = result['mean'] - result_inverse['mean']\n","            elif measure=='at_first_argmax':\n","                # The selection point is determined by the regular curve\n","                selection_point = np.argmax(result['is_hit_curve']) # Finds the first True (returns 0 if there are no Trues)\n","                if selection_point==0 and not (True in is_hit[0]): # Check if it's zero because there are no Trues\n","                  selection_point=len(is_hit)-1\n","                result['at_first_argmax_inv'] = result['at_first_argmax'] - result_inverse['output_curve'][selection_point]\n","            elif measure=='auc':\n","                result['auc_inv'] = result['auc'] - result_inverse['auc']\n","\n","    if with_random:\n","        # Get the measures for the inverse ranking\n","        result_random = get_measures_for_ranking(input, _get_random_ranking_row(ranking_row.shape), output_label, model, measures, num_samples, with_inverse=False, with_random=False)\n","        result['output_curve_bas'] = result_random['output_curve']\n","        result['is_hit_curve_bas'] = result_random['is_hit_curve']\n","        for measure in measures:\n","            if measure=='mean':\n","                result['mean_bas'] = result['mean'] - result_random['mean']\n","            elif measure=='at_first_argmax':\n","                # The selection point is determined by the regular curve\n","                selection_point = np.argmax(result['is_hit_curve']) # Finds the first True (returns 0 if there are no Trues)\n","                if selection_point==0 and not( True in is_hit[0]): # Check if it's zero because there are no Trues\n","                  selection_point=len(is_hit)-1\n","                result['at_first_argmax_bas'] = result['at_first_argmax'] - result_random['output_curve'][selection_point]\n","            elif measure=='auc':\n","                result['auc_bas'] = result['auc'] - result_random['auc']\n","\n","    #TODO Compute measures and return\n","    return result\n","\n","def get_measures_for_attributions(input, attributions, output_label, model, measures=['mean','at_first_argmax','auc'], num_samples=NUM_SAMPLES, with_inverse=False, with_random=False):\n","    ranking_row = torch.from_numpy(_attributions_to_ranking_row(attributions))\n","    return get_measures_for_ranking(input, ranking_row, output_label, model, measures, num_samples, with_inverse, with_random)\n","\n","measures = get_measures_for_attributions(torch.Tensor(row), some_ranking, label, network, with_inverse=True)\n","print(measures)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkmd5y-xjc5g","executionInfo":{"status":"ok","timestamp":1668422530105,"user_tz":-60,"elapsed":212,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}},"outputId":"c380d19c-0b05-47f1-ddae-162188429742"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["{'output_curve': array([[[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[-2.4176884 ,  2.3770678 ]],\n","\n","       [[ 0.11686104, -0.22199465]]], dtype=float32), 'is_hit_curve': array([[[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]]]), 'mean': -0.021923114, 'at_first_argmax': array([[ 0.11686104, -0.22199465]], dtype=float32), 'auc': array([[-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.02031028],\n","       [-0.05256681]], dtype=float32), 'output_curve_inv': array([[[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.3948519 ,  0.25201553]],\n","\n","       [[-0.39485192,  0.25201553]],\n","\n","       [[ 0.11686104, -0.22199465]]], dtype=float32), 'is_hit_curve_inv': array([[[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]],\n","\n","       [[ True,  True]]]), 'mean_inv': 0.048552502, 'at_first_argmax_inv': array([[ 0.5117129 , -0.47401017]], dtype=float32), 'auc_inv': array([[0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.0511079 ],\n","       [0.05110791],\n","       [0.        ]], dtype=float32)}\n"]}]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668421644826,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"},"user_tz":-60},"id":"yVw3RM4ievxI"},"outputs":[],"source":[]},{"cell_type":"code","source":["np.argmax([1,1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQvkCIx1iw7z","executionInfo":{"status":"ok","timestamp":1668419374802,"user_tz":-60,"elapsed":219,"user":{"displayName":"Anna Hedström","userId":"05540180366077551505"}},"outputId":"077e95f0-2c72-447d-ee4b-09ac3a130a41"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":[],"metadata":{"id":"GZq4rvAgiykk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}